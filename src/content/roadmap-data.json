{
  "poadmap_articles": [
     {
      "article_title": "What's an API?",
      article_title_citation": "https://blog.algomaster.io/p/whats-an-api",      
      "article_content_markdown": "# What's an API?\n\n### what every tech company has in common\n\nAPI stands for **Application Programming Interface**.\n\nAt its core, an API is a **bunch of code** that takes an **input** and gives you predictable **outputs.**\n\n[![](https://substackcdn.com/image/fetch/$s_!5FqW!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7187692b-8f59-414c-8e29-b44245f3d1d5_1534x306.png)](https://substackcdn.com/image/fetch/$s_!5FqW!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7187692b-8f59-414c-8e29-b44245f3d1d5_1534x306.png)\n\nThink of an API as a **middleman** that enables applications to interact **without needing direct access to each other's code or database**.\n\nAlmost every digital service you use today—social media, e-commerce, online banking, ride-hailing apps—all of them are a bunch of APIs working together.\n\n**Examples:**\n\n- **Weather API** – If you provide a city name as input (`\"New York\"`), the API returns the **current temperature, humidity, and weather conditions**.\n\n- **Uber Ride API** – If you provide a **pickup and destination address**, the API finds the **nearest available driver** and calculates the estimated fare.\n\n- **Python's**`sorted()` **API** – If you provide a list of numbers (`[5, 3, 8, 1]`), the API returns the **sorted list** (`[1, 3, 5, 8]`).\n\n\nWhen engineers build APIs, they clearly define **what inputs the API accepts** and **what outputs it produces**, ensuring consistent behavior across different applications.\n\nAPIs follow a simple **request-response** model:\n\n[![](https://substackcdn.com/image/fetch/$s_!EH_B!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c3a0e69-9134-4bd9-9d42-a898bc838e32_1574x504.png)](https://substackcdn.com/image/fetch/$s_!EH_B!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c3a0e69-9134-4bd9-9d42-a898bc838e32_1574x504.png)\n\n- A client (such as a web app or mobile app) makes a request to an API.\n\n- The API (hosted on an API server) processes the request, interacts with the necessary databases or services, and prepares a response.\n\n- The API sends the response back to the client in a structured format (usually JSON or XML).\n\n\n#### Inputs\n\nEvery API requires **specific types of inputs**, and passing incorrect data can result in errors.\n\nFor example: If you tried putting your name into the Google Maps API as an input, that wouldn’t work very well.\n\nSome APIs also **require inputs in a specific format**.\n\nExample: The **Currency Exchange API** might need the input as `\"USD_TO_EUR\"` instead of `\"usd to euro\"`.\n\nAPIs often **validate inputs** to ensure they are correct before processing them, which helps maintain **accuracy and security**.\n\n#### Outputs\n\nJust as APIs require **specific inputs**, they also return **well-structured outputs**.\n\nFor example, the **Google Maps API** always returns **coordinates in the same format**.\n\n```\n{\n  \"latitude\": 40.6892,\n  \"longitude\": -74.0445\n}\n```\n\nIf the API can’t find the location, it provides an error response explaining why.\n\n```\n{\n  \"error\": \"Invalid address format\",\n  \"code\": 400\n}\n```\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n# 1\\. How APIs Power Modern Applications\n\nThe apps you use every day—whether it's **Gmail, Instagram, Uber, or Spotify**—are essentially **a collection of APIs with a polished user interface (UI) on top**.\n\nMost applications follow the **frontend/backend architecture**, where:\n\n- The **backend** consists of APIs that handle **data processing, business logic, and communication with databases**.\n\n- The **frontend** is a **graphical user interface (GUI)** that interacts with these APIs, making applications user-friendly and accessible **without requiring users to write code**.\n\n\n[![](https://substackcdn.com/image/fetch/$s_!Xpcr!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27d50e3c-c298-4f48-b410-d70dd6a435e3_1322x890.png)](https://substackcdn.com/image/fetch/$s_!Xpcr!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27d50e3c-c298-4f48-b410-d70dd6a435e3_1322x890.png)\n\nLet’s break this down with a real-world example: **Uber**.\n\n#### The Backend\n\nBefore the Uber app existed as a sleek, user-friendly experience, the company first built **the core APIs that power ride-hailing services:**\n\n- Finding Nearby Drivers\n\n- Calculating Fares & Routes\n\n- Process Payment\n\n- Real-Time Tracking\n\n- Matching Riders & Drivers\n\n\nThese APIs run on Uber’s servers, forming the **backend infrastructure**. Every time you request a ride, track your driver, or make a payment, these backend APIs handle the request.\n\n**Backend engineers** are responsible for optimizing these APIs, improving ride-matching algorithms, securing transactions, and ensuring a smooth experience for millions of users.\n\n#### The Frontend\n\nThe backend APIs handle **all the complex logic**, but they **only work through code**—which isn't practical for everyday users. That’s why companies build a **frontend (user interface)** on top of these APIs, allowing users to interact with the system **visually and intuitively**.\n\n**Example:** When you enter your pickup & destination address, the frontend sends an API request to **find nearby drivers** and displays available cars.\n\nOnce the trip is complete, the frontend may call the process payment API to display the receipt.\n\n[Share](https://blog.algomaster.io/p/whats-an-api?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n# **2\\. Types of APIs**\n\nAPIs come in different forms depending on **who can access them**, **how they are used**, and **what purpose they serve**.\n\n### 1\\. Open APIs (Public APIs)\n\nOpen APIs, also known as **Public APIs**, are accessible to external developers with minimal restrictions.\n\nCompanies provide these APIs to encourage **third-party developers** to integrate their services and build new applications on top of them.\n\n#### **Example: YouTube Data API**\n\nNormally, when you use the **YouTube app**, it makes **internal API calls** to fetch your video feed, search for content, or post comments. However, YouTube also provides a **public API** that allows developers to access some of this functionality **outside of the app**.\n\nFor example, the **YouTube Search API** allows developers to fetch video results based on a keyword. If you send a request to the API with `\"machine learning tutorial\"` as the search term, it will return a structured response (JSON format) containing a list of relevant videos, including **titles, descriptions, thumbnails, and video links**.\n\nThis is incredibly useful because it enables developers to build custom applications on top of YouTube.\n\n### 2\\. Internal APIs (Private APIs)\n\n**Internal APIs**, also known as **Private APIs**, are designed **e** xclusively for internal use within an organization. Unlike Open APIs, these are not accessible to external developers and are used to facilitate seamless communication between different internal systems within a company.\n\nLet’s take **Amazon** as an example. When you place an order, you might assume that a single system processes your request. In reality, **multiple internal APIs** (order processing, inventory, payment, logistics etc..) work together behind the scenes to fulfill your order efficiently.\n\nEach of these APIs **operates independently**, but they communicate through well-defined protocols to ensure a smooth and efficient process.\n\nInternal APIs allow companies to break down their applications into **smaller, manageable services**, making it easier to scale. Developers can **reuse internal APIs** across different projects, reducing **duplication** and speeding up development.\n\n### 3\\. Code Interfaces\n\nThe first two types of APIs we discussed— **Open APIs and Internal APIs**—are functional and serve **real-world use cases** like fetching weather data or booking a ride.\n\nBut there’s another category of APIs that developers use daily: **Code Interfaces** (also called **Library APIs** or **Programming APIs**).\n\nThese APIs don’t connect different applications; instead, they provide predefined functions within a programming language or framework to make development easier.\n\n**Example:** Python’s built-in list API\n\nWhen working with lists, Python provides a set of **built-in functions (methods) to manipulate data**.\n\n```\nnumbers = [5, 3, 8, 1, 4] numbers.sort()  # API call to sort the list\nfruits = [\"apple\", \"banana\"]\nfruits.append(\"orange\")  # API call to add an element\nfruits.pop()  # API call to remove the last element\n```\n\nInstead of writing sorting algorithms from scratch, developers can use `sort()` or `sorted()` in Python.\n\nCode APIs are not just limited to built-in programming language functions. Take **TensorFlow**, an AI/ML library. It provides a **high-level API** for training machine learning models without needing to implement complex mathematical operations from scratch.\n\nFor example, creating a **neural network** using TensorFlow's API is as simple as:\n\n```\nimport tensorflow as tf model = tf.keras.Sequential([tf.keras.layers.Dense(64, activation=\"relu\")])\n```\n\nProgramming APIs abstract away complexity so that developers can focus on building solutions rather than reinventing the wheel.\n\n* * *\n\n# 3\\. API Communication Methods\n\nAPIs communicate using different **protocols and architectures** that define how requests are sent, how responses are formatted, and how data is exchanged between systems.\n\n### 1\\. REST (Representational State Transfer)\n\nREST is the most widely used API communication method today. It is **lightweight, stateless, and scalable**, making it perfect for web services and mobile applications.\n\nREST APIs follow a set of design principles and use **HTTP methods** (GET, POST, PUT, DELETE) to perform operations.\n\nREST APIs are based on **resources**, and each resource is accessed through a **URL (endpoint)**. The API follows the **client-server model**, meaning the client sends a request, and the server processes it and sends a response.\n\n#### Example: REST API for a Bookstore\n\n**Retrieve a list of books (GET Request):**\n\n```\nGET https://api.bookstore.com/books\n```\n\n**Response (JSON):**\n\n```\n[\\\n  {\\\n    \"id\": 1,\\\n    \"title\": \"Clean Code\",\\\n    \"author\": \"Robert C. Martin\"\\\n  },\\\n  {\\\n    \"id\": 2,\\\n    \"title\": \"The Pragmatic Programmer\",\\\n    \"author\": \"Andrew Hunt\"\\\n  }\\\n]\n```\n\n### 2\\. SOAP (Simple Object Access Protocol)\n\nSOAP is an older API communication method that **relies on XML-based messaging**.\n\nUnlike REST, which is lightweight, SOAP is more structured and secure, making it ideal for banking, healthcare, and enterprise applications.\n\nSOAP messages are sent using **XML format** and require a **WSDL (Web Services Description Language) file**, which defines the API's available functions and request structure.\n\n#### **Example: SOAP API for a Banking Service**\n\n**Request:** Fetching account balance\n\n```\n<soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:bank=\"http://bank.example.com/\">\n  <soapenv:Header/>\n  <soapenv:Body>\n    <bank:GetAccountBalance>\n      <bank:accountNumber>123456</bank:accountNumber>\n    </bank:GetAccountBalance>\n  </soapenv:Body>\n</soapenv:Envelope>\n```\n\n**Response:**\n\n```\n<soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:bank=\"http://bank.example.com/\">\n  <soapenv:Body>\n    <bank:GetAccountBalanceResponse>\n      <bank:balance>5000.00</bank:balance>\n    </bank:GetAccountBalanceResponse>\n  </soapenv:Body>\n</soapenv:Envelope>\n```\n\n### 3\\. GraphQL\n\nGraphQL is an alternative to REST that **allows clients to request exactly the data they need**, making it more efficient for modern applications. Unlike REST, which requires multiple API calls to fetch related data, GraphQL can **fetch all necessary data in a single request**.\n\nInstead of predefined endpoints, GraphQL exposes a **single API endpoint**, and the client sends queries to request specific fields.\n\n#### Example: Fetching a user's profile and their recent posts in a single request.\n\n```\n{\n  user(id: 123) {\n    name\n    email\n    posts {\n      title\n      likes\n    }\n  }\n}\n```\n\nResponse:\n\n```\n{\n  \"data\": {\n    \"user\": {\n      \"name\": \"Alice\",\n      \"email\": \"alice@example.com\",\n      \"posts\": [\\\n        {\\\n          \"title\": \"Hello World\",\\\n          \"likes\": 100\\\n        },\\\n        {\\\n          \"title\": \"GraphQL is Amazing!\",\\\n          \"likes\": 200\\\n        }\\\n      ]\n    }\n  }\n}\n```\n\n### 4\\. gRPC\n\ngRPC (Google Remote Procedure Call) is a **high-performance API communication method** that uses **Protocol Buffers (Protobuf)** instead of JSON or XML, making it faster and more efficient.\n\ngRPC uses **binary data format** instead of text-based formats, reducing payload size and it supports **bidirectional streaming**, meaning the client and server can send data at the same time.\n\n* * *\n\n# 4\\. How to Use an API (Step-by-Step Guide)\n\nUsing an API might seem complex at first, but it follows a simple **request-response** pattern.\n\nHere’s a guide on **how to find, access, and interact with an API** step by step:\n\n### **Step 1: Find an API to Use**\n\nBefore using an API, you need to **identify the right API** for your needs. APIs are available for different services like weather data, finance, social media, etc.\n\n#### **Where to Find APIs?**\n\n**Public API directories:**\n\n- [RapidAPI](https://rapidapi.com/) – A marketplace for APIs with free & paid options.\n\n- [Postman API Network](https://www.postman.com/explore) – A collection of public APIs.\n\n- [API List](https://apilist.fun/) – A fun list of free public APIs.\n\n- [GitHub’s Public API List](https://github.com/public-apis/public-apis) – Open-source API collection.\n\n\n**Official API Documentation:**\n\n- [Google APIs](https://developers.google.com/)\n\n- [X API](https://developer.x.com/)\n\n- [OpenWeather API](https://openweathermap.org/api)\n\n\n### **Step 2: Read the API Documentation**\n\nAPI documentation explains **how to use the API, available endpoints, authentication, and response formats**.\n\n**Example:** The **[OpenWeatherMap API](https://openweathermap.org/api/one-call-3)**\n\nThe OpenWeatherMap API allows users to fetch real-time weather data. Here's a breakdown of its key components:\n\n**API URL**\n\n```\nhttps://api.openweathermap.org/data/3.0/weather?q=city_name&appid=YOUR_API_KEY\n```\n\n**Required Parameters:**\n\n- `q`: City name (e.g., `London`)\n\n- `appid`: API Key (required for access)\n\n\n### **Step 3: Get API Access (API Key / Authentication)**\n\nMost APIs **require authentication** to prevent unauthorized access and manage usage limits.\n\n#### **Common Authentication Methods:**\n\n- **API Key -** A unique key provided by the API service\n\n- **OAuth 2.0 -** Secure login via Google, Github, etc.\n\n- **JWT (JSON Web Token):** Token-based authentication\n\n- **Basic Authentication:** Username + password (Base64 encoded)\n\n\n**Example: Getting an API Key (OpenWeather API)**\n\n- Sign up at https://home.openweathermap.org/users/sign\\_up.\n\n- Go to the **API keys** section and generate a key.\n\n- Use the API key in requests:\n\n\n```\nGET https://api.openweathermap.org/data/2.5/weather?q=London&appid=YOUR_API_KEY\n```\n\n### **Step 4: Test the API Using Postman or cURL**\n\nBefore writing code, **test the API** to see how it responds.\n\n#### **Option 1: Using Postman (Recommended for Beginners)**\n\n- Download & install **[Postman](https://www.postman.com/)**.\n\n- Click **\"New Request\"**, enter the API endpoint URL (`https://api.openweathermap.org/data/3.0/weather?q=London&appid=YOUR_API_KEY`).\n\n- Select **GET** as the HTTP method.\n\n- Click **\"Send\"** and view the response in **JSON format**.\n\n\n#### **Option 2: Using cURL (For Command Line Users)**\n\nYou can also test APIs directly from the **command line** using **[cURL](https://curl.se/)**.\n\n```\ncurl -X GET \"https://api.openweathermap.org/data/3.0/weather?q=New+York&appid=YOUR_API_KEY\"\n```\n\n### **Step 5: Write Code to Call the API**\n\nNow that you’ve tested the API, it’s time to **integrate it into your application**.\n\n#### **Example: Calling an API in Python**\n\n```\nimport requests\n\nAPI_KEY = \"YOUR_API_KEY\"\nCITY = \"New York\"\n\nurl = f\"https://api.openweathermap.org/data/3.0/weather?q={CITY}&appid={API_KEY}\"\n\nresponse = requests.get(url)\n\nif response.status_code == 200:\n    data = response.json()\n    temperature = data['main']['temp']\n    print(f\"Current temperature in {CITY}: {temperature}°C\")\nelse:\n    print(f\"Error retrieving data: Status code {response.status_code}\")\n```\n\n- `requests.get(url)` – Sends an API request.\n\n- `response.json()` – Converts response to JSON.\n\n- `if response.status_code == 200` – Checks if the request was successful.\n\n\n### **Step 6: Handle Errors & Rate Limits**\n\nAPIs **don’t always return perfect responses**. You should handle:\n\n- **Invalid inputs** (e.g., wrong city name).\n\n- **Authentication errors** (e.g., expired API keys).\n\n- **Rate limits** (e.g., exceeding request limits).\n\n\n#### **Example: Handling API Errors in Python**\n\n```\nimport requests\n\nAPI_KEY = \"YOUR_API_KEY\"\nCITY = \"New York\"\n\nurl = f\"https://api.openweathermap.org/data/3.0/weather?q={CITY}&appid={API_KEY}\"\n\nresponse = requests.get(url)\n\nif response.status_code == 200:\n    data = response.json()\n    weather_description = data['weather'][0]['description']\n    print(f\"Current weather in {CITY}: {weather_description}\")\nelif response.status_code == 401:\n    print(\"Error: Invalid API key\")\nelif response.status_code == 404:\n    print(\"Error: City not found\")\nelse:\n    print(f\"Unexpected error occurred: Status code {response.status_code}\")\n```\n\n### Step 7: Use API Responses in Your Application\n\nOnce you fetch data from an API, you can **display it dynamically in a web or mobile app**.\n\n**Example:** You can build a weather dashboard using the OpenWeatherMap API.\n\n- Fetch live weather data from the API.\n\n- Parse and extract relevant details (temperature, humidity, condition).\n\n- Display the weather report in a user-friendly format.\n\n"
      "article_content_markdown_citation": "https://blog.algomaster.io/p/whats-an-api"
    },
    {
      "article_title": "What are Webhooks?",
      "article_title_citation": "https://blog.algomaster.io/p/what-are-webhooks",
      "article_content_markdown": "Imagine you're building an e-commerce platform and using an external payment processor like [Stripe](https://stripe.com/) to collect payments from users.\n\nOnce a user completes a payment, your system needs to:\n\n- Mark the order as paid\n\n- Send an invoice\n\n- Notify the warehouse to start packing\n\n\n**But here's the challenge:**\n\nStripe operates on its own infrastructure. Your system doesn’t control it. So how do you know **instantly** when a payment goes through?\n\nA naive solution would be to keep asking Stripe every few seconds:\n\n[![](https://substackcdn.com/image/fetch/$s_!dx3C!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb2de1743-d3ec-4f12-bd3c-e7e348239d6a_1184x988.png)](https://substackcdn.com/image/fetch/$s_!dx3C!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb2de1743-d3ec-4f12-bd3c-e7e348239d6a_1184x988.png)\n\nThis is known as **polling**.\n\nNow imagine doing this for **every order** on a site like Amazon.\n\nIt just doesn’t scale and wastes server resources.\n\nInstead of your app repeatedly asking, **what if Stripe could just tell you** when the payment succeeds?\n\nThat’s what **webhooks** do.\n\nIn this article, we will explore:\n\n- What is a Webhook?\n\n- How Webhooks Work?\n\n- What does a Webhook request look like?\n\n- How to setup a Webhook receiver?\n\n- How to design a scalable Webhook infrastructure?\n\n\n* * *\n\n# 1\\. What is a Webhook?\n\n> A webhook is a simple way for one system (provider) to notify another system (receiver) in real time when an event happens using an HTTP request.\n\n[![](https://substackcdn.com/image/fetch/$s_!owua!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F15601152-796b-4599-9e78-cb4836da43c3_1644x930.png)](https://substackcdn.com/image/fetch/$s_!owua!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F15601152-796b-4599-9e78-cb4836da43c3_1644x930.png)\n\nInstead of one system asking repeatedly if something happened, the other system simply pushes the data as soon as the event is triggered.\n\n#### Real-World Analogy\n\nLet’s say you go to a busy restaurant.\n\nThe host says: “There’s a 30-minute wait. Please leave your number, and we’ll text you when your table is ready.”\n\nYou don’t need to stand at the counter asking every 2 minutes: “Is my table ready yet?”\n\nInstead, you walk away, and when your turn comes, **they notify you automatically**.\n\nThat’s the idea behind webhooks.\n\n[Share](https://blog.algomaster.io/p/what-are-webhooks?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n# 2\\. How Webhooks Work?\n\nAt a high level, webhooks work through **registration, triggering, and delivery**.\n\nLet’s walk through a real example to see what actually happens under the hood.\n\n### Example: GitHub Webhook to Your App\n\nLet’s say you’ve built a system that needs to react when someone opens a pull request (PR) in a GitHub repository — maybe to kick off a CI/CD pipeline, send a Slack notification, or run automated tests.\n\nHere’s how the webhook flow works step-by-step:\n\n#### **Step 1: You Register a Webhook**\n\n- You go to GitHub → Settings → Webhooks\n\n- You provide a **webhook URL** (e.g., `https://myapp.com/github-webhook`)\n\n- You choose the **events** you care about, like `pull_request`, `push`, or `issue_comment`\n\n\nAt this point, GitHub knows where to send data whenever those events occur.\n\n#### **Step 2: GitHub Monitors Events**\n\n- GitHub monitors its internal event stream for your repository\n\n- When someone opens a new pull request, the event gets logged internally\n\n\n#### **Step 3: GitHub Sends a POST Request**\n\n- GitHub prepares a **JSON payload** with details about the event: who opened the PR, which branch, repo metadata, etc.\n\n- It makes a `POST` request to your webhook URL:\n\n[![](https://substackcdn.com/image/fetch/$s_!2UJ1!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcee85f0b-bb88-43d7-9bd8-267236629fe1_480x386.png)](https://substackcdn.com/image/fetch/$s_!2UJ1!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcee85f0b-bb88-43d7-9bd8-267236629fe1_480x386.png)\n\n\n#### **Step 4: Your Server Processes the Event**\n\n- Your app receives the request\n\n- You verify the signature (to ensure it really came from GitHub)\n\n- You process the payload — maybe enqueue it in a job queue, log it, or trigger business logic\n\n- You respond with an HTTP `200 OK` to acknowledge receipt\n\n\n* * *\n\n# 3\\. Anatomy of a Webhook Request\n\nTo integrate with webhooks successfully, you need to understand **what’s actually being sent** to your server when the event occurs.\n\nMost webhook providers use the **HTTP**`POST` **method** to send event data to your server.\n\n- Why POST? Because it allows the payload to be sent in the request body, which can include structured data (usually JSON) describing what happened.\n\n- Rarely, some services allow `GET`, `PUT`, or even `PATCH`, but `POST` is the de facto standard for webhook delivery.\n\n\n### Request Headers\n\nThe headers in a webhook request often include **metadata** and **security-related information**.\n\nCommon headers include:\n\n- **Content-Type:** Usually application/json (or sometimes application/x-www-form-urlencoded)\n\n- **User-Agent:** Identifies the sender (e.g., Stripe/1.0, GitHub-Hookshot)\n\n- **X-Event-Type:** Describes what type of event occurred (payment\\_intent.succeeded, pull\\_request, etc.)\n\n- **X-Signature / X-Hub-Signature:** A hash of the payload using a secret key (HMAC) used to verify the request authenticity\n\n- **X-Request-ID:** Unique ID for the webhook event (useful for logging/debugging)\n\n\n### Request Body\n\nThe body of a webhook request typically contains **event data** in **JSON format**. This data includes what happened, when it happened, and which user/resource it’s related to.\n\n#### Example: GitHub PR Event\n\n```\n{\n  \"action\": \"opened\",\n  \"number\": 42,\n  \"pull_request\": {\n    \"id\": 11223344,\n    \"title\": \"Add login validation\",\n    \"user\": {\n      \"login\": \"octocat\"\n    },\n    \"created_at\": \"2025-04-21T12:00:00Z\"\n  },\n  \"repository\": {\n    \"name\": \"awesome-project\",\n    \"full_name\": \"octocat/awesome-project\"\n  },\n  \"sender\": {\n    \"login\": \"octocat\"\n  }\n}\n```\n\n#### Example: Stripe Payment Intent Succeeded\n\n```\n{\n  \"id\": \"evt_1PoJkD2eZvKYlo2CmOJbvwD9\",\n  \"object\": \"event\",\n  \"api_version\": \"2024-08-01\",\n  \"created\": 1713681701,\n  \"data\": {\n    \"object\": {\n      \"id\": \"pi_3JhdNe2eZvKYlo2C1IqojYg9\",\n      \"object\": \"payment_intent\",\n      \"amount\": 2000,\n      \"currency\": \"usd\",\n      \"status\": \"succeeded\"\n    }\n  },\n  \"livemode\": false,\n  \"type\": \"payment_intent.succeeded\"\n}\n```\n\n* * *\n\n# 4\\. Setting up a Webhook Receiver\n\nOnce you’ve registered your webhook URL with a provider like GitHub or Stripe, the next step is to **build a robust endpoint on your server** that can receive and process these events reliably.\n\nThis sounds simple — just receive a POST request, right?\n\nBut in production, things get tricky:\n\n- Webhooks might arrive **multiple times** or **out of order**\n\n- Your server might be **under load**, or briefly **unavailable**\n\n- **Malicious actors** might try to spoof requests\n\n\nLet’s break down how to setup your webhook receiver the _right_ way.\n\n## 4.1 Basic Setup\n\n#### Create a Dedicated Endpoint\n\nStart by exposing a simple HTTP endpoint like:\n\n```\nPOST /webhook\n```\n\nThis endpoint should:\n\n- Accept only POST requests\n\n- Accept only JSON (via `Content-Type`)\n\n- Be accessible over HTTPS\n\n\n#### Make It Idempotent\n\nWebhook events can be **retried**, **duplicated**, or even **replayed** by providers. Your handler must ensure that processing the same event **multiple times** has no side effects.\n\nHow?\n\n- Every webhook event includes a **unique ID** (e.g., `evt_1234` in Stripe, `delivery_id` in GitHub)\n\n- Store a record of processed IDs in a database or cache\n\n- Before processing, check if the event ID has already been handled\n\n\n```\nif (eventAlreadyProcessed(eventId)) {\n      return 200 OK;\n}\n```\n\n\nThis ensures **exactly-once processing**, even if you receive the same event more than once.\n\n#### Handle HTTP Status Codes Properly\n\n- Return `200 OK` after successful handling\n\n- Return `400 Bad Request` if the payload is invalid or malformed\n\n- Avoid 5xx errors unless something truly failed because most providers **retry** on 5xx\n\n\n## 4.2 Security Considerations\n\nWebhooks are public endpoints. That means **anyone on the internet can POST to them**. You must validate incoming requests.\n\n#### Verify the Signature (HMAC)\n\nMost providers include a **cryptographic signature** of the payload, using a shared secret. This ensures the payload came from the real source.\n\n**Example (Stripe):**\n\n- You configure a webhook secret: `whsec_abc123`\n\n- Stripe signs the payload using HMAC-SHA256\n\n- You verify the signature on your end:\n\n\n```\nString expectedSignature = hmacSha256(secret, payload);\n\nif (!expectedSignature.equals(signatureFromHeader)) {\n      return 403 Forbidden;\n}\n```\n\n\nThis prevents **spoofed or forged webhooks**.\n\n#### Whitelist Source IPs (Optional)\n\nSome providers publish static IP ranges from which webhooks are sent. You can optionally block all other IPs to tighten access.\n\n> Downside: This adds DevOps complexity and can break things if IPs change.\n\n#### Don’t Expose Sensitive Data\n\n- Don’t log full webhook payloads in plaintext\n\n- Don’t return stack traces or internal errors in responses\n\n- Don’t include secrets or tokens in the response body\n\n\n* * *\n\n# 5\\. Designing a Scalable Webhook Infrastructure\n\nAs your application grows and starts receiving thousands or even millions of webhook events daily, a simple synchronous handler won’t be enough.\n\nTo make your webhook system **reliable, fault-tolerant, and scalable**, you need a design that’s **asynchronous, decoupled, and observable**.\n\nLet’s walk through how to build a production-grade webhook processing pipeline.\n\n[![](https://substackcdn.com/image/fetch/$s_!y0on!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbecb9882-d03a-40c1-8849-c389080c5335_2424x1030.png)](https://substackcdn.com/image/fetch/$s_!y0on!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbecb9882-d03a-40c1-8849-c389080c5335_2424x1030.png)\n\n### 5.1 Queue Incoming Requests\n\nDon’t do heavy processing inside your webhook endpoint.\n\nInstead:\n\n- Parse and validate the request\n\n- Verify its authenticity (signature, event ID, etc.)\n\n- Immediately enqueue the event into a **message queue** like:\n\n  - **Kafka** (for high-throughput event pipelines)\n\n  - **RabbitMQ** (lightweight and flexible)\n\n  - **AWS SQS** (serverless and easy to manage)\n\n> This way, your server can return a fast `200 OK`, while actual processing happens in the background.\n\n### 5.2 Store Events for Audit & Replay\n\nTo ensure traceability and recovery, store every incoming event in a database:\n\n- Raw payload\n\n- Event ID and type\n\n- Source info (e.g., IP address, headers)\n\n- Status (`queued`, `processed`, `failed`)\n\n- Timestamps\n\n\nUse a durable data store like PostgreSQL, MongoDB, or DynamoDB.\n\n> This gives you the ability to **replay failed events** and **debug issues**.\n\n### 5.3 Process with Asynchronous Workers\n\nBackground workers (or worker pools) pull events from the queue and perform actual business logic:\n\n- Deduplicate the event using eventID\n\n- Run validations\n\n- Update internal databases or call downstream services\n\n- Trigger notifications or workflows\n\n\n**Why use workers?**\n\n- You can scale them horizontally\n\n- You gain control over load and processing rate\n\n- You isolate failures from the webhook endpoint\n\n\n### 5.4 Retry with Backoff\n\nSometimes, event processing fails temporarily due to a database issue, timeout, or an unavailable downstream API.\n\nYour workers should **retry** those events automatically, using a **backoff strategy**:\n\n- **Exponential** (recommended): retry with increasing delays (1s, 2s, 4s…)\n\n- **Linear**: retry every N seconds (e.g., retry every 30s)\n\n- **Jitter**: add randomness to avoid all retries happening at once\n\n\n> Always limit retries and log failures after the final attempt.\n\n### 5.5 Use a Dead Letter Queue (DLQ)\n\nIf a webhook consistently fails after multiple retries, don’t keep retrying forever.\n\nInstead, send it to a **[Dead Letter Queue](https://aws.amazon.com/what-is/dead-letter-queue/)**, a special holding queue for problematic events.\n\nFrom there, you can:\n\n- Trigger alerts\n\n- Investigate the root cause\n\n- Retry manually after fixing the issue\n\n\n> This prevents bad events from clogging your pipeline and ensures no event is lost silently.\n\n### 5.6 Add Observability: Logs, Metrics & Alerts\n\nYou can’t fix what you can’t see. Add observability at every stage of the pipeline.\n\n**Track metrics like:**\n\n- Total webhook events received per hour\n\n- Success vs. failure rate\n\n- Processing latency\n\n- Queue length\n\n- Retry count and DLQ event count\n\n\n**Set alerts for:**\n\n- Spikes in failure rate\n\n- Sudden drop in incoming events\n\n- Growing queue sizes (indicating backlog)\n\n\n**Popular observability tools:**\n\n- **Prometheus + Grafana** (open-source)\n\n- **Datadog**, **CloudWatch, New Relic** (cloud-based)\n\n- **ELK Stack** (Elasticsearch + Logstash + Kibana)\n\n\n> With proper observability, you’ll catch issues early before they impact your users.\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/what-are-webhooks?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)** and **[X](https://twitter.com/ashishps_1)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![AlexStudent's avatar](https://substackcdn.com/image/fetch/$s_!CSAG!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd8f3c81-3025-4ac9-832f-47863e5c83ac_96x96.png)](https://substack.com/profile/108392520-alexstudent)[![Rahul Saini AI.Collectives's avatar](https://substackcdn.com/image/fetch/$s_!wEdG!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c192654-3838-4599-90b0-62d0eea78684_946x946.jpeg)](https://substack.com/profile/142877952-rahul-saini-aicollectives)[![Dep's avatar](https://substackcdn.com/image/fetch/$s_!Nlbq!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83b44689-c326-4b4d-818a-8c7a1667729a_96x96.jpeg)](https://substack.com/profile/101623444-dep)[![Harsha vardhan reddy Pullela's avatar](https://substackcdn.com/image/fetch/$s_!FpWl!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3de4e9dc-24bd-4463-b3e0-7f252c2e20ab_502x590.jpeg)](https://substack.com/profile/20117765-harsha-vardhan-reddy-pullela)[![Swapnil Srivastava's avatar](https://substackcdn.com/image/fetch/$s_!0miu!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77a635e7-a7b2-4bda-a4f0-1b092875ed0c_144x144.png)](https://substack.com/profile/76399-swapnil-srivastava)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/what-are-webhooks"
    },
    {
      "article_title": "What are Webhooks?",
      "article_title_citation": "https://blog.algomaster.io/p/what-are-webhooks",
      "article_content_markdown": "Imagine you're building an e-commerce platform and using an external payment processor like [Stripe](https://stripe.com/) to collect payments from users.\n\nOnce a user completes a payment, your system needs to:\n\n- Mark the order as paid\n\n- Send an invoice\n\n- Notify the warehouse to start packing\n\n\n**But here's the challenge:**\n\nStripe operates on its own infrastructure. Your system doesn’t control it. So how do you know **instantly** when a payment goes through?\n\nA naive solution would be to keep asking Stripe every few seconds:\n\n[![](https://substackcdn.com/image/fetch/$s_!dx3C!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb2de1743-d3ec-4f12-bd3c-e7e348239d6a_1184x988.png)](https://substackcdn.com/image/fetch/$s_!dx3C!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb2de1743-d3ec-4f12-bd3c-e7e348239d6a_1184x988.png)\n\nThis is known as **polling**.\n\nNow imagine doing this for **every order** on a site like Amazon.\n\nIt just doesn’t scale and wastes server resources.\n\nInstead of your app repeatedly asking, **what if Stripe could just tell you** when the payment succeeds?\n\nThat’s what **webhooks** do.\n\nIn this article, we will explore:\n\n- What is a Webhook?\n\n- How Webhooks Work?\n\n- What does a Webhook request look like?\n\n- How to setup a Webhook receiver?\n\n- How to design a scalable Webhook infrastructure?\n\n\n* * *\n\n# 1\\. What is a Webhook?\n\n> A webhook is a simple way for one system (provider) to notify another system (receiver) in real time when an event happens using an HTTP request.\n\n[![](https://substackcdn.com/image/fetch/$s_!owua!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F15601152-796b-4599-9e78-cb4836da43c3_1644x930.png)](https://substackcdn.com/image/fetch/$s_!owua!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F15601152-796b-4599-9e78-cb4836da43c3_1644x930.png)\n\nInstead of one system asking repeatedly if something happened, the other system simply pushes the data as soon as the event is triggered.\n\n#### Real-World Analogy\n\nLet’s say you go to a busy restaurant.\n\nThe host says: “There’s a 30-minute wait. Please leave your number, and we’ll text you when your table is ready.”\n\nYou don’t need to stand at the counter asking every 2 minutes: “Is my table ready yet?”\n\nInstead, you walk away, and when your turn comes, **they notify you automatically**.\n\nThat’s the idea behind webhooks.\n\n[Share](https://blog.algomaster.io/p/what-are-webhooks?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n# 2\\. How Webhooks Work?\n\nAt a high level, webhooks work through **registration, triggering, and delivery**.\n\nLet’s walk through a real example to see what actually happens under the hood.\n\n### Example: GitHub Webhook to Your App\n\nLet’s say you’ve built a system that needs to react when someone opens a pull request (PR) in a GitHub repository — maybe to kick off a CI/CD pipeline, send a Slack notification, or run automated tests.\n\nHere’s how the webhook flow works step-by-step:\n\n#### **Step 1: You Register a Webhook**\n\n- You go to GitHub → Settings → Webhooks\n\n- You provide a **webhook URL** (e.g., `https://myapp.com/github-webhook`)\n\n- You choose the **events** you care about, like `pull_request`, `push`, or `issue_comment`\n\n\nAt this point, GitHub knows where to send data whenever those events occur.\n\n#### **Step 2: GitHub Monitors Events**\n\n- GitHub monitors its internal event stream for your repository\n\n- When someone opens a new pull request, the event gets logged internally\n\n\n#### **Step 3: GitHub Sends a POST Request**\n\n- GitHub prepares a **JSON payload** with details about the event: who opened the PR, which branch, repo metadata, etc.\n\n- It makes a `POST` request to your webhook URL:\n\n[![](https://substackcdn.com/image/fetch/$s_!2UJ1!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcee85f0b-bb88-43d7-9bd8-267236629fe1_480x386.png)](https://substackcdn.com/image/fetch/$s_!2UJ1!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcee85f0b-bb88-43d7-9bd8-267236629fe1_480x386.png)\n\n\n#### **Step 4: Your Server Processes the Event**\n\n- Your app receives the request\n\n- You verify the signature (to ensure it really came from GitHub)\n\n- You process the payload — maybe enqueue it in a job queue, log it, or trigger business logic\n\n- You respond with an HTTP `200 OK` to acknowledge receipt\n\n\n* * *\n\n# 3\\. Anatomy of a Webhook Request\n\nTo integrate with webhooks successfully, you need to understand **what’s actually being sent** to your server when the event occurs.\n\nMost webhook providers use the **HTTP**`POST` **method** to send event data to your server.\n\n- Why POST? Because it allows the payload to be sent in the request body, which can include structured data (usually JSON) describing what happened.\n\n- Rarely, some services allow `GET`, `PUT`, or even `PATCH`, but `POST` is the de facto standard for webhook delivery.\n\n\n### Request Headers\n\nThe headers in a webhook request often include **metadata** and **security-related information**.\n\nCommon headers include:\n\n- **Content-Type:** Usually application/json (or sometimes application/x-www-form-urlencoded)\n\n- **User-Agent:** Identifies the sender (e.g., Stripe/1.0, GitHub-Hookshot)\n\n- **X-Event-Type:** Describes what type of event occurred (payment\\_intent.succeeded, pull\\_request, etc.)\n\n- **X-Signature / X-Hub-Signature:** A hash of the payload using a secret key (HMAC) used to verify the request authenticity\n\n- **X-Request-ID:** Unique ID for the webhook event (useful for logging/debugging)\n\n\n### Request Body\n\nThe body of a webhook request typically contains **event data** in **JSON format**. This data includes what happened, when it happened, and which user/resource it’s related to.\n\n#### Example: GitHub PR Event\n\n```\n{\n  \"action\": \"opened\",\n  \"number\": 42,\n  \"pull_request\": {\n    \"id\": 11223344,\n    \"title\": \"Add login validation\",\n    \"user\": {\n      \"login\": \"octocat\"\n    },\n    \"created_at\": \"2025-04-21T12:00:00Z\"\n  },\n  \"repository\": {\n    \"name\": \"awesome-project\",\n    \"full_name\": \"octocat/awesome-project\"\n  },\n  \"sender\": {\n    \"login\": \"octocat\"\n  }\n}\n```\n\n#### Example: Stripe Payment Intent Succeeded\n\n```\n{\n  \"id\": \"evt_1PoJkD2eZvKYlo2CmOJbvwD9\",\n  \"object\": \"event\",\n  \"api_version\": \"2024-08-01\",\n  \"created\": 1713681701,\n  \"data\": {\n    \"object\": {\n      \"id\": \"pi_3JhdNe2eZvKYlo2C1IqojYg9\",\n      \"object\": \"payment_intent\",\n      \"amount\": 2000,\n      \"currency\": \"usd\",\n      \"status\": \"succeeded\"\n    }\n  },\n  \"livemode\": false,\n  \"type\": \"payment_intent.succeeded\"\n}\n```\n\n* * *\n\n# 4\\. Setting up a Webhook Receiver\n\nOnce you’ve registered your webhook URL with a provider like GitHub or Stripe, the next step is to **build a robust endpoint on your server** that can receive and process these events reliably.\n\nThis sounds simple — just receive a POST request, right?\n\nBut in production, things get tricky:\n\n- Webhooks might arrive **multiple times** or **out of order**\n\n- Your server might be **under load**, or briefly **unavailable**\n\n- **Malicious actors** might try to spoof requests\n\n\nLet’s break down how to setup your webhook receiver the _right_ way.\n\n## 4.1 Basic Setup\n\n#### Create a Dedicated Endpoint\n\nStart by exposing a simple HTTP endpoint like:\n\n```\nPOST /webhook\n```\n\nThis endpoint should:\n\n- Accept only POST requests\n\n- Accept only JSON (via `Content-Type`)\n\n- Be accessible over HTTPS\n\n\n#### Make It Idempotent\n\nWebhook events can be **retried**, **duplicated**, or even **replayed** by providers. Your handler must ensure that processing the same event **multiple times** has no side effects.\n\nHow?\n\n- Every webhook event includes a **unique ID** (e.g., `evt_1234` in Stripe, `delivery_id` in GitHub)\n\n- Store a record of processed IDs in a database or cache\n\n- Before processing, check if the event ID has already been handled\n\n\n```\nif (eventAlreadyProcessed(eventId)) {\n      return 200 OK;\n}\n```\n\n\nThis ensures **exactly-once processing**, even if you receive the same event more than once.\n\n#### Handle HTTP Status Codes Properly\n\n- Return `200 OK` after successful handling\n\n- Return `400 Bad Request` if the payload is invalid or malformed\n\n- Avoid 5xx errors unless something truly failed because most providers **retry** on 5xx\n\n\n## 4.2 Security Considerations\n\nWebhooks are public endpoints. That means **anyone on the internet can POST to them**. You must validate incoming requests.\n\n#### Verify the Signature (HMAC)\n\nMost providers include a **cryptographic signature** of the payload, using a shared secret. This ensures the payload came from the real source.\n\n**Example (Stripe):**\n\n- You configure a webhook secret: `whsec_abc123`\n\n- Stripe signs the payload using HMAC-SHA256\n\n- You verify the signature on your end:\n\n\n```\nString expectedSignature = hmacSha256(secret, payload);\n\nif (!expectedSignature.equals(signatureFromHeader)) {\n      return 403 Forbidden;\n}\n```\n\n\nThis prevents **spoofed or forged webhooks**.\n\n#### Whitelist Source IPs (Optional)\n\nSome providers publish static IP ranges from which webhooks are sent. You can optionally block all other IPs to tighten access.\n\n> Downside: This adds DevOps complexity and can break things if IPs change.\n\n#### Don’t Expose Sensitive Data\n\n- Don’t log full webhook payloads in plaintext\n\n- Don’t return stack traces or internal errors in responses\n\n- Don’t include secrets or tokens in the response body\n\n\n* * *\n\n# 5\\. Designing a Scalable Webhook Infrastructure\n\nAs your application grows and starts receiving thousands or even millions of webhook events daily, a simple synchronous handler won’t be enough.\n\nTo make your webhook system **reliable, fault-tolerant, and scalable**, you need a design that’s **asynchronous, decoupled, and observable**.\n\nLet’s walk through how to build a production-grade webhook processing pipeline.\n\n[![](https://substackcdn.com/image/fetch/$s_!y0on!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbecb9882-d03a-40c1-8849-c389080c5335_2424x1030.png)](https://substackcdn.com/image/fetch/$s_!y0on!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbecb9882-d03a-40c1-8849-c389080c5335_2424x1030.png)\n\n### 5.1 Queue Incoming Requests\n\nDon’t do heavy processing inside your webhook endpoint.\n\nInstead:\n\n- Parse and validate the request\n\n- Verify its authenticity (signature, event ID, etc.)\n\n- Immediately enqueue the event into a **message queue** like:\n\n  - **Kafka** (for high-throughput event pipelines)\n\n  - **RabbitMQ** (lightweight and flexible)\n\n  - **AWS SQS** (serverless and easy to manage)\n\n> This way, your server can return a fast `200 OK`, while actual processing happens in the background.\n\n### 5.2 Store Events for Audit & Replay\n\nTo ensure traceability and recovery, store every incoming event in a database:\n\n- Raw payload\n\n- Event ID and type\n\n- Source info (e.g., IP address, headers)\n\n- Status (`queued`, `processed`, `failed`)\n\n- Timestamps\n\n\nUse a durable data store like PostgreSQL, MongoDB, or DynamoDB.\n\n> This gives you the ability to **replay failed events** and **debug issues**.\n\n### 5.3 Process with Asynchronous Workers\n\nBackground workers (or worker pools) pull events from the queue and perform actual business logic:\n\n- Deduplicate the event using eventID\n\n- Run validations\n\n- Update internal databases or call downstream services\n\n- Trigger notifications or workflows\n\n\n**Why use workers?**\n\n- You can scale them horizontally\n\n- You gain control over load and processing rate\n\n- You isolate failures from the webhook endpoint\n\n\n### 5.4 Retry with Backoff\n\nSometimes, event processing fails temporarily due to a database issue, timeout, or an unavailable downstream API.\n\nYour workers should **retry** those events automatically, using a **backoff strategy**:\n\n- **Exponential** (recommended): retry with increasing delays (1s, 2s, 4s…)\n\n- **Linear**: retry every N seconds (e.g., retry every 30s)\n\n- **Jitter**: add randomness to avoid all retries happening at once\n\n\n> Always limit retries and log failures after the final attempt.\n\n### 5.5 Use a Dead Letter Queue (DLQ)\n\nIf a webhook consistently fails after multiple retries, don’t keep retrying forever.\n\nInstead, send it to a **[Dead Letter Queue](https://aws.amazon.com/what-is/dead-letter-queue/)**, a special holding queue for problematic events.\n\nFrom there, you can:\n\n- Trigger alerts\n\n- Investigate the root cause\n\n- Retry manually after fixing the issue\n\n\n> This prevents bad events from clogging your pipeline and ensures no event is lost silently.\n\n### 5.6 Add Observability: Logs, Metrics & Alerts\n\nYou can’t fix what you can’t see. Add observability at every stage of the pipeline.\n\n**Track metrics like:**\n\n- Total webhook events received per hour\n\n- Success vs. failure rate\n\n- Processing latency\n\n- Queue length\n\n- Retry count and DLQ event count\n\n\n**Set alerts for:**\n\n- Spikes in failure rate\n\n- Sudden drop in incoming events\n\n- Growing queue sizes (indicating backlog)\n\n\n**Popular observability tools:**\n\n- **Prometheus + Grafana** (open-source)\n\n- **Datadog**, **CloudWatch, New Relic** (cloud-based)\n\n- **ELK Stack** (Elasticsearch + Logstash + Kibana)\n\n\n> With proper observability, you’ll catch issues early before they impact your users.\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/what-are-webhooks?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)** and **[X](https://twitter.com/ashishps_1)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![AlexStudent's avatar](https://substackcdn.com/image/fetch/$s_!CSAG!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd8f3c81-3025-4ac9-832f-47863e5c83ac_96x96.png)](https://substack.com/profile/108392520-alexstudent)[![Rahul Saini AI.Collectives's avatar](https://substackcdn.com/image/fetch/$s_!wEdG!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c192654-3838-4599-90b0-62d0eea78684_946x946.jpeg)](https://substack.com/profile/142877952-rahul-saini-aicollectives)[![Dep's avatar](https://substackcdn.com/image/fetch/$s_!Nlbq!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83b44689-c326-4b4d-818a-8c7a1667729a_96x96.jpeg)](https://substack.com/profile/101623444-dep)[![Harsha vardhan reddy Pullela's avatar](https://substackcdn.com/image/fetch/$s_!FpWl!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3de4e9dc-24bd-4463-b3e0-7f252c2e20ab_502x590.jpeg)](https://substack.com/profile/20117765-harsha-vardhan-reddy-pullela)[![Swapnil Srivastava's avatar](https://substackcdn.com/image/fetch/$s_!0miu!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77a635e7-a7b2-4bda-a4f0-1b092875ed0c_144x144.png)](https://substack.com/profile/76399-swapnil-srivastava)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/what-are-webhooks"
    },
    {
      "article_title": "REST vs GraphQL",
      "article_title_citation": "https://blog.algomaster.io/p/rest-vs-graphql",
      "article_content_markdown": "**APIs** are the backbone of modern applications, acting as the bridge between **client applications and backend servers**.\n\nAmong the many API design choices, **REST** and **GraphQL** have emerged as two dominant approaches.\n\nBoth offer powerful ways to retrieve and manipulate data, but they are built on fundamentally different philosophies.\n\n[![](https://substackcdn.com/image/fetch/$s_!cEwV!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d86506-cb5f-4c9f-a56a-257439ec46eb_1666x1210.png)](https://substackcdn.com/image/fetch/$s_!cEwV!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d86506-cb5f-4c9f-a56a-257439ec46eb_1666x1210.png)\n\nREST, a time-tested architectural style, structures APIs around **fixed endpoints and HTTP methods**, making it intuitive and widely adopted.\n\nOn the other hand, GraphQL, a newer query language developed by Facebook, takes a more **flexible and efficient approach**, allowing clients to request exactly the data they need in a single request.\n\nIn this article, we’ll break down REST and GraphQL, compare their differences, and help you decide which one is best suited for your use case.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n# 1\\. What is REST?\n\n**REST** emerged in the early 2000s as a set of architectural principles for designing networked applications.\n\nREST is not a protocol or standard but rather a **set of guiding principles** that leverage the existing **HTTP protocol** to enable communication between clients and servers.\n\nAt its core, REST is built around **resources**. Each resource (such as a user, order, or product) is uniquely identified by a **URL (** Uniform Resource Locator **)**, and clients interact with these resources using a **fixed set of HTTP methods**.\n\n- **GET** → Retrieve a resource (e.g., `GET /api/users/123` to fetch user data).\n\n- **POST** → Create a new resource (e.g., `POST /api/users` to add a new user).\n\n- **PUT/PATCH** → Update an existing resource (e.g., `PUT /api/users/123` to update user details).\n\n- **DELETE** → Remove a resource (e.g., `DELETE /api/users/123` to delete a user).\n\n\nFor example, let’s say a client needs information about a specific user with **ID 123**.\n\n[![](https://substackcdn.com/image/fetch/$s_!HBtO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c704568-18c9-48e5-ba45-f8e6e1e25a6b_1554x896.png)](https://substackcdn.com/image/fetch/$s_!HBtO!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c704568-18c9-48e5-ba45-f8e6e1e25a6b_1554x896.png)\n\n- The client makes a request\n\n- The server responds with a JSON representation of the user\n\n\nREST APIs typically **return data in JSON** and use **HTTP status codes** to communicate the outcome of the request:\n\n- **200 OK** → Success\n\n- **201 Created** → Resource successfully created\n\n- **400 Bad Request** → Client error (e.g., missing required fields)\n\n- **404 Not Found** → Requested resource does not exist\n\n- **500 Internal Server Error** → Unexpected server issue\n\n\n### Benefits of REST\n\n- **Simplicity and Intuitive Design**: The resource-based model aligns well with most business domains, making REST intuitive for developers.\n\n- **Statelessness**: Each request contains all the information needed to complete it, making REST scalable across distributed systems.\n\n- **Cacheability**: HTTP's caching mechanisms can be leveraged to improve performance.\n\n- **Scalability:** REST APIs can be easily scaled using load balancers and CDNs.\n\n- **Mature Ecosystem**: With nearly two decades of widespread use, REST enjoys robust tooling, documentation, and developer familiarity.\n\n\n### **Drawbacks** of REST\n\n- **Over-fetching:** REST endpoints often return **more data than needed**, leading to inefficient network usage. For example, if a mobile app only needs a user’s name and email, but the API response includes additional fields like address, phone number, and metadata, it results in **wasted bandwidth**.\n\n- **Under-fetching**: If an API doesn’t return related data, the client may need to **make multiple requests** to retrieve all required information. For example, to get user details and their posts, a client might have to make:\n\n1. `GET /api/users/123` (fetch user)\n\n2. `GET /api/users/123/posts` (fetch user’s posts)\n- **Versioning issues**: When APIs evolve, maintaining backward compatibility becomes difficult. REST APIs often require **versioned URLs** (`/v1/users`, `/v2/users`), adding maintenance overhead.\n\n- **Rigid Response Structure:** The server defines how data is returned, and clients must adapt to it—even if they only need a subset of the data.\n\n\n[Share](https://blog.algomaster.io/p/rest-vs-graphql?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n# 2\\. What is GraphQL?\n\nFor years, **REST** was the de facto standard for building APIs. However, as applications grew more complex, REST began to show limitations—especially in scenarios where clients needed fine-grained control over the data they fetched.\n\nTo address these challenges, **Facebook introduced GraphQL in 2015**, offering a more flexible and efficient approach to data retrieval.\n\n### **How GraphQL Works**\n\nUnlike REST, which organizes APIs around **fixed endpoints and HTTP methods**, GraphQL is a **query language** that allows clients to request exactly the data they need—nothing more, nothing less.\n\n> A **single GraphQL endpoint** (`/graphql`) replaces multiple REST endpoints, allowing clients to structure their own queries instead of relying on predefined responses.\n\n#### **Example:**\n\n[![](https://substackcdn.com/image/fetch/$s_!s0a7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b40446b-9156-4e7f-9107-654235bb1e53_2138x1806.png)](https://substackcdn.com/image/fetch/$s_!s0a7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b40446b-9156-4e7f-9107-654235bb1e53_2138x1806.png)\n\nHere, the query asks for a **specific user's firstName, email, profileUrl and posts**, all within a **single request.**\n\nGraphQL aggregates the data from multiple services and returns precisely the requested data.\n\nIt solves the problems of **over-fetching** (getting unnecessary data) and **under-fetching** (requiring multiple requests to retrieve related data).\n\nUnlike REST, where API responses are **loosely structured** and may vary across versions, **GraphQL enforces a strict schema** that defines the shape of the data.\n\nA simple GraphQL schema for the above example might look like this:\n\n```\ntype User {\n  id: ID!\n  firstName: String!\n  lastName: String!\n  email: String!\n  profile: Profile!\n  posts: [Post!]\n}\n\ntype Profile {\n  id: ID!\n  url: String!\n}\n\ntype Post {\n  id: ID!\n  title: String!\n  publishedDate: String!\n  content: String!\n  author: User!\n}\n\ntype Query {\n  user(id: ID!): User\n  posts: [Post!]!\n}\n```\n\n### Three Core Functionalities of GraphQL\n\nGraphQL provides three core functionalities:\n\n#### 1\\. Queries → Fetch Data\n\nSimilar to GET requests in REST, GraphQL queries allow clients to request specific fields of data.\n\nClients have full control over what they retrieve, avoiding unnecessary data fetching.\n\n**Example: Fetching specific user and post details in a single request**\n\n```\nquery {\n  user(id: 123) {\n    name\n    email\n    posts {\n      title\n      content\n    }\n  }\n}\n```\n\n#### 2\\. **Mutations** → Modify Data\n\nEquivalent to **POST, PUT, PATCH, or DELETE** in REST. Used to **create, update, or delete** resources in the API.\n\n**Example: Creating a new post**\n\n```\nmutation {\n  createPost(title: \"GraphQL vs REST\", content: \"GraphQL solves many of REST's limitations...\", publishedDate: \"2025-03-10\") {\n    id\n    title\n    content\n  }\n}\n```\n\nThe response will contain the newly created post with its **ID, title, and content**.\n\n#### 3\\. **Subscriptions** → Real-Time Updates\n\nUnlike REST, which requires polling or WebSockets for real-time updates, GraphQL subscriptions enable clients to listen for changes and receive updates automatically when data is modified.\n\nIdeal for chat applications, live feeds, stock market updates, and notifications.\n\n**Example: Listening for new posts**\n\n```\nsubscription {\n  newPost {\n    title\n    content\n    author {\n      name\n    }\n  }\n}\n```\n\nWhenever a **new post is created**, all subscribed clients will **receive instant updates**.\n\n### **How GraphQL Differs from REST**\n\nBoth GraphQL and REST rely on **HTTP requests and responses**, but they differ in how they structure and deliver data.\n\n- REST centers around resources (each identified by a URL).\n\n- GraphQL centers around a schema that defines the types of data available.\n\n\nIn REST, the **API implementer** decides which data is included in a response. If a client requests a blog post, the API might also return related **author details**, even if they aren’t needed.\n\nWith GraphQL, the **client decides** what to fetch. This makes GraphQL more flexible but also introduces challenges in **caching and performance optimization**.\n\n### Benefits of GraphQL\n\n1. **Precise Data Fetching**: Clients can request only the fields they need, reducing over-fetching and under-fetching.\n\n2. **Single Request for Multiple Resources**: Related data can be retrieved in one request, solving REST’s `n+1` query problem.\n\n3. **Strong Typing**: GraphQL APIs use a schema to define available data, making them easier to explore and document.\n\n4. **Real-time Data with Subscriptions:** GraphQL natively supports real-time data updates through subscriptions, enabling clients to receive automatic notifications whenever data changes on the server.\n\n5. **API Evolution Without Versioning**: New fields can be added without breaking existing queries, avoiding REST-style `/v1`, `/v2` versioning issues.\n\n\n### Drawbacks of GraphQL\n\n1. **Complex Setup & Tooling**: Unlike REST, which can be used with basic HTTP clients (cURL, browsers), GraphQL requires a GraphQL server, schema, and resolvers.\n\n2. **Caching challenges**: REST APIs leverage HTTP caching (e.g., browser caching, CDNs), but GraphQL queries use POST requests, making caching trickier.\n\n3. **Increased Server Load:** Since clients can request arbitrary amounts of data, GraphQL APIs must be carefully optimized to prevent performance issues.\n\n4. **Security Risks:** Unoptimized queries (e.g., deeply nested requests) can lead to costly database scans, increasing the risk of denial-of-service (DoS) attacks.\n\n\n### Performance Risks with GraphQL\n\nImagine a mobile app introduces a **new feature** that unexpectedly triggers a **full table scan** on a critical database table.\n\nWith REST, this scenario is less likely because API endpoints are predefined, and developers control how data is exposed.\n\nWith GraphQL, the client **constructs the query**, which could inadvertently request massive amounts of data. If a poorly designed query is executed on a high-traffic service, it could **bring down the entire database**.\n\nTo mitigate this, GraphQL APIs require **strict query rate limiting, depth restrictions, and cost analysis mechanisms**—adding additional complexity to the implementation.\n\n* * *\n\n# 3\\. Which One Should You Pick?\n\nThere is no **one-size-fits-all** answer. **REST** remains a great choice for simple APIs, while **GraphQL** is powerful for complex applications with varying data needs.\n\nUltimately, it’s not about which is better, but which is better for your specific needs.\n\nHere’s a quick guide:\n\n#### Use **REST** if:\n\n- Your API is simple and doesn’t require flexible queries.\n\n- You need caching benefits from HTTP.\n\n- You need a standardized, well-established API approach.\n\n- You’re integrating with third-party services.\n\n- Your team is already familiar with REST and need faster implementation.\n\n\n#### Use **GraphQL** if:\n\n- You need flexible and efficient data fetching.\n\n- Your API serves multiple clients (mobile, web, IoT) with different data needs.\n\n- Real-time updates are required (GraphQL subscriptions).\n\n- You want to avoid API versioning issues.\n\n- Your application requires deeply nested data\n\n\n#### **Can You Use Both REST and GraphQL?**\n\nAbsolutely! REST and GraphQL are **not mutually exclusive**, and many organizations implement a **hybrid approach** to get the best of both worlds:\n\n- GraphQL for client-facing applications where flexibility, performance, and dynamic querying are essential.\n\n- REST for admin interfaces, third-party integrations, and internal microservices where statelessness, caching, and simplicity are beneficial.\n\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/rest-vs-graphql?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)** and **[X](https://twitter.com/ashishps_1)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![Anirudh's avatar](https://substackcdn.com/image/fetch/$s_!hULw!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc61da395-4905-4402-a6ea-c26bbec32e2d_144x144.png)](https://substack.com/profile/109312186-anirudh)[![pratik thorve's avatar](https://substackcdn.com/image/fetch/$s_!8hvf!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a4d4546-58cc-4194-b13c-acd6dd8e2ffc_96x96.jpeg)](https://substack.com/profile/43234375-pratik-thorve)[![TÉJAS's avatar](https://substackcdn.com/image/fetch/$s_!Vg-i!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bab1b2d-bf7d-44c0-a27f-8304a72fa293_96x96.jpeg)](https://substack.com/profile/230693113-tejas)[![Josphat Mwania's avatar](https://substackcdn.com/image/fetch/$s_!3Cn7!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe2614c66-ad57-4f68-a0b2-75704d9a62d4_144x144.png)](https://substack.com/profile/133094877-josphat-mwania)[![shaun's avatar](https://substackcdn.com/image/fetch/$s_!MTg9!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8f2d938-5bb0-4478-b7be-8bcfcadcc473_1280x1282.jpeg)](https://substack.com/profile/110988704-shaun)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/rest-vs-graphql"
    },
    {
      "article_title": "What is an API Gateway?",
      "article_title_citation": "https://blog.algomaster.io/p/what-is-an-api-gateway",
      "article_content_markdown": "**APIs**, or **Application Programming Interfaces**, are a set of rules and protocols that allows two software applications or services to communicate with each other.\n\nAs applications grow in size, the number of APIs increases too. Without the right tools and infrastructure, managing these APIs can quickly become a challenge.\n\nThis is where **API Gateway** comes into play.\n\n> An API Gateway acts as a **central server** that sits between clients (e.g., browsers, mobile apps) and backend services.\n\nInstead of clients interacting with multiple microservices directly, they send their requests to the API Gateway. The gateway processes these requests, enforces security, and forwards them to the appropriate microservices.\n\nIn this article, we will explore why do we need an API gateway, the key features it provides and how it works step by step.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n## 1\\. Why Do We Need an API Gateway?\n\nModern applications, especially those built using microservices architecture, have multiple backend services managing different functionalities.\n\nFor example, in an e-commerce service:\n\n- One service handles **user accounts**.\n\n- Another handles **payments**.\n\n- Another manages **product inventory**.\n\n\n#### **Without an API Gateway:**\n\n[![](https://substackcdn.com/image/fetch/$s_!Yp-h!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6da835a-257c-4247-a4b9-d7297c289fce_1044x718.png)](https://substackcdn.com/image/fetch/$s_!Yp-h!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6da835a-257c-4247-a4b9-d7297c289fce_1044x718.png)\n\n- Clients would need to know the location and details of all backend services.\n\n- Developers would need to manage authentication, rate limiting, and security for each service individually.\n\n\n#### **With an API Gateway:**\n\n[![](https://substackcdn.com/image/fetch/$s_!_CtQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e41325f-2b6b-4f2a-8ca6-d622413ad64c_1692x720.png)](https://substackcdn.com/image/fetch/$s_!_CtQ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e41325f-2b6b-4f2a-8ca6-d622413ad64c_1692x720.png)\n\n- Clients send all requests to one place – the API Gateway.\n\n- The API Gateway takes care of routing, authentication, security, and other operational tasks, simplifying both client interactions and backend management.\n\n\n## 2\\. Core Features of an API Gateway\n\n[![](https://substackcdn.com/image/fetch/$s_!_ZNj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb0c8192-4b1b-4834-b068-20d8cfb65050_1856x1412.png)](https://substackcdn.com/image/fetch/$s_!_ZNj!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb0c8192-4b1b-4834-b068-20d8cfb65050_1856x1412.png)\n\n#### 1\\. **Authentication and Authorization**\n\nAPI Gateway secures the backend systems by ensuring only authorized users and clients can access backend services.\n\nIt handles tasks like:\n\n- **Authentication:** Verifying the identity of the client using tokens (e.g., OAuth, JWT), API keys, or certificates.\n\n- **Authorization:** Checking the client’s permissions to access specific services or resources.\n\n\nBy centralizing these tasks, the API gateway eliminates the need for individual services to handle authentication, reducing redundancy and ensuring consistent access control across the system.\n\n#### 2\\. **Rate Limiting**\n\nTo prevent abuse and ensure fair usage of resources, most API Gateways implement **rate limiting**.\n\nThis feature:\n\n- Controls the frequency of requests a client can make within a given timeframe.\n\n- Protects backend services from being overwhelmed by excessive traffic or potential denial-of-service (DoS) attacks.\n\n\n> For example, a public API might allow a maximum of 100 requests per minute per user. If a client exceeds this limit, the API Gateway will block additional requests until the rate resets.\n\n#### 3\\. **Load Balancing**\n\nHigh-traffic applications rely on **load balancing** to distribute incoming requests evenly across multiple instances of a service.\n\nThe API Gateway can:\n\n- Redirect requests to healthy service instances while avoiding ones that are down or overloaded.\n\n- Use algorithms like round-robin, least connections, or weighted distribution to manage traffic intelligently.\n\n\n#### 4\\. **Caching**\n\nTo improve response times and reduce the strain on backend services, most API Gateways provide **caching**.\n\nThey temporarily store frequently requested data, such as:\n\n- Responses to commonly accessed endpoints (e.g., product catalogs or weather data).\n\n- Static resources like images or metadata.\n\n\n> Caching helps in reducing latency and enhancing user experience while lowering the operational cost of backend services.\n\n#### 5\\. **Request Transformation**\n\nIn systems with diverse clients and backend services, **request transformation** is essential for compatibility.\n\nAn API Gateway can:\n\n- Modify the structure or format of incoming requests to match the backend service requirements.\n\n- Transform responses before sending them back to the client, ensuring they meet the client’s expectations.\n\n\n> For instance, it might convert XML responses from a legacy service into JSON for modern frontend applications.\n\n#### 6\\. **Service Discovery**\n\nModern systems often involve microservices that scale dynamically.\n\nThe **service discovery** feature of an API Gateway dynamically identifies the appropriate backend service instance to handle each request.\n\nThis ensures seamless request routing even in environments where services frequently scale up or down.\n\n#### 7\\. **Circuit Breaking**\n\nCircuit breaking is a mechanism that temporarily stops sending requests to a backend service when it detects persistent failures, such as:\n\n- Slow responses or timeouts.\n\n- Server errors (e.g., HTTP 500 status codes).\n\n- High latency or unavailability of a service.\n\n\nThe API Gateway continuously monitors the health and performance of backend services and uses circuit breaking to block requests to a failing service.\n\n#### 8\\. **Logging and Monitoring**\n\nAPI Gateways provide robust **monitoring and logging** capabilities to track and analyze system behavior.\n\nThese capabilities include:\n\n- Logging detailed information about each request, such as source, destination, and response time.\n\n- Collecting metrics like request rates, error rates, and latency.\n\n\nThis data helps system administrators detect anomalies, troubleshoot issues, and optimize the system’s performance. Many API Gateways also integrate with monitoring tools like Prometheus, Grafana, or AWS CloudWatch.\n\n[Share](https://blog.algomaster.io/p/what-is-an-api-gateway?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n## **3\\. How Does an API Gateway Work?**\n\nImagine you're using a food delivery app to order dinner. When you tap \"Place Order\" your phone makes an API request. But instead of talking directly to various backend services, it communicates with an API Gateway first.\n\n#### **Step 1: Request Reception**\n\nWhen you tap \"Place Order,\" the app sends a request to the **API Gateway**, asking it to process your order.\n\nThis request includes things like:\n\n- Your user ID\n\n- Selected restaurant and menu items\n\n- Delivery address\n\n- Payment method\n\n- Authentication tokens\n\n\nThe API Gateway receives the request as the single entry point to the backend system.\n\n#### **Step 2: Request Validation**\n\nBefore forwarding the request, the API Gateway validates it to ensure:\n\n- The required parameters or headers are present.\n\n- The data is in the correct format (e.g., JSON).\n\n- The request conforms to the expected structure or schema.\n\n\n```\n// Example of initial request handling\napp.post('/api/v1/orders', async (req, res) => {\n  // Check if request has required headers\n  if (!req.headers['content-type'].includes('application/json')) {\n    return res.status(400).send('Invalid content type');\n  }\n  // Continue processing...\n});\n```\n\nIf any information is missing or incorrect, the gateway immediately rejects the request and notifies the app with an appropriate error message.\n\n#### **Step 3: Authentication & Authorization**\n\nThe gateway now verifies your identity and permissions to ensures only legitimate users can place orders:\n\n- It forwards your authentication token (e.g., OAuth or JWT) to an identity provider to confirm your identity.\n\n- It checks your permissions to ensure you’re authorized to use the app for placing an order.\n\n\n```\nconst authenticateRequest = async (req) => {\n  // Extract JWT token from header\n  const token = req.headers.authorization?.split(' ')[1];\n\n  // Verify token and get user details\n  const user = await verifyToken(token);\n\n  // Check if user has permission to place orders\n  return user.permissions.includes('place_orders');\n};\n```\n\nIf authentication or authorization fails, the API Gateway sends a `401 Unauthorized` or `403 Forbidden` error back to the app.\n\n#### **Step 4: Rate Limiting**\n\nTo prevent abuse, the API Gateway checks how many requests you’ve made recently. For example:\n\n- If you’ve made 10 \"Place Order\" requests in the last minute (maybe by accident), the gateway might block additional requests temporarily and return `429 Too Many Requests` response.\n\n\n```\nconst checkRateLimit = async (userId) => {\n  const key = `rate_limit:order:${userId}`;\n  const current = await redis.incr(key);\n\n  // If first request in window, set expiry\n  if (current === 1) {\n    await redis.expire(key, 60); // 1 minute window\n  }\n\n  return current <= 10; // Allow 10 order requests per minute\n};\n```\n\nThis ensures the system remains stable and fair for all users specially during traffic spikes or malicious attacks, such as distributed denial-of-service (DDoS) attempts.\n\n#### **Step 5: Request Transformation (if needed)**\n\nIf any of these backend services require specific data formats or additional details, the API Gateway transforms the request.\n\nFor example:\n\n- The app sends the delivery address in plain text, but the Delivery Service expects GPS coordinates. The API Gateway converts the address into coordinates before forwarding the request.\n\n\n```\nconst transformRequest = async (originalRequest) => {\n  const address = originalRequest.deliveryAddress;\n\n  // Convert address to GPS coordinates using a geocoding API\n  const coordinates = await getCoordinatesFromAddress(address);\n\n  if (!coordinates) {\n    throw new Error('Failed to fetch GPS coordinates');\n  }\n\n  // Transform the request for the Delivery Service\n  return {\n    orderId: originalRequest.orderId,\n    customerName: originalRequest.customerName,\n    deliveryLocation: {\n      latitude: coordinates.lat,\n      longitude: coordinates.lng\n    },\n    deliveryInstructions: originalRequest.instructions || \"\"\n  };\n};\n```\n\n#### Step 6: Request Routing\n\nThe API Gateway now needs to coordinate several backend services to process your order.\n\nUsing **service discovery**, it identifies:\n\n- **Order Service:** To create a new order record.\n\n- **Inventory Service:** To check if the restaurant has your selected items available.\n\n- **Payment Service:** To process your payment.\n\n- **Delivery Service:** To assign a delivery driver to your order.\n\n\nThe gateway dynamically routes the request to these services using a **load balancing** algorithm, ensuring it connects to available and healthy service instances.\n\n```\nconst routeRequest = async (req, serviceType) => {\n  // Get service registry\n  const services = await serviceDiscovery.getServices(serviceType);\n\n  // Select instance\n  const targetService = selectServiceInstance(services);\n\n  // Forward request\n  return await axios.post(\n    `${targetService.url}/api/orders`,\n    req.body,\n    { headers: req.headers }\n  );\n};\n```\n\n#### **Step 7: Response Handling**\n\nOnce the API Gateway receives the response(s) from the backend service(s), it performs the following tasks:\n\n- **Transformation:** Adjusts the response format or structure to match the client’s requirements.\n\n- **Caching (Optional):** Stores the response temporarily for frequently accessed data, reducing future latency.\n\n\n```\nconst handleResponse = async (serviceResponse) => {\n  // Transform response if needed\n  const transformedResponse = {\n    orderId: serviceResponse.order_reference,\n    estimatedDelivery: serviceResponse.eta,\n    status: serviceResponse.current_status\n  };\n\n  // Cache response if applicable\n  if (serviceResponse.cacheable) {\n    await cacheResponse(\n      transformedResponse.orderId,\n      transformedResponse\n    );\n  }\n\n  return transformedResponse;\n};\n```\n\nFinally, the API Gateway sends the processed response back to the client in a format they can easily understand.\n\n#### Step 8: Logging & Monitoring\n\nThroughout this process, the gateway records important metrics to track each request:\n\n```\nconst logRequest = async (req, res, timing) => {\n  await logger.log({\n    timestamp: new Date(),\n    path: req.path,\n    method: req.method,\n    responseTime: timing,\n    statusCode: res.statusCode,\n    userId: req.user?.id\n  });\n};\n```\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/what-is-an-api-gateway?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![Manikrishna Sanganabatla's avatar](https://substackcdn.com/image/fetch/$s_!GYc7!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93a96ef0-f36e-4748-b48d-e2ebe43df208_144x144.png)](https://substack.com/profile/220878978-manikrishna-sanganabatla)[![Gokulram's avatar](https://substackcdn.com/image/fetch/$s_!ixnI!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1f7c98a-b01b-4113-a807-49a810e995dd_144x144.png)](https://substack.com/profile/21898713-gokulram)[![pratyush ranjan's avatar](https://substackcdn.com/image/fetch/$s_!6rhC!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F60526379-e020-4e03-bae1-ce967d94c4c9_96x96.jpeg)](https://substack.com/profile/119694940-pratyush-ranjan)[![Joe Turner's avatar](https://substackcdn.com/image/fetch/$s_!vvqp!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe166ca0c-de6f-445b-ab53-dbbfe355b390_750x750.jpeg)](https://substack.com/profile/88633413-joe-turner)[![Khai Le's avatar](https://substackcdn.com/image/fetch/$s_!myd9!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f4d81e-ca96-4d90-8068-be0b940d38d8_400x400.png)](https://substack.com/profile/6195793-khai-le)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/what-is-an-api-gateway"
    },
    {
      "article_title": "How Load Balancers Actually Work",
      "article_title_citation": "https://blog.algomaster.io/p/how-load-balancers-actually-work",
      "article_content_markdown": "A **load balancer** is one of the most foundational building blocks in distributed systems. It sits between clients and your backend servers and **spreads incoming traffic across a pool of machines**, so no single server becomes the bottleneck (or the single point of failure).\n\nBut the interesting questions start after the definition:\n\n- How does the load balancer decide which server should handle a request?\n\n- What’s the difference between L4 and L7 Load Balancers?\n\n- What happens when a server slows down or goes offline mid-traffic?\n\n- How can the load balancer ensure that request from the same client always go to the same server?\n\n- And what happens if the load balancer itself goes down?\n\n\nIn this article, we’ll answer these questions and build an intuitive understanding of how load balancers work in real systems.\n\nLet’s start with the basics: **why we need load balancers in the first place.**\n\n* * *\n\n# 1\\. Why Do We Need Load Balancers?\n\nImagine a web app with just one server. Every user request hits the same machine.\n\n[![](https://substackcdn.com/image/fetch/$s_!iVgQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fb6ba4d-93ed-4ad4-ae43-ba982907aebd_460x175.png)](https://substackcdn.com/image/fetch/$s_!iVgQ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fb6ba4d-93ed-4ad4-ae43-ba982907aebd_460x175.png)\n\nIt works… until it doesn’t. This “single-server” setup has a few fundamental problems:\n\n1. **Single Point of Failure:** If the server crashes, your entire application goes down.\n\n2. **Limited Scalability:** A single server can only handle so many requests before it becomes overloaded.\n\n3. **Poor Performance:** As traffic increases, response times degrade for all users.\n\n4. **No Redundancy:** Hardware failures, software bugs, or maintenance windows cause complete outages.\n\n\nA **load balancer** solves these problems by distributing traffic across multiple servers.\n\n[![](https://substackcdn.com/image/fetch/$s_!iJQc!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bce6202-ec2a-4435-a1fe-ca9119015eda_476x284.png)](https://substackcdn.com/image/fetch/$s_!iJQc!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bce6202-ec2a-4435-a1fe-ca9119015eda_476x284.png)\n\nWith this setup, you get:\n\n- **High Availability:** If one server fails, traffic is automatically routed to healthy servers.\n\n- **Horizontal Scalability:** You can add more servers to handle increased load.\n\n- **Better Performance:** Requests are distributed, so no single server is overwhelmed.\n\n- **Zero-Downtime Deployments:** You can take servers out of rotation for maintenance without affecting users.\n\n\n_**But how does the load balancer decide which server should handle each request?**_\n\n[Share](https://blog.algomaster.io/p/how-load-balancers-actually-work?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n# 2\\. Load Balancing Algorithms\n\nThe load balancer uses algorithms to distribute incoming requests. Each algorithm has different characteristics and is suited for different scenarios.\n\nBelow are the most common ones you’ll see in real systems.\n\n## 2.1 Round Robin\n\nThe simplest algorithm. Requests are distributed to servers in sequential order.\n\n[![](https://substackcdn.com/image/fetch/$s_!Bc7a!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70cff03e-f5ac-4ce3-8ddf-158dc7530cc3_493x203.png)](https://substackcdn.com/image/fetch/$s_!Bc7a!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70cff03e-f5ac-4ce3-8ddf-158dc7530cc3_493x203.png)\n\n```\nRequest 1 → Server A\nRequest 2 → Server B\nRequest 3 → Server C\nRequest 4 → Server A  (cycle repeats)\nRequest 5 → Server B\n...\n```\n\n#### Pros:\n\n- Simple to implement\n\n- Works well when all servers have equal capacity\n\n- Predictable distribution\n\n\n#### Cons:\n\n- Does not account for server load or capacity differences\n\n- A slow request on one server does not affect the distribution\n\n\n**Best for:** Homogeneous server environments where all servers have similar specs and requests have similar processing times.\n\n## 2.2 Weighted Round Robin\n\nAn extension of Round Robin where servers are assigned weights based on their capacity.\n\n[![](https://substackcdn.com/image/fetch/$s_!uczx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8327b027-1d8f-4589-9037-52428f3447ac_504x223.png)](https://substackcdn.com/image/fetch/$s_!uczx!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8327b027-1d8f-4589-9037-52428f3447ac_504x223.png)\n\n```\nServer A (weight=3): Handles 3 out of every 6 requests\nServer B (weight=2): Handles 2 out of every 6 requests\nServer C (weight=1): Handles 1 out of every 6 requests\n```\n\n#### Pros:\n\n- Still simple\n\n- Better for mixed instance sizes (e.g., 2 vCPU + 4 vCPU + 8 vCPU)\n\n\n#### Cons:\n\n- Still not load-aware in real time\n\n- If one server becomes slow (GC pause, noisy neighbor, warm cache vs cold cache), it will still get its scheduled share\n\n\n**Best for:** Heterogeneous environments where servers have different capacities (e.g., different CPU, memory, or network bandwidth).\n\n## 2.3 Least Connections\n\nRoutes requests to the server with the fewest active connections.\n\nThis algorithm is **dynamic**, it considers the current state of each server rather than using a fixed rotation.\n\n[![](https://substackcdn.com/image/fetch/$s_!D0s8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84d04287-a773-401e-9011-87f9c15533f1_483x333.png)](https://substackcdn.com/image/fetch/$s_!D0s8!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84d04287-a773-401e-9011-87f9c15533f1_483x333.png)\n\n```\nServer A: 10 active connections\nServer B: 5 active connections  ← Next request goes here\nServer C: 8 active connections\n```\n\n#### Pros:\n\n- Adapts to varying request processing times\n\n- Naturally balances load when some requests take longer than others\n\n\n#### Cons:\n\n- Requires tracking connection counts for each server\n\n- Slightly more overhead than Round Robin\n\n\n**Best for:** Applications where request processing times vary significantly (e.g., database queries, file uploads).\n\n## 2.4 Weighted Least Connections\n\nCombines Least Connections with server weights. The algorithm considers both the number of active connections and the server’s capacity.\n\n```\nScore = Active Connections / Weight\n\nServer A: 10 connections, weight 5 → Score = 2.0\nServer B: 6 connections, weight 2  → Score = 3.0\nServer C: 4 connections, weight 1  → Score = 4.0\n\nNext request goes to Server A (lowest score)\n```\n\n#### Pros:\n\n- Works well for mixed instance sizes _and_ mixed request durations\n\n- More robust than either “weighted” or “least connections” alone\n\n\n#### Cons:\n\n- Needs reliable tracking + weight tuning\n\n- Still uses connections as a proxy for load (not always perfect)\n\n\n**Best for:** Heterogeneous environments with varying request processing times.\n\n## 2.5 IP Hash\n\nThe client’s IP address is hashed to determine which server handles the request. The same client IP always goes to the same server.\n\n[![](https://substackcdn.com/image/fetch/$s_!D4NK!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffabb590c-7c5e-45b0-a598-f35d9e5b66d0_488x332.png)](https://substackcdn.com/image/fetch/$s_!D4NK!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffabb590c-7c5e-45b0-a598-f35d9e5b66d0_488x332.png)\n\n```\nhash(192.168.1.10) % 3 = 1 → Server B\nhash(192.168.1.20) % 3 = 0 → Server A\nhash(192.168.1.30) % 3 = 2 → Server C\n```\n\n#### Pros:\n\n- Simple session persistence without cookies\n\n- No additional state to track\n\n\n#### Cons:\n\n- Uneven distribution if IP addresses are not uniformly distributed\n\n- Server additions/removals cause redistribution of clients\n\n\n**Best for:** Applications requiring basic session persistence without cookie support.\n\n## 2.6 Least Response Time\n\nRoutes requests to the server with the fastest response time and fewest active connections.\n\nThe load balancer continuously measures:\n\n- Average response time for each server\n\n- Number of active connections\n\n\n#### Pros\n\n- Optimizes for perceived performance\n\n- Can avoid slow/unhealthy servers before they fully fail\n\n\n#### Cons\n\n- Highest operational complexity (needs continuous measurement and smoothing)\n\n- Can “overreact” to noise without careful tuning (feedback loops)\n\n- Requires good metrics and stable observation windows\n\n\n**Best for:** Latency-sensitive applications where response time is critical.\n\n* * *\n\n# 3\\. Layer 4 vs Layer 7 Load Balancing\n\nLoad balancers operate at different layers of the [OSI model](https://algomaster.io/learn/system-design/osi), and this determines what information they can use to make routing decisions.\n\nIn practice, this usually comes down to two common modes:\n\n- **Layer 4 (Transport):** routes based on IPs/ports and the transport protocol (TCP/UDP)\n\n- **Layer 7 (Application):** routes based on HTTP/HTTPS request details (path, headers, cookies, etc.)\n\n\n## 3.1 Layer 4 (Transport Layer)\n\nA **Layer 4** load balancer operates at the **TCP/UDP level**. It does not understand HTTP paths, headers, or payloads. It only sees network and transport metadata such as:\n\n- Source IP address\n\n- Destination IP address\n\n- Source port\n\n- Destination port\n\n- Protocol (TCP/UDP)\n\n\n#### How it works (TCP example)\n\n1. The client opens a TCP connection to the load balancer (e.g., `:443`).\n\n2. The load balancer chooses a backend server (Server 1 or Server 2).\n\n3. It forwards packets to that backend.\n\n4. **That connection stays pinned** to the chosen backend for the lifetime of the TCP session.\n\n\n#### Pros\n\n- **Very fast:** no request parsing, no payload inspection\n\n- **Efficient:** lower CPU/memory overhead\n\n- **Protocol-agnostic:** works for _any_ TCP/UDP traffic (HTTP, TLS, gRPC, MQTT, custom protocols)\n\n\n#### Cons\n\n- **No content-based routing:** can’t do `/api/*` vs `/images/*`\n\n- **Limited app visibility:** doesn’t know response codes, URL patterns, user sessions, etc.\n\n- **Harder to do “smart” behaviors** that require HTTP awareness\n\n\n**Examples:** AWS Network Load Balancer (NLB), HAProxy (TCP mode)\n\n## 3.2 Layer 7 (Application Layer)\n\nA **Layer 7** load balancer understands **HTTP/HTTPS**. It can inspect each request and route based on application-level information like:\n\n- HTTP method (`GET`, `POST`, …)\n\n- URL path and query parameters (`/api/users?id=7`)\n\n- HTTP headers (`Host`, `Authorization`, `Cookie`, `User-Agent`, …)\n\n- Sometimes the request body (with caveats)\n\n\n[![](https://substackcdn.com/image/fetch/$s_!N58q!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44555f31-2374-4f44-8dc6-2536810a8606_519x305.png)](https://substackcdn.com/image/fetch/$s_!N58q!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44555f31-2374-4f44-8dc6-2536810a8606_519x305.png)\n\n#### Content-based routing examples\n\n```\n/api/*          → API server pool\n/images/*       → Image server pool\n/videos/*       → Video streaming servers\nMobile clients  → Mobile-optimized servers\n```\n\nLayer 7 is especially useful when your “backend” isn’t one pool of identical servers, but a **set of specialized services**.\n\n#### Pros\n\n- **Smart routing:** based on path, headers, cookies, hostnames\n\n- **Better visibility:** can observe HTTP status codes, latency, retries, error rates\n\n- **Can transform traffic:** header injection, redirects, rewrites (depending on product)\n\n- **Commonly supports TLS termination:** decrypt at the LB, forward plain HTTP internally (or re-encrypt)\n\n\n#### Cons\n\n- **More overhead:** must parse HTTP (and sometimes decrypt TLS first)\n\n- **Higher latency:** usually small, but measurable at high scale\n\n- **Protocol-specific:** primarily for HTTP/HTTPS traffic\n\n\n**Examples:** AWS Application Load Balancer (ALB), NGINX, HAProxy (HTTP mode)\n\n* * *\n\n# 4\\. Health Checks and Failover\n\nA load balancer is only useful if it can **avoid sending traffic to broken servers**. If it keeps routing requests to a dead instance, users will see timeouts, 5xx errors, and intermittent failures that are hard to debug.\n\nThat’s why every serious load balancer has two jobs:\n\n1. **Detect health** (which servers are safe to send traffic to)\n\n2. **Fail over** (stop routing to unhealthy servers, and bring them back safely once recovered)\n\n\n## 4.1 Types of Health Checks\n\nHealth checks come in two broad flavors: **passive** (observe real traffic) and **active** (send probes). Most production setups use a combination.\n\n### Passive Health Checks\n\nThe load balancer monitors actual traffic to detect failures.\n\n```\nIf Server A returns 5xx errors for 3 consecutive requests\n  → Mark Server A as unhealthy\n  → Stop sending traffic to Server A\n```\n\n#### Pros\n\n- No extra “probe” traffic\n\n- Detects failures that matter to users (real request paths)\n\n\n#### Cons\n\n- You only detect issues **after users are already impacted**\n\n- Can be noisy: a few bad requests might be app-level bugs, not server death\n\n- Doesn’t help much when traffic is low (nothing to observe)\n\n\n**Best used for:** fast detection of application-level failures _in addition_ to active checks.\n\n### Active Health Checks\n\nThe load balancer periodically sends probe requests to each server, independent of user traffic.\n\n[![](https://substackcdn.com/image/fetch/$s_!8Fkd!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cd18a63-1823-4831-b035-83ca7c5628ec_541x225.png)](https://substackcdn.com/image/fetch/$s_!8Fkd!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8cd18a63-1823-4831-b035-83ca7c5628ec_541x225.png)\n\n**Example:**\n\n- `GET /health` every 10 seconds\n\n- If probes fail repeatedly, the server is removed from rotation\n\n\nThis catches failures before they hit users (or at least reduces blast radius quickly).\n\n### Health check types by depth\n\n#### TCP Health Checks\n\nThe load balancer checks whether it can open a TCP connection to a port.\n\n```\nCan I connect to Server A on port 8080?\n  → Yes: Server is healthy\n  → No: Server is unhealthy\n```\n\n**Good for:** basic liveness (“is the process listening?”)\n\n**Blind spot:** the app may accept TCP but still be broken internally (DB down, stuck threads).\n\n#### HTTP Health Checks\n\nThe load balancer sends an HTTP request to a known endpoint and validates the response.\n\n```\nGET /health HTTP/1.1\nHost: server-a.internal\n\nExpected response:\n  - Status code: 200\n  - Body contains: \"OK\"\n  - Response time: < 500ms\n```\n\n**Good for:** verifying the app can actually serve HTTP and respond quickly.\n\n#### Application-Level Health Checks\n\nA richer endpoint that checks internal dependencies and returns structured status.\n\n```\nGET /health\n\n{\n  \"status\": \"healthy\",\n  \"checks\": {\n    \"database\": \"healthy\",\n    \"cache\": \"healthy\",\n    \"external_api\": \"degraded\"\n  },\n  \"timestamp\": \"2024-01-15T10:30:00Z\"\n}\n```\n\n## 4.2 Failover Process\n\nFailover is what happens after health checks decide a server is unhealthy.\n\n#### Removing an unhealthy server (fail-out)\n\nOnce a server crosses the **unhealthy threshold**, the load balancer:\n\n- marks it **unhealthy**\n\n- stops sending it **new** traffic\n\n- continues sending traffic only to healthy servers\n\n\n**Example Timeline:**\n\n```\n00:00 - Server C fails to respond to health check\n00:10 - Second health check fails\n00:20 - Third health check fails → Server C marked unhealthy\n00:20 - All new traffic goes to Servers A and B only\n```\n\n#### Bringing a server back (recovery / fail-in)\n\nAfter the server is fixed, it shouldn’t immediately receive full traffic (to avoid instant re-failure).\n\nWith a **healthy threshold** of 2:\n\n```\n...Server C is fixed...\n\n05:00 - Health check succeeds\n05:10 - Second health check succeeds → Server C marked healthy\n05:10 - Server C rejoins the pool\n```\n\nMany systems also use **slow start / ramp-up**, gradually increasing traffic to a recovered server so it can warm caches and stabilize.\n\n* * *\n\n# 5\\. Session Persistence (Sticky Sessions)\n\nBy default, a load balancer may send each request from the same user to a different backend server. That’s usually fine for **stateless** services but it breaks quickly if your application stores session data **in-memory on the server**.\n\n**Example failure mode:**\n\n```\nRequest 1: User logs in → Server A (session created)\nRequest 2: User views profile → Server B (no session found!)\nRequest 3: User logs in again → Server C (another session created)\n```\n\nTo avoid this, systems use **session persistence** (aka **sticky sessions**): the load balancer keeps routing a given user’s requests to the same server.\n\n## 5.1 Methods of Session Persistence\n\nThere are a few common ways to achieve stickiness, each with different trade-offs.\n\n### Cookie-Based Persistence\n\nThe load balancer sets a cookie identifying which server the client should use.\n\n#### How it works:\n\n[![](https://substackcdn.com/image/fetch/$s_!7WfR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7caea3f-1b5c-44af-9d97-d0bbcd1cbff6_1022x589.png)](https://substackcdn.com/image/fetch/$s_!7WfR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7caea3f-1b5c-44af-9d97-d0bbcd1cbff6_1022x589.png)\n\n1. On the first request, the load balancer selects a backend (say, Server A).\n\n2. The response includes a cookie that encodes the “chosen backend”.\n\n3. On subsequent requests, the client sends that cookie back.\n\n4. The load balancer uses the cookie to route the request to the same server.\n\n\n#### Pros\n\n- Works well for browsers and HTTP clients\n\n- Doesn’t require special networking assumptions\n\n- Very reliable as long as cookies are preserved\n\n\n#### Cons\n\n- Ties users to a specific server, reducing flexibility\n\n- If the cookie is not handled carefully, it can become a security or operability risk (tampering, leakage, etc.)\n\n- Doesn’t help for non-HTTP protocols\n\n\n### IP-Based Persistence\n\nUse the client’s IP address to consistently route to the same server (same as IP Hash algorithm).\n\n#### Pros\n\n- Simple\n\n- No cookies required\n\n\n#### Cons\n\n- NAT and proxies: many users can appear from the same IP (corporate networks, mobile carriers)\n\n- Client IP may be masked by CDNs, proxies, or gateways unless forwarded correctly\n\n- Adding/removing servers can reshuffle mapping and break stickiness\n\n\n**Best for:** basic stickiness in environments where client IP is stable and meaningful.\n\n### Application-Controlled Persistence\n\nThe application explicitly indicates the sticky target via a header or cookie, and the load balancer respects it.\n\n**Example:**\n\n- Response header: `X-Sticky-Server: server-a-pod-xyz`\n\n\nThis is less common in “standard” setups, but it can be useful when the application has stronger context about routing needs (multi-tenant affinity, shard affinity, warm-cache affinity, etc.).\n\n## 5.2 Problems with Sticky Sessions\n\nSticky sessions solve one problem, but they create new ones.\n\n#### Uneven load distribution\n\nIf a few users generate heavy traffic, and they’re pinned to the same backend, that server becomes hot while others stay underutilized.\n\n#### Failover becomes user-visible\n\nIf Server A dies, every user pinned to A may lose their session and get forced to re-authenticate (unless the app has other recovery mechanisms).\n\n#### Scaling helps less than you expect\n\nWhen you add new servers, existing users remain pinned to old ones. So the new capacity primarily benefits new users, not the current load distribution.\n\n## 5.3 Better Alternative: Externalized Sessions\n\nInstead of keeping sessions in server memory, store session state in a shared external store. Then **any server can handle any request**.\n\n[![](https://substackcdn.com/image/fetch/$s_!pdYw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4e69f817-4c27-4e7a-8521-b806322cdb23_668x278.png)](https://substackcdn.com/image/fetch/$s_!pdYw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4e69f817-4c27-4e7a-8521-b806322cdb23_668x278.png)\n\nWith externalized sessions:\n\n- Any backend can serve any request (no affinity required)\n\n- Server failures don’t wipe sessions\n\n- Horizontal scaling becomes clean and predictable\n\n- Deployments become simpler (no special draining logic for “pinned” users)\n\n\n**Popular session stores:** Redis (very common), Memcached, DynamoDB\n\n> **Key point:** Sticky sessions are often a tactical fix. Externalizing sessions is usually the strategic solution especially once you care about reliability, autoscaling, and smooth deployments.\n\n* * *\n\n## 6\\. SSL/TLS Termination\n\nHTTPS is non-negotiable on the modern internet but **TLS handshakes and encryption are not free**. They cost CPU, add latency, and require careful certificate management.\n\nLoad balancers often take on this work so your application servers can focus on business logic.\n\nThere are three common patterns:\n\n## 6.1 TLS Termination at Load Balancer\n\nThe client connects to the load balancer over HTTPS. The load balancer decrypts the traffic and forwards it to backends as plain HTTP.\n\n[![](https://substackcdn.com/image/fetch/$s_!k_2o!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8fcdcae4-a198-43f1-9215-a8034438c062_692x178.png)](https://substackcdn.com/image/fetch/$s_!k_2o!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8fcdcae4-a198-43f1-9215-a8034438c062_692x178.png)\n\n#### Pros:\n\n- Reduces CPU load on application servers\n\n- Centralized certificate management\n\n- Easier to inspect and modify traffic\n\n\n#### Cons:\n\n- Traffic between load balancer and servers is unencrypted\n\n- Requires trusting the internal network\n\n\n## 6.2 TLS Passthrough\n\nThe load balancer does **not** decrypt TLS. It forwards the encrypted bytes to a backend, and the backend terminates TLS.\n\n[![](https://substackcdn.com/image/fetch/$s_!Oocq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc288b095-3ca5-448f-b1b1-241965c3c545_605x178.png)](https://substackcdn.com/image/fetch/$s_!Oocq!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc288b095-3ca5-448f-b1b1-241965c3c545_605x178.png)\n\n#### Pros:\n\n- End-to-end encryption\n\n- No certificate management at load balancer\n\n\n#### Cons:\n\n- Cannot inspect or modify traffic (Layer 4 only)\n\n- Each server must handle SSL/TLS\n\n\n## 6.3 TLS Re-encryption\n\nThe load balancer decrypts traffic, applies L7 routing/inspection, then **re-encrypts** before forwarding to backends.\n\n[![](https://substackcdn.com/image/fetch/$s_!hdLP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee7c6fa1-c1f1-47d5-8f13-5943fcb2d22c_664x176.png)](https://substackcdn.com/image/fetch/$s_!hdLP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee7c6fa1-c1f1-47d5-8f13-5943fcb2d22c_664x176.png)\n\n#### Pros:\n\n- End-to-end encryption\n\n- Can still inspect and route based on content\n\n\n#### Cons:\n\n- Double encryption/decryption overhead\n\n- More complex certificate management\n\n\n* * *\n\n# 7\\. High Availability for Load Balancers\n\nA load balancer improves availability for your **backend servers** but it also introduces a new risk: If you deploy _one_ load balancer and it fails, your entire service becomes unreachable.\n\nSo the question becomes: **how do we make the load balancer itself highly available?**\n\nThere are three common approaches:\n\n## 7.1 Active-Passive (Failover)\n\nTwo load balancers are deployed: one active, one standby. If the active fails, the passive takes over.\n\n[![](https://substackcdn.com/image/fetch/$s_!J8d7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb486720c-bad6-4645-a156-fbbc5fa086d8_421x347.png)](https://substackcdn.com/image/fetch/$s_!J8d7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb486720c-bad6-4645-a156-fbbc5fa086d8_421x347.png)\n\nThe two load balancers share a **Virtual IP (VIP)**. When the active fails, the standby claims the VIP.\n\n#### How failover is typically implemented\n\n- **VRRP** (Virtual Router Redundancy Protocol)\n\n- **Keepalived** (common Linux tool that uses VRRP)\n\n- Heartbeats between LBs to detect failure quickly\n\n\n#### Pros\n\n- Easier to reason about\n\n- Works well for on-prem / self-managed environments\n\n\n#### Cons\n\n- The standby is mostly idle (wasted capacity)\n\n- Failover is not instant (there’s always a detection + takeover window)\n\n- You still need to design for state:\n\n  - if the active LB held session affinity state, failover may break stickiness unless state is shared\n\n## 7.2 Active-Active\n\nIn active-active mode, both load balancers handle traffic simultaneously. DNS or an upstream router distributes traffic between them.\n\n[![](https://substackcdn.com/image/fetch/$s_!uhT7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd28d50b8-de51-47b1-add4-427376a26814_419x308.png)](https://substackcdn.com/image/fetch/$s_!uhT7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd28d50b8-de51-47b1-add4-427376a26814_419x308.png)\n\n#### Pros:\n\n- Better resource utilization (no idle standby)\n\n- Higher total capacity (you scale the LB tier horizontally)\n\n- Often smoother failure handling: if one LB dies, the other still serves traffic\n\n\n#### Cons:\n\n- More moving parts: routing, failover behavior, monitoring, and debugging are harder\n\n- **Session persistence gets trickier**\n\n  - If stickiness is implemented at the LB, users might bounce between LBs unless the mechanism works across both (or you keep LBs stateless)\n\n## 7.3 Cloud Load Balancers\n\nIn most cloud environments, you don’t run your own HA pair of load balancers. You use a managed LB (e.g., AWS ALB/NLB, Google Cloud Load Balancing, Azure Load Balancer).\n\nThese are designed to be **highly available by default**, typically by:\n\n- running across multiple **Availability Zones**\n\n- automatically replacing unhealthy infrastructure\n\n- scaling the LB fleet as traffic increases\n\n- providing built-in health checks and failover mechanisms\n\n\n**Trade-off:** less control over internals, and you must design within the feature set of the managed product.\n\n* * *\n\n# 8\\. Key Takeaways\n\n1. **Load balancers distribute traffic** across multiple servers for better performance, availability, and scalability.\n\n2. **Algorithms matter.** Round Robin is simple but does not account for server load. Least Connections adapts to varying request times.\n\n3. **Layer 4 vs Layer 7:** Layer 4 is faster but less flexible. Layer 7 enables content-based routing and advanced features.\n\n4. **Health checks are critical.** Without them, users get routed to dead servers.\n\n5. **Session persistence has trade-offs.** Sticky sessions can cause uneven load. Externalized sessions are usually better.\n\n6. **SSL termination** at the load balancer reduces backend server CPU usage.\n\n7. **Load balancers need HA too.** Use active-passive or active-active setups to avoid single points of failure.\n\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions/suggestions, feel free to leave a comment.\n\n* * *\n\n#### Subscribe to AlgoMaster Newsletter\n\nBy Ashish Pratap Singh · Thousands of paid subscribers\n\nMaster Coding and System Design Interviews. Level up your Software Engineering career. Subscribe and get a FREE System Design Interview Handbook in your inbox.\n\nSubscribe\n\nBy subscribing, I agree to Substack's [Terms of Use](https://substack.com/tos), and acknowledge its [Information Collection Notice](https://substack.com/ccpa#personal-data-collected) and [Privacy Policy](https://substack.com/privacy).\n\n[![AbdulRahman H. Mohammed's avatar](https://substackcdn.com/image/fetch/$s_!EmBX!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa302a896-ec57-496b-9291-a6aa0da687c0_1052x1052.jpeg)](https://substack.com/profile/101627639-abdulrahman-h-mohammed)[![naviinbharathy's avatar](https://substackcdn.com/image/fetch/$s_!7gK1!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb2a73812-c290-4f6e-a7ff-e7656e985329_96x96.jpeg)](https://substack.com/profile/161224250-naviinbharathy)[![Barsha Mondal's avatar](https://substackcdn.com/image/fetch/$s_!_HrQ!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F464d3b3e-0baf-4aa3-acbd-c8fe5e594794_96x96.png)](https://substack.com/profile/287551341-barsha-mondal)[![Haridev S's avatar](https://substackcdn.com/image/fetch/$s_!31xb!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F859a15d2-0a40-4c96-95d4-433596dbb9aa_96x96.png)](https://substack.com/profile/150052906-haridev-s)[![Ishan Gupta's avatar](https://substackcdn.com/image/fetch/$s_!dDX3!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9648e1ab-a756-4d53-a549-56fb82afa972_1024x1028.jpeg)](https://substack.com/profile/18530345-ishan-gupta)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/how-load-balancers-actually-work"
    },
    {
      "article_title": "Load Balancing Algorithms Explained with Code",
      "article_title_citation": "https://blog.algomaster.io/p/load-balancing-algorithms-explained-with-code",
      "article_content_markdown": "Load balancing is the process of **distributing incoming network traffic** across multiple servers to ensure that no single server is overwhelmed.\n\n[![](https://substackcdn.com/image/fetch/$s_!QKkY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5215d10-fcd8-4c50-acb6-ccbb36dea24f_832x1000.png)](https://substackcdn.com/image/fetch/$s_!QKkY!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5215d10-fcd8-4c50-acb6-ccbb36dea24f_832x1000.png)\n\nBy evenly spreading the workload, load balancing aims to **prevent overload** on a single server, **enhance performance** by reducing response times and **improve availability** by rerouting traffic in case of server failures.\n\nThere are several algorithms to achieve load balancing, each with its pros and cons.\n\nIn this article, we will dive into the most commonly used load balancing algorithms, how they work, when to use them, their benefits/drawbacks and how to implement them in code.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n# **Algorithm 1: Round Robin**\n\n[![](https://substackcdn.com/image/fetch/$s_!jpjg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F54114fcc-cce5-4f0d-a678-47f8f0339fd4_1304x1076.png)](https://substackcdn.com/image/fetch/$s_!jpjg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F54114fcc-cce5-4f0d-a678-47f8f0339fd4_1304x1076.png)\n\n#### **How it Works:**\n\n1. A request is sent to the first server in the list.\n\n2. The next request is sent to the second server, and so on.\n\n3. After the last server in the list, the algorithm loops back to the first server.\n\n\n#### **When to Use**:\n\n- When all servers have similar processing capabilities and are equally capable of handling requests.\n\n- When simplicity and even distribution of load is more critical.\n\n\n#### **Benefits**:\n\n- Simple to implement and understand.\n\n- Ensures even distribution of traffic.\n\n\n#### **Drawbacks**:\n\n- Does not consider server load or response time.\n\n- Can lead to inefficiencies if servers have different processing capabilities.\n\n\n#### **Implementation:**\n\n[![](https://substackcdn.com/image/fetch/$s_!8xw6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea11f328-dd14-43d9-adb4-967651f8c4f3_2912x1716.png)](https://substackcdn.com/image/fetch/$s_!8xw6!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea11f328-dd14-43d9-adb4-967651f8c4f3_2912x1716.png)\n\n**[Code Link](https://github.com/ashishps1/awesome-system-design-resources/blob/main/implementations/python/load_balancing_algorithms/round_robin.py.py)**\n\nIn this implementation, the `RoundRobin` class maintains a **list of servers** and keeps track of the **current index**.\n\nThe `get_next_server()` updates the index and returns the next server in the cycle.\n\n* * *\n\n# Algorithm 2: Weighted Round Robin\n\n[![](https://substackcdn.com/image/fetch/$s_!v6Dt!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb12546e-4905-46b0-89e6-80ab007a6aa2_1570x1110.png)](https://substackcdn.com/image/fetch/$s_!v6Dt!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb12546e-4905-46b0-89e6-80ab007a6aa2_1570x1110.png)\n\n#### **How it Works:**\n\n1. Each server is assigned a **weight** based on their processing power or available resources.\n\n2. Servers with higher weights receive a proportionally larger share of incoming requests.\n\n\n#### When to use:\n\n- When servers have different processing capabilities or available resources.\n\n- When you want to distribute the load based on the capacity of each server.\n\n\n#### **Benefits**:\n\n- Balances load according to server capacity.\n\n- More efficient use of server resources.\n\n\n#### **Drawbacks**:\n\n- Slightly more complex to implement than simple Round Robin.\n\n- Does not consider current server load or response time.\n\n\n#### **Implementation:**\n\n[![](https://substackcdn.com/image/fetch/$s_!C6xU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c138f0a-d1e6-463d-be1f-dfa06cb8a402_3060x2528.png)](https://substackcdn.com/image/fetch/$s_!C6xU!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c138f0a-d1e6-463d-be1f-dfa06cb8a402_3060x2528.png)\n\n**[Code Link](https://github.com/ashishps1/awesome-system-design-resources/blob/main/implementations/python/load_balancing_algorithms/weighted_round_robin.py)**\n\nIn this implementation, the `WeightedRoundRobin` class takes a list of servers and their corresponding weights.\n\nThe `get_next_server()` method runs an infinite loop to find a suitable server based on the weights, ensuring that servers with higher weights receive more requests.\n\nThe algorithm keeps track of the current weight and adjusts it in each iteration to maintain the desired distribution ratio.\n\n**Example:** if the weights are `[5, 1, 1]`, Server 1 will be selected 5 times more often than Server 2 or Server 3.\n\n[Share](https://blog.algomaster.io/p/load-balancing-algorithms-explained-with-code?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n# **Algorithm 3: Least Connections**\n\n[![](https://substackcdn.com/image/fetch/$s_!MRhR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc42a1db9-75b4-4a52-9e9b-dfcc0118c235_1728x1118.png)](https://substackcdn.com/image/fetch/$s_!MRhR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc42a1db9-75b4-4a52-9e9b-dfcc0118c235_1728x1118.png)\n\n#### **How it Works:**\n\n1. Monitor the **number of active connections** on each server.\n\n2. Assigns incoming requests to the server with the least number of active connections.\n\n\n#### When to use:\n\n- When you want to distribute the load based on the current number of active connections.\n\n- When servers have similar processing capabilities but may have different levels of concurrent connections.\n\n\n#### **Benefits**:\n\n- Balances load more dynamically based on current server load.\n\n- Helps prevent any server from becoming overloaded with a high number of active connections.\n\n\n#### **Drawbacks**:\n\n- May not be optimal if servers have different processing capabilities.\n\n- Requires tracking active connections for each server.\n\n\n#### **Implementation:**\n\n[![](https://substackcdn.com/image/fetch/$s_!SyrO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21a93e0e-f38c-4c12-9dc1-c537a10bbf65_3680x2888.png)](https://substackcdn.com/image/fetch/$s_!SyrO!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21a93e0e-f38c-4c12-9dc1-c537a10bbf65_3680x2888.png)\n\n**[Code Link](https://github.com/ashishps1/awesome-system-design-resources/blob/main/implementations/python/load_balancing_algorithms/least_connections.py)**\n\nIn this example, the `LeastConnections` class maintains a map of servers and the number of active connections for each server.\n\nThe `get_next_server()` method selects a random server with the least number of connections and increments the connection count for that server.\n\nThe `release_connection()` method is called when a connection is closed, decrementing the connection count for the corresponding server.\n\n* * *\n\n# **Algorithm 4: Least Response Time**\n\n[![](https://substackcdn.com/image/fetch/$s_!WU5I!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13178f62-358e-4717-83e9-f404bf9f91e5_1710x1120.png)](https://substackcdn.com/image/fetch/$s_!WU5I!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13178f62-358e-4717-83e9-f404bf9f91e5_1710x1120.png)\n\n#### **How It Works**:\n\n- Monitors the response time of each server\n\n- Assigns incoming requests to the server with the fastest response time.\n\n\n#### **When to Use**:\n\n- When you have servers with varying response times and want to route requests to the fastest server.\n\n\n#### **Benefits**:\n\n- Minimizes overall latency by selecting the server with the fastest response time.\n\n- Can adapt dynamically to changes in server response times.\n\n- Helps improve the user experience by providing quick responses.\n\n\n#### **Drawbacks**:\n\n- Requires accurate measurement of server response times, which can be challenging in distributed systems.\n\n- May not consider other factors such as server load or connection count.\n\n\n#### **Implementation:**\n\n[![](https://substackcdn.com/image/fetch/$s_!NNqg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b35e86a-239e-4633-a1e0-89aa38324389_2584x3336.png)](https://substackcdn.com/image/fetch/$s_!NNqg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b35e86a-239e-4633-a1e0-89aa38324389_2584x3336.png)\n\n**[Code Link](https://github.com/ashishps1/awesome-system-design-resources/blob/main/implementations/python/load_balancing_algorithms/least_response_time.py)**\n\nIn this example, the `LeastResponseTime` class maintains a list of servers and keeps track of the response time for each server.\n\nThe `get_next_server()` method selects the server with the least response time. The `update_response_time()` method is called after each request to update the response time for the corresponding server.\n\nTo simulate the response time, we use a `simulate_response_time()` function that introduces a random delay to mimic the server's response time.\n\nIn a real-world scenario, you would measure the actual response time of each server.\n\n* * *\n\n# **Algorithm 5: IP Hash**\n\n[![](https://substackcdn.com/image/fetch/$s_!qMbL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc38a5648-bcdf-487c-9fe6-a0a179eb5f72_1304x1098.png)](https://substackcdn.com/image/fetch/$s_!qMbL!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc38a5648-bcdf-487c-9fe6-a0a179eb5f72_1304x1098.png)\n\n#### **How It Works**:\n\n- Calculates a hash value from the client’s IP address and uses it to determine the server to route the request.\n\n\n#### **When to Use**:\n\n- When you need session persistence, as requests from the same client are always directed to the same server.\n\n\n#### **Benefits**:\n\n- Simple to implement.\n\n- Useful for applications that require sticky sessions.\n\n\n#### **Drawbacks**:\n\n- Can lead to uneven load distribution if certain IP addresses generate more traffic than others.\n\n- Lacks flexibility if a server goes down, as the hash mapping may need to be reconfigured.\n\n\n#### **Implementation:**\n\n[![](https://substackcdn.com/image/fetch/$s_!JKRt!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6dfb1f4-34f2-4eac-aa1f-7468d2e88fdf_2912x1988.png)](https://substackcdn.com/image/fetch/$s_!JKRt!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6dfb1f4-34f2-4eac-aa1f-7468d2e88fdf_2912x1988.png)\n\n**[Code Link](https://github.com/ashishps1/awesome-system-design-resources/blob/main/implementations/python/load_balancing_algorithms/ip_hash.py)**\n\nIn this implementation, the `IPHash` class takes a list of servers.\n\nThe `get_next_server()` method calculates the MD5 hash of the client's IP address and uses the modulo operator to determine the index of the server to which the request should be routed.\n\nThis ensures that **requests from the same IP address are always directed to the same server.**\n\n# **Summary:**\n\n- **Round Robin**: Simple and even distribution, best for homogeneous servers.\n\n- **Weighted Round Robin**: Distributes based on server capacity, good for heterogeneous environments.\n\n- **Least Connections**: Dynamically balances based on load, ideal for varying workloads.\n\n- **Least Response Time**: Optimizes for fastest response, best for environments with varying server performance.\n\n- **IP Hash**: Ensures session persistence, useful for stateful applications.\n\n\nChoosing the right load balancing algorithm depends on the specific needs and characteristics of your system, including server capabilities, workload distribution, and performance requirements.\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/load-balancing-algorithms-explained-with-code?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![Gabriel Anyosa's avatar](https://substackcdn.com/image/fetch/$s_!voRc!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f9f5c35-b7cd-45c1-84e6-13f4c0ffe127_144x144.png)](https://substack.com/profile/35967120-gabriel-anyosa)[![Carlos Jiga's avatar](https://substackcdn.com/image/fetch/$s_!eq1G!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46b67219-2528-4f40-aa40-101e72747817_144x144.png)](https://substack.com/profile/200015540-carlos-jiga)[![Sudheendra's avatar](https://substackcdn.com/image/fetch/$s_!hxM_!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe17c8e0b-2fe3-48bd-8cda-86ac9006f422_144x144.png)](https://substack.com/profile/6349898-sudheendra)[![Sidharth S's avatar](https://substackcdn.com/image/fetch/$s_!FXYU!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff229df93-0b9b-4ef1-aae7-ca438799bcd0_144x144.png)](https://substack.com/profile/169944729-sidharth-s)[![Jawahar's avatar](https://substackcdn.com/image/fetch/$s_!UrNX!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4bfd7200-1ede-434f-9037-380cc16fd109_1167x1169.jpeg)](https://substack.com/profile/33915730-jawahar)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/load-balancing-algorithms-explained-with-code"
    },
    {
      "article_title": "Proxy vs Reverse Proxy (Explained with Examples)",
      "article_title_citation": "https://blog.algomaster.io/p/proxy-vs-reverse-proxy-explained",
      "article_content_markdown": "**Proxies** and **reverse proxies** are servers that sit between clients and servers to improve security, privacy and performance.\n\nA **Proxy server** (sometimes called a **Forward proxy**) acts on behalf of clients, while a **Reverse Proxy** acts on **behalf** of servers.\n\n[![](https://substackcdn.com/image/fetch/$s_!dGvk!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87424c89-0ba3-4580-89bb-ccd5870dff69_945x419.png)](https://substackcdn.com/image/fetch/$s_!dGvk!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87424c89-0ba3-4580-89bb-ccd5870dff69_945x419.png) **Visualized using [Multiplayer](https://dub.sh/92xtmEY)**\n\nIn this article, we’ll break down the key differences between **proxies** and **reverse proxies** and how they function with real-world examples and simple illustrations.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n# 1\\. What is a Proxy Server?\n\n> A **proxy** is an entity that has the authority to act on behalf of another.\n\nIn computer terms, a **proxy** (or a **forward proxy**) is a server that acts on behalf of clients on a network.\n\nWhen you send a request, like opening a webpage, the proxy intercepts it, forwards it to the target server, and then relays the server’s response back to you.\n\n[![](https://substackcdn.com/image/fetch/$s_!i5Av!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff11ff886-4db5-4550-aa0f-5f232b094b03_887x477.png)](https://substackcdn.com/image/fetch/$s_!i5Av!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff11ff886-4db5-4550-aa0f-5f232b094b03_887x477.png) **Visualized using [Multiplayer](https://dub.sh/92xtmEY)**\n\nThink of proxy server as a **middleman** that sits between a private network and the public internet.\n\nLet’s walk through a simplified example of how a proxy server handles a request:\n\n1. The user types a website URL into their browser. The request is intercepted by the proxy server instead of going directly to the website.\n\n2. The proxy server examines the request to decide if it should forward it, deny it, or serve a cached copy.\n\n3. If the proxy decides to forward the request, it contacts the target website. The website sees only the proxy server’s IP, not the user’s.\n\n4. When the target website responds, the proxy receives the response and relays it to the user.\n\n\n### **Key Benefits of Proxy Servers:**\n\n1. **Privacy and Anonymity:** Proxy servers hide your IP address by using their own, so the destination server cannot know your real location or identity.\n\n2. **Access Control:** Organizations use proxies to enforce content restrictions, monitor internet usage.\n\n3. **Security:** Proxies can filter out malicious content and block suspicious sites, providing an additional layer of security.\n\n4. **Improved Performance:** Proxies cache frequently accessed content, reducing latency and improving load times for websites.\n\n\n#### Is a VPN the same as a Proxy?\n\nNo. While both hide your IP, a **VPN** encrypts all your internet traffic, making it more secure. A proxy only forwards specific requests without necessarily encrypting them.\n\n### Real-World Applications of Proxy Servers\n\n#### 1\\. Bypassing Geographic Restrictions\n\nOne of the most common uses of proxy servers is **bypassing geographic restrictions** on websites and content.\n\nStreaming services, for instance, often offer different content based on a user’s location. With a proxy server based in the target region, you can access that region’s content library as if you were a local user.\n\n[![](https://substackcdn.com/image/fetch/$s_!9Vqq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb145010-53d0-4a3f-b158-31acec73d923_729x519.png)](https://substackcdn.com/image/fetch/$s_!9Vqq!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb145010-53d0-4a3f-b158-31acec73d923_729x519.png) **Visualized using [Multiplayer](https://dub.sh/92xtmEY)**\n\n> **Example:** Suppose you’re in India and want to access the US library of a streaming platform (eg.. Netflix). By connecting to a proxy server located in the US, your request to the streaming platform will appear to be coming from the US, allowing access to its content as if you were a US-based viewer.\n\n#### 2\\. Speed and Performance Optimization (Caching)\n\nProxies can store cached versions of frequently accessed content, enabling faster load times and reducing bandwidth usage.\n\n[![](https://substackcdn.com/image/fetch/$s_!-vu2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F005673b3-62cb-48a8-adc6-19fc69156a17_887x477.png)](https://substackcdn.com/image/fetch/$s_!-vu2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F005673b3-62cb-48a8-adc6-19fc69156a17_887x477.png) **Visualized using [Multiplayer](https://dub.sh/92xtmEY)**\n\nWhen a user requests cached content, the proxy server serves the stored copy rather than fetching it from the destination server, which reduces latency.\n\nTo avoid stale content, it uses a Time-To-Live (TTL) value, automatically expiring cached data after the configured time\n\n> **Example:** An organization with hundreds of employees frequently accessing the same online resources can deploy a caching proxy. This proxy caches common websites in it’s database, so subsequent requests are served quickly from the proxy’s storage, saving time and bandwidth.\n\n[Share](https://blog.algomaster.io/p/proxy-vs-reverse-proxy-explained?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n# 2\\. What is a Reverse Proxy?\n\nA **reverse proxy** is the **reverse** of a forward proxy. It regulates traffic coming into a network.\n\nIt sits in front of servers, intercepts client requests and forwards them to backend servers based on predefined rules.\n\n[![](https://substackcdn.com/image/fetch/$s_!L8Gg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3be42662-47d2-4165-b278-95d583e2d2be_904x517.png)](https://substackcdn.com/image/fetch/$s_!L8Gg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3be42662-47d2-4165-b278-95d583e2d2be_904x517.png) **Visualized using [Multiplayer](https://dub.sh/92xtmEY)**\n\nThink of a reverse proxy as a **gatekeeper**. Instead of hiding clients from the server, it hides servers from clients.\n\nAllowing direct access to servers can pose **security risks**, exposing them to threats like **hackers** and **DDoS attacks**.\n\nA reverse proxy mitigates these risks by creating a single, controlled point of entry that filters and regulates incoming traffic all while keeping server IP addresses hidden.\n\nWith a reverse proxy in place, clients no longer interact directly with the servers. They only communicate with the reverse proxy.\n\nLet’s walk through a simplified example of how a proxy server handles a request:\n\n1. A user types a website URL into their browser, which sends a request to the server.\n\n2. The reverse proxy server receives the request before it reaches the backend servers.\n\n3. Based on predefined rules (like load balancing or server availability), the reverse proxy forwards the request to the appropriate backend server.\n\n4. The backend server processes the request and sends a response back to the reverse proxy.\n\n5. The reverse proxy relays the response to the client, with the client never directly interacting with the backend servers.\n\n\n### Key Benefits of Reverse Proxy\n\n- **Enhanced Security:** By acting as a protective layer, a reverse proxy hides backend servers from clients, reducing the risk of attacks directly targeting backend infrastructure.\n\n- **Load Balancing:** A reverse proxy can distribute incoming requests evenly across multiple backend servers, improving system reliability and preventing server overload.\n\n- **Caching Static Content:** Reverse proxies can cache static assets like images, CSS, and JavaScript, reducing the need to fetch these files from the backend repeatedly.\n\n- **SSL Termination:** Reverse proxies can handle SSL encryption, offloading this work from backend servers.\n\n- **Web Application Firewall (WAF):** Reverse proxies can inspect incoming requests, acting as a firewall to detect and block malicious traffic.\n\n\n### Real-World Example of a Reverse Proxy\n\n**Cloudflare’s** reverse proxy is widely used by global websites and applications to boost speed, security, and reliability.\n\nIt’s **Web Application Firewall (WAF)** and **DDoS protection** blocks malicious traffic before it reaches the site’s servers, safeguarding against attacks and improving uptime.\n\nCloudflare’s global content caching caches static and dynamic content at over 200 data centers around the world, storing frequently accessed files (like images, CSS, and JavaScript) closer to users. This significantly reduces load times and latency, as requests don’t always need to travel to the origin server.\n\n### Setting Up a Reverse Proxy with Nginx\n\nOne of the most popular reverse proxy tools is **Nginx**.\n\nHere’s how you can set up a basic reverse proxy configuration using Nginx on a Linux server.\n\n#### 1\\. Install Nginx\n\n```\nsudo apt update sudo apt install nginx\n```\n\n#### 2\\. Add Reverse Proxy Configuration\n\n```\nserver {\n    listen 80;\n\n    location / {\n        proxy_pass http://backend_server_ip;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    }\n}\n```\n\n#### 3\\. Test and Reload Nginx\n\n```\nsudo nginx -t sudo systemctl reload nginx\n```\n\n### Load Balancing Across Multiple Servers\n\nFor a high-traffic website, spreading incoming requests across multiple backend servers is crucial.\n\nA reverse proxy can implement load balancing algorithms such as round-robin, least connections, or IP hash, ensuring optimal distribution of traffic.\n\n```\nupstream backend_servers {\n    ip_hash;\n    server backend1.example.com;\n    server backend2.example.com;\n    server backend3.example.com;\n}\n\nserver {\n    listen 80;\n    server_name example.com;\n\n    location / {\n        proxy_pass http://backend_servers;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    }\n}\n```\n\nNginx uses **round robin** by default. To change it, we can simply add the required algorithm (eg.. **ip\\_hash**) in the `upstream` block.\n\nWith this configuration, Nginx will balance requests among `backend1`, `backend2`, and `backend3`, ensuring no single server becomes overwhelmed.\n\n* * *\n\n# 3\\. Summary\n\nHere’s a table summarizing the key details:\n\n[![](https://substackcdn.com/image/fetch/$s_!NSoF!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2aa8d0f5-5ece-4ec1-9241-6eb5f33a523b_2144x1056.png)](https://substackcdn.com/image/fetch/$s_!NSoF!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2aa8d0f5-5ece-4ec1-9241-6eb5f33a523b_2144x1056.png)\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/proxy-vs-reverse-proxy-explained?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![Kushal Das's avatar](https://substackcdn.com/image/fetch/$s_!WuiR!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bbf932b-0814-460b-9243-497ed8f33127_144x144.png)](https://substack.com/profile/87178442-kushal-das)[![Vijay Kumar Didwania's avatar](https://substackcdn.com/image/fetch/$s_!s0qw!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d08d49e-172f-4b0f-a6dc-903d37fbea91_96x96.jpeg)](https://substack.com/profile/161659273-vijay-kumar-didwania)[![Kranthi N's avatar](https://substackcdn.com/image/fetch/$s_!ojtB!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F65cb8562-a2cb-493e-af09-4674cf970628_96x96.png)](https://substack.com/profile/244274548-kranthi-n)[![Sayan's avatar](https://substackcdn.com/image/fetch/$s_!a5DG!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69eb9cd0-2f5d-4e2a-a964-3cc379a6f956_734x736.jpeg)](https://substack.com/profile/7437441-sayan)[![Jawahar's avatar](https://substackcdn.com/image/fetch/$s_!UrNX!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4bfd7200-1ede-434f-9037-380cc16fd109_1167x1169.jpeg)](https://substack.com/profile/33915730-jawahar)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/proxy-vs-reverse-proxy-explained"
    },
    {
      "article_title": "System Design: What is Scalability?",
      "article_title_citation": "https://blog.algomaster.io/p/scalability",
      "article_content_markdown": "As a system grows, the performance starts to **degrade** unless we adapt it to deal with that growth.\n\n**Scalability** is the property of a system to handle a growing amount of load by **adding resources** to the system.\n\n> A system that can continuously evolve to support a growing amount of work is scalable.\n\nIn this article, we will explore different ways a system can grow and common ways to make a system scalable.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n# How can a System Grow?\n\nA system can grow in several dimensions.\n\n[![](https://substackcdn.com/image/fetch/$s_!ND0I!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52ae3453-524b-4b9b-ace5-fe6ef1690255_1834x1066.png)](https://substackcdn.com/image/fetch/$s_!ND0I!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52ae3453-524b-4b9b-ace5-fe6ef1690255_1834x1066.png)\n\n#### 1\\. Growth in User Base\n\nMore users started using the system, leading to increased number of requests.\n\n- **Example:** A social media platform experiencing a surge in new users.\n\n\n#### 2\\. Growth in Features\n\nMore features were introduced to expand the system's capabilities.\n\n- **Example:** An e-commerce website adding support for a new payment method.\n\n\n#### 3\\. Growth in Data Volume\n\nGrowth in the amount of data the system stores and manages due to user activity or logging.\n\n- **Example:** A video streaming platform like youtube storing more video content over time.\n\n\n#### 4\\. Growth in Complexity\n\nThe system's architecture evolves to accommodate new features, scale, or integrations, resulting in additional components and dependencies.\n\n- **Example:** A system that started as a simple application is broken into smaller, independent systems.\n\n\n#### 5\\. Growth in Geographic Reach\n\nThe system is expanded to serve users in new regions or countries.\n\n- **Example:** An e-commerce company launching websites and distribution in new international markets.\n\n\n[Share](https://blog.algomaster.io/p/scalability?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n# How to Scale a System?\n\nHere are 10 common ways to make a system scalable:\n\n### 1\\. Vertical Scaling (Scale up)\n\nThis means adding more power to your existing machines by upgrading server with more RAM, faster CPUs, or additional storage.\n\nIt's a good approach for simpler architectures but has limitations in how far you can go.\n\n[![](https://substackcdn.com/image/fetch/$s_!ks4s!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03b5da02-dfdf-413e-8c31-72542bf1712b_1086x556.png)](https://substackcdn.com/image/fetch/$s_!ks4s!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03b5da02-dfdf-413e-8c31-72542bf1712b_1086x556.png)\n\n### 2\\. Horizontal Scaling (Scale out)\n\nThis means adding more machines to your system to spread the workload across multiple servers.\n\nIt's often considered the most effective way to scale for large systems.\n\n[![](https://substackcdn.com/image/fetch/$s_!f-c9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdfa4e242-45c5-4ae3-8bdd-bef0193f8e3c_1180x426.png)](https://substackcdn.com/image/fetch/$s_!f-c9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdfa4e242-45c5-4ae3-8bdd-bef0193f8e3c_1180x426.png)\n\n> **Example:** Netflix uses horizontal scaling for its streaming service, adding more servers to their clusters to handle the growing number of users and data traffic.\n\n### 3\\. Load Balancing\n\nLoad balancing is the process of distributing traffic across multiple servers to ensure no single server becomes overwhelmed.\n\n[![](https://substackcdn.com/image/fetch/$s_!xC1h!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e916f2f-303d-4ed2-b0d1-10975404ea05_832x1000.png)](https://substackcdn.com/image/fetch/$s_!xC1h!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e916f2f-303d-4ed2-b0d1-10975404ea05_832x1000.png)\n\n> **Example:** Google employs load balancing extensively across its global infrastructure to distribute search queries and traffic evenly across its massive server farms.\n\n### 4\\. Caching\n\nCaching is a technique to store frequently accessed data in-memory (like RAM) to reduce the load on the server or database.\n\nImplementing caching can dramatically improve response times.\n\n[![](https://substackcdn.com/image/fetch/$s_!fNPz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F597ef66a-1639-4cec-83d6-259f02ef03fa_1406x896.png)](https://substackcdn.com/image/fetch/$s_!fNPz!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F597ef66a-1639-4cec-83d6-259f02ef03fa_1406x896.png)\n\n> **Example:** Reddit uses caching to store frequently accessed content like hot posts and comments so that they can be served quickly without querying the database each time.\n\n### 5\\. Content Delivery Networks (CDNs)\n\nCDN distributes static assets (images, videos, etc.) closer to users. This can reduce latency and result in faster load times.\n\n> **Example:** Cloudflare provides CDN services, speeding up website access for users worldwide by caching content in servers located close to users.\n\n[![Map of globally distributed servers serving content - What is a CDN](https://substackcdn.com/image/fetch/$s_!O26s!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53e92b3d-791e-4951-8b6b-eb1d9b2bcea2_5667x2834.png)](https://substackcdn.com/image/fetch/$s_!O26s!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53e92b3d-791e-4951-8b6b-eb1d9b2bcea2_5667x2834.png) Credit: https://www.cloudflare.com/learning/cdn/what-is-a-cdn/\n\n### 6\\. Sharding/Partitioning\n\nPartitioning means splitting data or functionality across multiple nodes/servers to distribute workload and avoid bottlenecks.\n\n[![](https://substackcdn.com/image/fetch/$s_!sVeK!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2eb7898-e932-49f7-b7d5-849b2eafcdbf_1228x1180.png)](https://substackcdn.com/image/fetch/$s_!sVeK!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2eb7898-e932-49f7-b7d5-849b2eafcdbf_1228x1180.png)\n\n> **Example:** Amazon DynamoDB uses partitioning to distribute data and traffic for its NoSQL database service across many servers, ensuring fast performance and scalability.\n\n### 7\\. Asynchronous communication\n\nAsynchronous communication means deferring long-running or non-critical tasks to background queues or message brokers.\n\nThis ensures your main application remains responsive to users.\n\n> **Example:** Slack uses asynchronous communication for messaging. When a message is sent, the sender's interface doesn't freeze; it continues to be responsive while the message is processed and delivered in the background.\n\n### 8\\. Microservices Architecture\n\nMicro-services architecture breaks down application into smaller, independent services that can be scaled independently.\n\nThis improves resilience and allows teams to work on specific components in parallel.\n\n[![](https://substackcdn.com/image/fetch/$s_!ks0o!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cedcfb2-b859-4ec5-abf4-0173202be17c_1212x482.png)](https://substackcdn.com/image/fetch/$s_!ks0o!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cedcfb2-b859-4ec5-abf4-0173202be17c_1212x482.png)\n\n> **Example:** Uber has evolved its architecture into microservices to handle different functions like billing, notifications, and ride matching independently, allowing for efficient scaling and rapid development.\n\n### 9\\. Auto-Scaling\n\nAuto-Scaling means automatically adjusting the number of active servers based on the current load.\n\nThis ensures that the system can handle spikes in traffic without manual intervention.\n\n[![](https://substackcdn.com/image/fetch/$s_!seU2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd61097f-944f-4f47-b713-8cb25275c53b_1296x428.png)](https://substackcdn.com/image/fetch/$s_!seU2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd61097f-944f-4f47-b713-8cb25275c53b_1296x428.png)\n\n> **Example:** AWS Auto Scaling monitors applications and automatically adjusts capacity to maintain steady, predictable performance at the lowest possible cost.\n\n### 10\\. Multi-region Deployment\n\nDeploy the application in multiple data centers or cloud regions to reduce latency and improve redundancy.\n\n> **Example:** Spotify uses multi-region deployments to ensure their music streaming service remains highly available and responsive to users all over the world, regardless of where they are located.\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/scalability?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![Chand Sharma's avatar](https://substackcdn.com/image/fetch/$s_!_KhY!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55f8d3eb-4d6e-421d-986c-7bbf06a8003c_96x96.jpeg)](https://substack.com/profile/211216906-chand-sharma)[![Sairam0000's avatar](https://substackcdn.com/image/fetch/$s_!rgeO!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabb4016d-0b6d-497d-a1d0-0e35d0755442_144x144.png)](https://substack.com/profile/178012041-sairam0000)[![Aakash Paul's avatar](https://substackcdn.com/image/fetch/$s_!9e1b!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57df78d2-ab07-4c86-850d-6b0d026b4ca6_96x96.jpeg)](https://substack.com/profile/12453052-aakash-paul)[![Tiger Abrodi's avatar](https://substackcdn.com/image/fetch/$s_!GE08!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6147c0a-6f1f-45e8-bf11-a22e4d0591a5_2389x2523.jpeg)](https://substack.com/profile/70741339-tiger-abrodi)[![Nigam's avatar](https://substackcdn.com/image/fetch/$s_!55WA!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39c4217b-8dc0-44ed-a82b-c9ec79331bfb_512x512.png)](https://substack.com/profile/208980828-nigam)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/scalability"
    },
    {
      "article_title": "System Design: What is Availability?",
      "article_title_citation": "https://blog.algomaster.io/p/system-design-what-is-availability",
      "article_content_markdown": "In this blog, we'll explore the concept of availability, availability tiers, strategies to improve availability, and best practices for achieving high availability.\n\n# What is Availability?\n\n> Availability refers to the proportion of time a system is operational and accessible when required.\n\nIt is usually expressed as a percentage, indicating the system's uptime over a specific period.\n\nThe formal definition of availability is:\n\n```\nAvailability = Uptime / (Uptime + Downtime)\n```\n\n**Uptime**: The period during which a system is functional and accessible.\n\n**Downtime**: The period during which a system is unavailable due to failures, maintenance, or other issues.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n# Availability Tiers\n\nAvailability is often expressed in `\"nines\"`. The higher the availability, the less downtime there is.\n\n[![](https://substackcdn.com/image/fetch/$s_!b4Is!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe271d918-4a3b-4c74-ada6-6ce1b01a30ef_1632x912.png)](https://substackcdn.com/image/fetch/$s_!b4Is!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe271d918-4a3b-4c74-ada6-6ce1b01a30ef_1632x912.png)\n\nEach additional \"nine\" represents an order of magnitude improvement in availability.\n\n> **Example:** 99.99% availability represents a **10-fold** improvement in uptime compared to 99.9%.\n\n[Share](https://blog.algomaster.io/p/system-design-what-is-availability?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n# Strategies for Improving Availability\n\n## 1\\. Redundancy\n\nRedundancy involves having backup components that can take over when primary components fail.\n\n[![](https://substackcdn.com/image/fetch/$s_!a2HP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63a5b30f-7a6c-4d51-951f-f3a6bbdd1762_822x670.png)](https://substackcdn.com/image/fetch/$s_!a2HP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63a5b30f-7a6c-4d51-951f-f3a6bbdd1762_822x670.png)\n\n#### **Techniques:**\n\n- **Server Redundancy**: Deploying multiple servers to handle requests, ensuring that if one server fails, others can continue to provide service.\n\n- **Database Redundancy:** Creating a replica database that can take over if the primary database fails.\n\n- **Geographic Redundancy**: Distributing resources across multiple geographic locations to mitigate the impact of regional failures.\n\n\n## 2\\. Load Balancing\n\nLoad balancing distributes incoming network traffic across multiple servers to ensure no single server becomes a bottleneck, enhancing both performance and availability.\n\n[![](https://substackcdn.com/image/fetch/$s_!I8dJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7c69a4f-3b6e-42d9-af13-852c3f6fc5af_832x1000.png)](https://substackcdn.com/image/fetch/$s_!I8dJ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7c69a4f-3b6e-42d9-af13-852c3f6fc5af_832x1000.png)\n\n#### Techniques:\n\n- **Hardware Load Balancers**: Physical devices that distribute traffic based on pre-configured rules.\n\n- **Software Load Balancers**: Software solutions that manage traffic distribution, such as HAProxy, Nginx, or cloud-based solutions like AWS Elastic Load Balancer.\n\n\n## 3\\. Failover Mechanisms\n\nFailover mechanisms automatically switch to a redundant system when a failure is detected.\n\n[![](https://substackcdn.com/image/fetch/$s_!oQaI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84715a05-01d5-4ebf-abf7-5c510efc6beb_1340x592.png)](https://substackcdn.com/image/fetch/$s_!oQaI!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84715a05-01d5-4ebf-abf7-5c510efc6beb_1340x592.png)\n\n#### Techniques:\n\n- **Active-Passive Failover**: A primary active component is backed by a passive standby component that takes over upon failure.\n\n- **Active-Active Failover**: All components are active and share the load. If one fails, the remaining components continue to handle the load seamlessly.\n\n\n## 4\\. Data Replication\n\nData replication involves copying data from one location to another to ensure that data is available even if one location fails.\n\n[![](https://substackcdn.com/image/fetch/$s_!G9YJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F639c6206-d78d-4e65-af22-72fe8d224244_878x498.png)](https://substackcdn.com/image/fetch/$s_!G9YJ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F639c6206-d78d-4e65-af22-72fe8d224244_878x498.png)\n\n#### Techniques:\n\n- **Synchronous Replication**: Data is replicated in real-time to ensure consistency across locations.\n\n- **Asynchronous Replication**: Data is replicated with a delay, which can be more efficient but may result in slight data inconsistencies.\n\n\n## 5\\. Monitoring and Alerts\n\nContinuous health monitoring involves checking the status of system components to detect failures early and trigger alerts for immediate action.\n\n[![](https://substackcdn.com/image/fetch/$s_!vOJ8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F812131b9-9aa0-4db5-b4ac-bd15ee58116c_612x458.png)](https://substackcdn.com/image/fetch/$s_!vOJ8!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F812131b9-9aa0-4db5-b4ac-bd15ee58116c_612x458.png)\n\n#### Techniques:\n\n- **Heartbeat Signals**: Regular signals sent between components to check their status.\n\n- **Health Checks**: Automated scripts or tools that perform regular health checks on components.\n\n- **Alerting Systems**: Tools like PagerDuty or OpsGenie that notify administrators of detected issues.\n\n\n# Best Practices for High Availability\n\n1. **Design for Failure**: Assume that any component of your system can fail at any time and design your system accordingly.\n\n2. **Implement Health Checks**: Regular health checks allow you to detect and respond to issues before they become critical failures.\n\n3. **Use Multiple Availability Zones**: Distribute your system across different data centers to prevent localized failures.\n\n4. **Practice Chaos Engineering**: Intentionally introduce failures to test system resilience.\n\n5. **Implement Circuit Breakers**: Prevent cascading failures by quickly cutting off problematic services.\n\n6. **Use Caching Wisely**: Caching can improve availability by reducing load on backend systems.\n\n7. **Plan for Capacity**: Ensure your system can handle both expected and unexpected load increases.\n\n\nAvailability is a critical aspect of system design that ensures users can access services reliably and continuously.\n\nBy implementing strategies like redundancy, load balancing, failover mechanisms, and data replication, you can design highly available systems.\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/system-design-what-is-availability?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![Sai Keerthan Palavarapu's avatar](https://substackcdn.com/image/fetch/$s_!747Y!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8c3bf59-88ec-4fbd-a42e-a46c1a35707b_144x144.png)](https://substack.com/profile/188627818-sai-keerthan-palavarapu)[![Sandeep Pandey's avatar](https://substackcdn.com/image/fetch/$s_!MAYm!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8aa02f62-6384-4010-bea3-18877ff4c7f9_96x96.png)](https://substack.com/profile/153236202-sandeep-pandey)[![Nagender Aneja's avatar](https://substackcdn.com/image/fetch/$s_!Hc_P!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F66676bfe-fced-407a-a4f5-e90508a3ab82_306x306.jpeg)](https://substack.com/profile/15548094-nagender-aneja)[![Swapnil Srivastava's avatar](https://substackcdn.com/image/fetch/$s_!0miu!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77a635e7-a7b2-4bda-a4f0-1b092875ed0c_144x144.png)](https://substack.com/profile/76399-swapnil-srivastava)[![Mayur Sonowal's avatar](https://substackcdn.com/image/fetch/$s_!-Nwg!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F893da79d-8420-46ae-9ee9-4a9d0825e4ef_144x144.png)](https://substack.com/profile/113641078-mayur-sonowal)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/system-design-what-is-availability"
    },
    {
      "article_title": "System Design: How to Avoid Single Point of Failures?",
      "article_title_citation": "https://blog.algomaster.io/p/system-design-how-to-avoid-single-point-of-failures",
      "article_content_markdown": "A **Single Point of Failure (SPOF)** is a component in your system whose failure can bring down the entire system, causing downtime, potential data loss, and unhappy users.\n\n[![](https://substackcdn.com/image/fetch/$s_!V89-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F312b09fc-5d30-4ab8-8520-4e50f64c0328_979x360.png)](https://substackcdn.com/image/fetch/$s_!V89-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F312b09fc-5d30-4ab8-8520-4e50f64c0328_979x360.png) **Created using [Multiplayer](https://dub.sh/flNw5qt)**\n\nIn the above example, if there is only one instance of the **load balancer,** it becomes a SPOF. If it goes down, clients won’t be able to communicate with the servers.\n\nBy minimizing the number of SPOFs, you can improve the overall **reliability** and **availability** of the system.\n\nIn this article, we'll explore what a SPOF is, how to identify it in a distributed system, and strategies to avoid it.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n## **1\\. Understanding SPOFs**\n\nA Single Point of Failure (SPOF) is any component within a system whose failure would cause the entire system to stop functioning.\n\n> Imagine a bridge that connects two cities. If it's the only route between them and it collapses, the cities are cut off. In this scenario, the bridge is the single point of failure.\n\nIn distributed systems, failures are inevitable. Common causes include **hardware malfunctions**, **software bugs**, **power outages**, **network disruptions**, and **human error**.\n\nWhile failures can't be entirely avoided, the goal is to ensure they don’t bring down the entire system.\n\nIn system design, SPOFs can include a single server, network link, database, or any component that lacks redundancy or backup.\n\nLet’s see an example of a system and various single points of failures in it:\n\n[![](https://substackcdn.com/image/fetch/$s_!qMnO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa503119a-3ab3-48ed-bf90-bc33fd83c03c_1314x604.png)](https://substackcdn.com/image/fetch/$s_!qMnO!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa503119a-3ab3-48ed-bf90-bc33fd83c03c_1314x604.png) **Created using [Multiplayer](https://dub.sh/flNw5qt)**\n\nThis system has one load balancer, two application servers, one database, and one cache server.\n\nClients send requests to the load balancer, which distributes traffic across the two application servers. The application servers retrieve data from the cache if it's available, or from the database if it's not.\n\nIn this design, the potential SPOFs are:\n\n- **Load Balancer**: If there is only one load balancer instance and it fails, all traffic will stop, preventing clients from reaching the application servers. To avoid this, we can add a **standby** load balancer that can takeover if the primary one fails.\n\n- **Database**: With only one database, its failure would result in data being unavailable, causing downtime and potential data loss. We can avoid this by **replicating** the data across multiple servers and locations.\n\n- **Cache Server**: The cache server is not a true SPOF in the sense that it doesn’t bring the entire system down. When it’s down, every request hits the database, increasing its load and slowing response times.\n\n\nThe **application servers** are not SPOFs since you have two of them. If one fails, the other can still handle requests, assuming the load balancer can distribute traffic effectively.\n\n[Share](https://blog.algomaster.io/p/system-design-how-to-avoid-single-point-of-failures?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n## **2\\. How to Identify SPOFs in a Distributed System**\n\n### 1\\. **Map Out the Architecture**\n\nCreate a detailed diagram of your system's architecture. Identify all components, services, and their dependencies.\n\nLook for components that do not have backups or redundancy.\n\n### 2\\. **Dependency Analysis**\n\nAnalyze dependencies between different services and components.\n\nIf a single component is required by multiple services and does not have a backup, it is likely a SPOF.\n\n### 3\\. **Failure Impact Assessment**\n\nAssess the impact of failure for each component.\n\nPerform a **\"what if\"** analysis for each component.\n\nAsk questions like, “What if this component fails?” If the answer is that the system would stop functioning or degrade significantly, then that component is a SPOF.\n\n### 4\\. **Chaos Testing**\n\nChaos testing, also known as Chaos Engineering, is the practice of intentionally injecting failures and disruptions into a system to understand how it behaves under stress and to ensure it can recover gracefully.\n\nChaos engineering often involves the use of tools like **[Chaos Monkey](https://github.com/Netflix/chaosmonkey)** (developed by Netflix) that randomly shut down instances or services to observe how the rest of the system responds.\n\nThis can help us identify components that, if they fail, would cause a significant impact on the system.\n\n* * *\n\n## **3\\. Strategies to Avoid Single Points of Failures**\n\n### **1\\. Redundancy**\n\nThe most common way to avoid SPOFs is by adding **redundancy**. Redundancy means having multiple components that can take over if one fails.\n\nRedundant components can be either **active** or **passive**. Active components are always running. Passive (standby) components are only used as a backup when the active component fails.\n\n[![](https://substackcdn.com/image/fetch/$s_!oUFW!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbee6c03-c8cf-42cf-b9c0-c163b7ca7433_736x290.png)](https://substackcdn.com/image/fetch/$s_!oUFW!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbee6c03-c8cf-42cf-b9c0-c163b7ca7433_736x290.png) **Created using [Multiplayer](https://dub.sh/flNw5qt)**\n\n### **2\\. Load Balancing**\n\nLoad balancers distribute incoming traffic across multiple servers, ensuring no single server becomes overwhelmed.\n\n[![](https://substackcdn.com/image/fetch/$s_!BEMO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09639c8a-4b8f-4867-a278-6d699e0ed440_704x753.png)](https://substackcdn.com/image/fetch/$s_!BEMO!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09639c8a-4b8f-4867-a278-6d699e0ed440_704x753.png) **Created using [Multiplayer](https://dub.sh/flNw5qt)**\n\nThey help avoid single point of failures by detecting failed servers and rerouting traffic to healthy instances.\n\n### **3\\. Data Replication**\n\nData replication involves copying data from one location to another to ensure that data is available even if one location fails.\n\n- **Synchronous Replication**: Data is replicated in real-time to ensure consistency across locations.\n\n- **Asynchronous Replication**: Data is replicated with a delay, which can be more efficient but may result in slight data inconsistencies.\n\n\n### **4\\. Geographic Distribution**\n\nDistributing services and data across multiple geographic locations mitigates the risk of regional failures.\n\nThis includes using:\n\n- **Content Delivery Networks (CDNs)** to distribute content globally, improving availability and reducing latency.\n\n- **Multi-Region Cloud Deployments** to ensure that an outage in one region does not disrupt your entire application.\n\n\n### **5\\. Graceful Handling of Failures**\n\nDesign applications to handle failures without crashing.\n\n> **Example:** If a service that provides user recommendations fails, the application should still function, perhaps with a message indicating limited features temporarily.\n\nImplement failover mechanisms to automatically switch to backup systems when failures are detected.\n\n[![](https://substackcdn.com/image/fetch/$s_!0vXV!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4054072f-4ec1-4af8-9540-8e97179f9841_1212x692.png)](https://substackcdn.com/image/fetch/$s_!0vXV!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4054072f-4ec1-4af8-9540-8e97179f9841_1212x692.png) **Sketched using [Multiplayer](https://dub.sh/flNw5qt)**\n\n### 6\\. Monitoring and Alerting\n\nProactive monitoring helps detect failures before they lead to major outages.\n\nKey practices include:\n\n- **Health Checks**: Automated tools that perform regular health checks on components.\n\n- **Automated Alerts**: Alerts and notifications sent when a component fails or behaves abnormally.\n\n- **Self-Healing Systems**: Systems that automatically recover from failures, such as auto-scaling to replace failed servers.\n\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/system-design-how-to-avoid-single-point-of-failures?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![Anton Ganeshalingam's avatar](https://substackcdn.com/image/fetch/$s_!9lKQ!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a710bff-957c-4eb1-b381-b250b727d950_144x144.png)](https://substack.com/profile/187945673-anton-ganeshalingam)[![muhamad haikal's avatar](https://substackcdn.com/image/fetch/$s_!Y6Jp!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e5cb758-d452-47a7-8542-988e84e65116_96x96.jpeg)](https://substack.com/profile/95654891-muhamad-haikal)[![Amit Jha's avatar](https://substackcdn.com/image/fetch/$s_!Ilr-!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc82212fa-7634-4737-aa1b-b0f6aaaef1b8_144x144.png)](https://substack.com/profile/83092407-amit-jha)[![Ranjeet Nair's avatar](https://substackcdn.com/image/fetch/$s_!UwMO!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d9bcd05-70cb-46a8-a30e-fbc575c0beed_144x144.png)](https://substack.com/profile/94327944-ranjeet-nair)[![Pramod's avatar](https://substackcdn.com/image/fetch/$s_!Rx57!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff954ba60-377d-4407-9a93-b166861c16f1_3072x4080.jpeg)](https://substack.com/profile/104820979-pramod)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/system-design-how-to-avoid-single-point-of-failures"
    },
    {
      "article_title": "CAP Theorem Explained",
      "article_title_citation": "https://blog.algomaster.io/p/cap-theorem-explained",
      "article_content_markdown": "The **CAP theorem**, introduced by Eric Brewer in 2000, provides a fundamental framework for understanding the **trade-offs** that must be made when designing distributed systems.\n\n[![](https://substackcdn.com/image/fetch/$s_!vOjG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40850582-9eaf-48e2-a254-43817c4d60c0_951x792.png)](https://substackcdn.com/image/fetch/$s_!vOjG!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40850582-9eaf-48e2-a254-43817c4d60c0_951x792.png)\n\nCAP stands for **Consistency**, **Availability**, and **Partition Tolerance**, and the theorem states that:\n\n> **It is impossible for a distributed data store to simultaneously provide all three guarantees.**\n\n- **Consistency (C)**: Every read receives the most recent write or an error.\n\n- **Availability (A)**: Every request (read or write) receives a non-error response, without guarantee that it contains the most recent write.\n\n- **Partition Tolerance (P)**: The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network between nodes.\n\n\nIn this article, we will explore the the 3 pillars of CAP theorem, trade-offs, and practical design strategies for building resilient and scalable distributed systems.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n# 3 Pillars of CAP\n\n## **1\\. Consistency**\n\nConsistency ensures that **every read receives the most recent write** **or an error**. This means that all working nodes in a distributed system will return the same data at any given time.\n\n[![](https://substackcdn.com/image/fetch/$s_!y3bc!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6cda484-672c-4009-9cda-69a8e36e95a3_1166x932.png)](https://substackcdn.com/image/fetch/$s_!y3bc!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6cda484-672c-4009-9cda-69a8e36e95a3_1166x932.png)\n\n> In a consistent distributed system, if you write data to node A, a read operation from node B will immediately reflect the write operation on node A.\n\nConsistency is crucial for applications where having the most up-to-date data is critical, such as financial systems, where a balance inquiry must reflect the most up-to-date state of an account.\n\n## **2\\. Availability**\n\nAvailability guarantees that **every request (read or write) receives a response**, without ensuring that it contains the most recent write. This means that the system remains **operational** and **responsive**, even if the response from some of the nodes don’t reflect most up-to-date data.\n\n[![](https://substackcdn.com/image/fetch/$s_!3lf-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d8ccf80-2bee-4ff6-8cc4-005a418da7ae_1188x868.png)](https://substackcdn.com/image/fetch/$s_!3lf-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d8ccf80-2bee-4ff6-8cc4-005a418da7ae_1188x868.png)\n\nAvailability is important for applications that need to remain operational at all times, such as online retail systems.\n\n## **3\\. Partition Tolerance**\n\nPartition Tolerance means that the **system continues to function despite network partitions** where nodes cannot communicate with each other.\n\n[![](https://substackcdn.com/image/fetch/$s_!13Kz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73a83347-71c5-4d8f-9487-ff41b5bc1333_844x858.png)](https://substackcdn.com/image/fetch/$s_!13Kz!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73a83347-71c5-4d8f-9487-ff41b5bc1333_844x858.png)\n\n> A **network partition** occurs when a network failure causes a distributed system to split into two or more groups of nodes that cannot communicate with each other.\n\nWhen there is a network partition, the system must choose between **Consistency** and **Availability**.\n\nPartition Tolerance is essential for distributed systems because network failures can and do happen. A system that tolerates partitions can maintain operations across different network segments.\n\n[Share](https://blog.algomaster.io/p/cap-theorem-explained?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n# The CAP Trade-Off: Choosing 2 out of 3\n\nThe CAP theorem asserts that in the presence of a network partition, a distributed system must choose between **Consistency** and **Availability**.\n\nLet's explore these scenarios:\n\n## **CP (Consistency and Partition Tolerance):**\n\nThese systems prioritize consistency and can tolerate network partitions, but at the cost of availability. During a partition, the system may reject some requests to maintain consistency.\n\nTraditional relational databases, such as MySQL and PostgreSQL, when configured for strong consistency, prioritize consistency over availability during network partitions.\n\n> **Banking systems** typically prioritize **consistency over availability** since data accuracy is more critical than availability during network issues.\n>\n> Consider an ATM network for a bank. When you withdraw money, the system must ensure that your balance is updated accurately across all nodes (consistency) to prevent overdrafts or other errors.\n\n## **AP (Availability and Partition Tolerance):**\n\nThese systems ensure availability and can tolerate network partitions, but at the cost of consistency. During a partition, different nodes may return different values for the same data.\n\nNoSQL databases like Cassandra and DynamoDB are designed to be highly available and partition-tolerant, potentially at the cost of strong consistency.\n\n> **Amazon's** shopping cart system is designed to always accept items, prioritizing availability.\n>\n> When you add items to your Amazon cart, the action almost never fails, even during high traffic periods like Black Friday.\n\n## **CA (Consistency and Availability):**\n\nIn the absence of partitions, a system can be both consistent and available. However, network partitions are inevitable in distributed systems, making this combination impractical.\n\n**Example Systems:** Single-node databases can provide both consistency and availability but aren't partition-tolerant. In a distributed setting, this combination is theoretically impossible.\n\n# Practical Design Strategies\n\nDesigning distributed systems requires carefully balancing these trade-offs based on application requirements.\n\nHere are some practical strategies:\n\n## **1\\. Eventual Consistency**\n\nFor many systems, strict consistency isn't always necessary.\n\nEventual consistency can provide a good balance where updates are propagated to all nodes eventually, but not immediately.\n\n> **Example:** Systems where immediate consistency is not critical, such as DNS and content delivery networks (CDNs).\n\n## **2\\. Strong Consistency**\n\nA model ensuring that once a write is confirmed, any subsequent reads will return that value.\n\n> **Example:** Systems requiring high data accuracy, like financial applications and inventory management.\n\n## **3\\. Tunable Consistency**\n\nTunable consistency allows systems to adjust their consistency levels based on specific needs, providing a balance between strong and eventual consistency.\n\nSystems like Cassandra allow configuring the level of consistency on a per-query basis, providing flexibility.\n\n> **Example:** Applications needing different consistency levels for different operations, such as e-commerce platforms where order processing requires strong consistency but product recommendations can tolerate eventual consistency.\n\n## **4\\. Quorum-Based Approaches:**\n\nQuorum-based approaches use voting among a group of nodes to ensure a certain level of consistency and fault tolerance.\n\n> **Example:** Systems needing a balance between consistency and availability, often used in consensus algorithms like Paxos and Raft.\n\n# Beyond CAP: PACELC\n\nWhile CAP is foundational, it doesn't cover all scenarios.\n\nDaniel Abadi proposed the **[PACELC](https://en.wikipedia.org/wiki/PACELC_theorem)** theorem as an extension by introducing **latency** and **consistency** as additional attributes of distributed systems.\n\n- If there is a partition (P), the trade-off is between availability and consistency (A and C).\n\n- Else (E), the trade-off is between **latency (L)** and **consistency (C)**.\n\n\nThis theorem acknowledges that even when the system is running normally, there's a tradeoff between latency and consistency.\n\nIn conclusion, the CAP Theorem is a powerful tool for understanding the inherent trade-offs in distributed system design. It's not about choosing the \"best\" property, but rather about making informed decisions based on the specific needs of your application.\n\nBy carefully evaluating the CAP trade-offs, you can architect robust and resilient systems that deliver the right balance of consistency, availability, and partition tolerance.\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/cap-theorem-explained?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![Achyut Ghosh's avatar](https://substackcdn.com/image/fetch/$s_!kn4F!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc09addd0-d7f7-493f-b281-96f82f669f5d_96x96.png)](https://substack.com/profile/246578430-achyut-ghosh)[![Aparna Panwar's avatar](https://substackcdn.com/image/fetch/$s_!ph29!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9349464f-af73-4cc5-aaf2-ab9470fe4e8e_1176x1176.jpeg)](https://substack.com/profile/88673369-aparna-panwar)[![Hemant Pandey's avatar](https://substackcdn.com/image/fetch/$s_!G-vB!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5d8aef1-0399-40a0-9537-5615ca0fe8d4_1166x1167.jpeg)](https://substack.com/profile/58770480-hemant-pandey)[![Bharath R B's avatar](https://substackcdn.com/image/fetch/$s_!Flrk!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34872fb6-8ce0-4e79-9cc6-5d48c52d48dc_144x144.png)](https://substack.com/profile/16124651-bharath-r-b)[![Pradeep's avatar](https://substackcdn.com/image/fetch/$s_!JqyG!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8aecfcae-946a-4943-a6b7-cc35f52bfa89_144x144.png)](https://substack.com/profile/225192662-pradeep)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/cap-theorem-explained"
    },
    {
      "article_title": "15 Types of Databases and When to Use Them",
      "article_title_citation": "https://blog.algomaster.io/p/15-types-of-databases",
      "article_content_markdown": "Databases are foundational building blocks of System Design used to store, manage and retrieve data efficiently.\n\n[![](https://substackcdn.com/image/fetch/$s_!PvX_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F06ea11e0-0161-4f3c-a2ed-99c766b261a6_1944x1148.png)](https://substackcdn.com/image/fetch/$s_!PvX_!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F06ea11e0-0161-4f3c-a2ed-99c766b261a6_1944x1148.png)\n\nIn this article, we'll explore 15 common types of databases and discuss when to use them, along with examples.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n## 1\\. Relational Databases (RDBMS)\n\nRelational databases structure data into one or more tables of rows and columns, with a unique key identifying each row. Rows in a table can be linked to rows in other tables through foreign keys, establishing a relationship between them.\n\nThis structure allows relational databases to handle large amounts of structured data, enforce data integrity, and support complex queries and ACID transactions.\n\nThey use Structured Query Language (SQL) for defining, manipulating, and querying data, making them highly versatile and widely used in various applications.\n\n#### **Common Use-cases:**\n\n- **Enterprise Applications:** For managing customer data, inventory, employee records, and financial transactions, where data integrity and relationships are critical.\n\n- **E-commerce Platforms:** Handling product catalogs, customer orders, and payment transactions, requiring complex queries and transaction processing.\n\n- **Banking and Financial Services:** Managing accounts, transactions, and user data, where the ACID properties ensure the reliability and consistency of financial operations.\n\n\n> **Examples:** MySQL, PostgreSQL, Oracle Database.\n\n## 2\\. Key-Value Store\n\nKey-value stores are NoSQL databases that store data as key-value pairs providing fast retrieval of values based on unique keys.\n\nThey are primarily used when the data model is based on key-value pairs and requires high scalability, availability and throughput.\n\nHowever, they may not be the best fit for applications that require complex querying, data relationships, or strong consistency guarantees.\n\n#### **Common Use-cases:**\n\n- **Session Storage:** Storing and managing user session information such as user preferences, shopping carts or authentication tokens in web applications.\n\n- **Caching:** Implementing caching mechanisms to improve the performance of web applications by storing frequently accessed data in memory for rapid retrieval.\n\n- **Real-time data processing:** Key-value stores can quickly store and retrieve data for real-time analytics, event processing, or message queues.\n\n\n> **Examples:** Redis, DynamoDB.\n\n[Share](https://blog.algomaster.io/p/15-types-of-databases?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n## 3\\. Document Databases\n\nDocument databases, a subset of the broader NoSQL family, are designed to store, manage, and retrieve document-oriented information.\n\nThese databases handle data in a semi-structured format, typically JSON, XML, or BSON, allowing for a more flexible schema than traditional relational databases.\n\nDocument databases are particularly useful in scenarios where the data model evolves frequently, and where fast read and write performance is critical.\n\nHowever, they may not be the best fit for highly structured data or complex transactions spanning multiple documents or collections.\n\n#### **Common Use-cases:**\n\n- **E-commerce Platforms:** Storing product catalogs with diverse attributes, user reviews, and inventory data, allowing for flexible representation of product information.\n\n- **Content Management Systems (CMS):** Ideal for managing articles, user profiles, and comments, where each piece of content can be stored as a document.\n\n- **Real-Time Analytics and IoT:** Handling varied data structures generated by IoT devices and supporting real-time analytics on this data.\n\n\n> **Examples:** MongoDB, Couchbase, and Apache CouchDB\n\n## 4\\. Graph Databases\n\nGraph databases are a type of NoSQL database that specialize in storing, managing, and querying complex networks of interconnected data.\n\nThey represent data as graphs, consisting of nodes (entities), edges (relationships between entities), and properties (information associated with nodes and edges).\n\nBy leveraging the graph structure, graph databases enable efficient traversal, querying, and analysis of interconnected data.\n\nThey are very useful in applications like social networks and recommendation engines.\n\n#### **Common Use-cases:**\n\n- **Social Networks:** Managing user profiles and their connections, enabling features like friend recommendations and social graph analysis.\n\n- **Recommendation Systems:** Analyzing customer preferences, product inventories, and purchase histories to generate personalized product or content recommendations.\n\n- **Knowledge Graphs:** Building vast repositories of interconnected data for semantic searches, information retrieval, and decision support systems.\n\n\n> **Examples:** Neo4j, Amazon Neptune.\n\n## 5\\. Wide-Column Stores\n\nWide-Column Stores represent a type of NoSQL database optimized for storing and querying large amounts of data across many machines.\n\nThey organize data into tables with a flexible and dynamic column structure. They are designed to handle large-scale, distributed data storage and provide high scalability and performance.\n\nTheir column-oriented architecture, flexible schema, and eventual consistency model make them well-suited for applications that require high write throughput and real-time data processing.\n\nHowever, they may not be the best fit for use cases that require complex joins, strong consistency, or strict ACID transactions.\n\n#### **Common Use-Cases:**\n\n- **Web analytics and user tracking:** Ideal for capturing and analyzing event data in real-time, such as web analytics, user activity logs, and network monitoring.\n\n- **Real-Time Analytics:** They can quickly aggregate and analyze data, making them suitable for dashboards, alerting systems, and operational analytics.\n\n\n> **Examples:** Apache Cassandra, Apache HBase, Google Bigtable.\n\n## 6\\. In-Memory Databases\n\nIn-Memory Databases store data directly in the main memory (RAM) of the computer, as opposed to disk-based storage.\n\nThey are designed to provide extremely fast data access and low latency by eliminating the need for disk I/O operations.\n\nIn-memory databases are particularly well-suited for applications that require real-time processing, high-speed transactions, and low-latency data access such as caching, real-time analytics, high-frequency trading.\n\nHowever, they are costly and the main memory may lack sufficient capacity to store the entire dataset.\n\n#### **Common Use-Cases:**\n\n- **Online Gaming:** To manage user sessions and game state in real time, ensuring fast and responsive gameplay experiences.\n\n- **High-Frequency Trading:** They enable a large number of financial transactions per second with minimal latency.\n\n\n> **Examples:** Redis, Memcached.\n\n## 7\\. Time-Series Databases\n\nTime-Series Databases (TSDBs) specialize in storing, retrieving, and managing time-stamped or time-series data.\n\nTime-series data is a sequence of data points collected over time intervals.\n\nTSDBs are commonly used in applications that generate and process time-series data, such as monitoring systems, sensor networks, financial trading platforms, and IoT (Internet of Things) devices.\n\nThey provide the necessary performance, scalability, and specialized features to handle the unique characteristics of time-series data.\n\n#### **Common Use-Cases:**\n\n- **Financial Trading Platforms:** For tracking stock prices, trade volumes, and market indicators over time, enabling trend analysis and algorithmic trading strategies.\n\n- **IoT and Sensor Data Management:** Collecting and analyzing data from sensors and IoT devices, useful in smart homes, industrial automation, and environmental monitoring.\n\n- **Performance Monitoring:** In IT and network infrastructure, to monitor system metrics (CPU usage, memory consumption, network traffic) over time, helping in capacity planning and anomaly detection.\n\n\n> **Examples:** InfluxDB, TimescaleDB, Prometheus.\n\n## 8\\. Object-Oriented Databases\n\nObject-oriented databases (OODB) are databases that store and manipulate data as objects.\n\nThese objects are instances of classes, which can encapsulate both data (attributes) and behaviors (methods), mirroring the structure and concepts of object-oriented programming languages like Java, C++, or Python.\n\nOODBs are particularly well-suited for applications where complex data models are necessary, or the application logic heavily relies on object-oriented principles.\n\nBy allowing developers to work directly with objects in the database, OODBs can simplify the development process and provide a more natural and efficient way to manage complex data structures and relationships.\n\n#### **Common Use-Cases:**\n\n- **Object-Oriented Applications:** Applications developed using OOP languages that require a seamless persistence mechanism for storing and retrieving objects without the need to convert them to a different format (object-relational mapping).\n\n- **Multimedia Databases:** Storing, organizing, and retrieving multimedia items like images, videos, and audio files, which can benefit from the encapsulation of both data and behaviors (e.g., methods to play or edit).\n\n\n> **Examples:** ObjectDB, db4o\n\n## 9\\. Text Search Databases\n\nText Search Databases are specialized systems designed for efficient storage, indexing, and retrieval of large volumes of unstructured or semi-structured text data.\n\nThey provide fast and scalable search capabilities, enabling users to query and find relevant information from vast collections of documents, web pages, or other text-based content.\n\n#### **Common Use-Cases:**\n\n- **E-commerce:** For product searches within online stores, helping customers find products based on descriptions, reviews, and metadata.\n\n- **Web search:** These are used in Search engines like Google, Bing, and DuckDuckGo to index and search the vast amount of content available on the internet, allowing users to find relevant web pages based on their queries.\n\n- **Log analysis:** These can be used to index and search large volumes of log data, such as application logs or system logs, for troubleshooting, monitoring, and analytics purposes.\n\n\n> **Examples:** Elasticsearch, Apache Solr, Sphinx.\n\n## 10\\. Spatial Databases\n\nSpatial databases are designed to store, manage, and analyze data that represents geographical or spatial information. They extend traditional database capabilities to handle complex spatial data types, such as points, lines, polygons, and other geometric shapes, along with their associated attributes and relationships.\n\nSpatial databases employ efficient indexing techniques, such as R-trees or quadtrees, to optimize spatial queries and improve performance.\n\nThey are used heavily in services that are based on the user's location, such as mapping routes, finding nearby restaurants, or tracking vehicle movements in real-time.\n\n#### **Common Use-Cases:**\n\n- **Geographic Information Systems (GIS):** For mapping, analyzing, and managing data related to places on the earth's surface for urban planning, environmental management, and emergency response planning.\n\n- **Location-Based Services (LBS):** To provide services based on the user's location, such as mapping routes and finding nearby restaurants.\n\n- **Logistics and transportation:** Spatial databases are used in logistics and transportation systems to optimize routes, track vehicle movements, and analyze traffic patterns.\n\n\n> **Examples:** PostGIS (extension for PostgreSQL), Oracle Spatial.\n\n## 11\\. Blob Datastore\n\nBlob (Binary Large Object) datastores are designed for storing, managing, and retrieving large blocks of unstructured data, such as images, audio files, videos, and documents.\n\nUnlike traditional databases that handle structured data with well-defined fields and records, blob datastores are optimized for large, complex blobs of data that do not fit neatly into standard database schemas.\n\nThey provide a scalable, highly available, durable and cost-effective solution for managing massive amounts of unstructured data.\n\n#### **Common Use-Cases:**\n\n- **Content Delivery Networks (CDNs):** For storing and delivering large media files, such as videos and images, to users around the globe.\n\n- **Big data storage:** Blob datastores can store large datasets, such as log files, sensor data, and scientific data, for big data analytics and processing pipelines.\n\n- **Backup and archival:** Blob datastores provide a reliable and scalable solution for storing backup data, archives, and long-term data retention. They also offer cost-effective storage options for infrequently accessed data.\n\n\n> **Examples:** Amazon S3, Azure Blob Storage, HDFS.\n\n## 12\\. Ledger Databases\n\n[![](https://substackcdn.com/image/fetch/$s_!RJlW!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e0c77b0-cf76-4110-9a65-5ebe4dbb97a7_1388x678.png)](https://substackcdn.com/image/fetch/$s_!RJlW!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e0c77b0-cf76-4110-9a65-5ebe4dbb97a7_1388x678.png) Credit: https://aws.amazon.com/qldb/\n\nLedger databases also known as blockchain databases are designed to provide an immutable, append-only record of transactions.\n\nThey are engineered to ensure that once a transaction is recorded, it cannot be altered or deleted, providing a verifiable and tamper-evident history of all changes over time.\n\nLedger databases are particularly suitable for applications that require a high level of trust, transparency, and immutability.\n\n#### **Common Use-Cases:**\n\n- **Supply chain management:** Ledger databases can track the movement of goods and materials across a supply chain, ensuring transparency and traceability.\n\n- **Healthcare:** Managing patient records, consent forms, and treatment histories with a clear, unchangeable record.\n\n- **Voting systems:** Ledger databases can provide a secure and transparent platform for conducting voting processes by ensuring the integrity of the voting results and prevent tampering or manipulation.\n\n\n> **Examples:** Amazon Quantum Ledger Database (QLDB), Hyperledger Fabric.\n\n## 13\\. Hierarchical Databases\n\nHierarchical databases organize data into a tree-like structure where data is stored in records, and each record has a single parent record but can have a multiple children, establishing a one-to-many relationship between records.\n\nHierarchical databases were popular in the early days of computing, particularly in mainframe systems. They were commonly used for file systems, where directories and files naturally fit into a hierarchical structure.\n\nHowever, they have largely been replaced by other database models, such as relational databases and NoSQL databases, which offer more flexibility and better support for complex relationships.\n\n#### **Common Use-Cases:**\n\n- **Organizational Structures:** Managing data in organizational charts where each entity (e.g., employee) has a clear hierarchical relationship.\n\n- **File Systems:** The directory structure of file systems is a classic example of hierarchical data, where folders have subfolders and files.\n\n\n> **Examples:** IBM IMS, Windows Registry\n\n## 14\\. Vector Databases\n\nVector databases are specialized databases designed for storing and searching vectors which are arrays of numbers representing data in high-dimensional spaces.\n\nThey are optimized for similarity search and nearest neighbor queries enabling fast retrieval of similar items based on their vector representations.\n\nThese databases are particularly relevant in the field of machine learning and artificial intelligence (AI), where vector representations are commonly used to encode the features of various types of data, including text, images, and audio.\n\n#### **Common Use-Cases:**\n\n- **Image and Video Search:** Vector databases enable content-based image and video retrieval by storing visual features as high-dimensional vectors.\n\n- **Recommendation Systems:** By representing users and items (e.g., products, movies) as vectors, vector databases can quickly identify and recommend items similar to a user's interests.\n\n- **Anomaly detection:** By comparing the similarity of new data points to known normal samples, anomalies can be detected based on their dissimilarity.\n\n\n> **Examples:** Faiss, Milvus, Pinecone.\n\n## 15\\. Embedded Databases\n\nEmbedded databases are specialized databases designed to be tightly integrated into software applications. Unlike traditional client-server databases that run as separate processes, embedded databases are linked and run as part of the application itself.\n\nBy being tightly integrated into the application process, they offer fast data access, small footprint, and simplified deployment.\n\nEmbedded databases are particularly useful in resource-constrained environments where a full-fledged client-server database is not necessary or practical.\n\n#### **Common Use-Cases:**\n\n- **Gaming:** Saving game states, player progress, and configuration settings directly within the game application.\n\n- **Desktop Applications:** Storing configuration settings, user preferences, and application data locally on a user's machine.\n\n\n> **Examples:** SQLite, RocksDB, Berkeley DB.\n\nWhen it comes to choosing a database, there's no one-size-fits-all solution.\n\nThe choice of a database depends on your specific use case, data model, scalability needs, and budget.\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/15-types-of-databases?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![Mayallo's avatar](https://substackcdn.com/image/fetch/$s_!fkFm!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d591bd-62c2-4a22-9ae1-eabf82316f86_144x144.png)](https://substack.com/profile/170616840-mayallo)[![Divyam Raj pandey's avatar](https://substackcdn.com/image/fetch/$s_!2hCt!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79d75cea-cb26-4822-a24e-82395f2e72c3_1080x1080.jpeg)](https://substack.com/profile/211679047-divyam-raj-pandey)[![ROHIT DUBEY's avatar](https://substackcdn.com/image/fetch/$s_!U4dN!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe14bf229-9fbc-4a63-bb04-ea4b90c6da5f_96x96.jpeg)](https://substack.com/profile/145074179-rohit-dubey)[![Sammee Sharma's avatar](https://substackcdn.com/image/fetch/$s_!oniv!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F682df774-812f-4c42-b787-ba67f993d62f_144x144.png)](https://substack.com/profile/210277662-sammee-sharma)[![Dhruval Patel's avatar](https://substackcdn.com/image/fetch/$s_!H-rh!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F374097ca-a2a0-46ed-bb48-9f17b1591a96_1167x1168.jpeg)](https://substack.com/profile/11374085-dhruval-patel)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/15-types-of-databases"
    },
    {
      "article_title": "SQL vs NoSQL - 7 Key Differences You Must Know",
      "article_title_citation": "https://blog.algomaster.io/p/sql-vs-nosql-7-key-differences",
      "article_content_markdown": "One of the biggest decisions we make while designing a system is **choosing between a relational (SQL) or non-relational (NoSQL) database.**\n\n[![](https://substackcdn.com/image/fetch/$s_!3Es9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa81088b7-a188-4089-845a-63936e930a71_1632x1076.png)](https://substackcdn.com/image/fetch/$s_!3Es9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa81088b7-a188-4089-845a-63936e930a71_1632x1076.png)\n\nBoth have their strengths and use cases, but they differ significantly in their approach to **data storage** and **retrieval**.\n\nThis article will explore **7 key differences** between SQL and NoSQL databases to help you understand which might be best suited for your specific needs.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n## 1\\. **Data Model**\n\nThe **data model** of a database defines how data is stored, organized, and related.\n\n### **SQL**\n\n**SQL databases** use a **relational data model** where data is stored in **tables (** often referred to as relations **).**\n\nEach table has **rows** (tuples) representing individual records, and **columns** representing attributes of those records.\n\nThe **primary key** uniquely identifies each record, while **foreign keys** link tables together, allowing for relational queries.\n\n#### Example:\n\nLet’s consider a **user management system** with two tables: `Users` and `Orders`. The `Users` table contains user details, and the `Orders` table stores order details linked to specific users.\n\n[![](https://substackcdn.com/image/fetch/$s_!jxfg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf745269-4458-42fd-a800-a08cfd7df63b_2332x706.png)](https://substackcdn.com/image/fetch/$s_!jxfg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf745269-4458-42fd-a800-a08cfd7df63b_2332x706.png)\n\nThe **UserID** in the `Orders` table is a **foreign key** that references the `Users` table, establishing a relationship between users and their orders.\n\nThis structured approach is ideal for applications requiring **complex queries** and **joins** between tables.\n\n### **NoSQL**\n\nNoSQL databases use **flexible**, **non-relational** data models, allowing for various ways of storing and managing data.\n\n#### a) Key-Value Model (e.g., Redis)\n\nThe key-value model is the simplest NoSQL model, where data is stored as **key-value** pairs. This model works well for applications that need **fast lookups** by a unique key.\n\nFor the same **user management system**, user data can be stored as key-value pairs where the key is the `UserID`, and the value is the associated user information.\n\n```\nKey: 1\nValue: { \"name\": \"John\", \"email\": \"john@email.com\", \"age\": 28 }\n\nKey: 2\nValue: { \"name\": \"Mike\", \"email\": \"mike@email.com\", \"age\": 31 }\n```\n\nThis model is very efficient for **simple lookups**, but it doesn't support complex querying or relationships between data.\n\n#### b) **Document** Model (e.g., MongoDB)\n\nIn the document model, data is stored as **documents** in formats such as **JSON** or **BSON**.\n\nEach document contains a **unique identifier (key)** and a set of **key-value pairs** **(attributes)**. Documents can have varying structures, making the document model schema-less or flexible.\n\nLet’s model the same **user management system** using a document database.\n\n```\n{\n  \"_id\": 1,\n  \"name\": \"John\",\n  \"email\": \"john@email.com\",\n  \"age\": 28,\n  \"orders\": [\\\n    {\\\n      \"orderId\": 101,\\\n      \"product\": \"Laptop\",\\\n      \"price\": 1200\\\n    },\\\n    {\\\n      \"orderId\": 104,\\\n      \"product\": \"Smartphone\",\\\n      \"price\": 800\\\n    }\\\n  ]\n}\n```\n\nIn this document model, each user document contains an embedded array of orders, allowing for hierarchical storage within a single document.\n\n#### c) Column-Family Model (e.g., Cassandra)\n\nIn the column-family model, data is organized into rows and columns, but unlike the relational model, each row can have a **variable number of columns.** It is optimized for **fast querying** and **large-scale distributed storage**.\n\n**Example:**\n\nLet’s assume we're building a **user activity tracking system** that stores the actions users take on a website, such as page views and purchases.\n\nEach user has a unique `UserID`, and their activity (page views and purchases) is stored in a column-family.\n\n[![](https://substackcdn.com/image/fetch/$s_!gBzY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0ccf881-f687-495c-b8f0-c8dc14bde13c_2176x942.png)](https://substackcdn.com/image/fetch/$s_!gBzY!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0ccf881-f687-495c-b8f0-c8dc14bde13c_2176x942.png)\n\n**Row Key (UserID)**: The unique identifier for each user.\n\n**Page1, Page2, Purchase1, Purchase2**: Columns representing the user's activity, which can vary from row to row.\n\n- In **row 1**, user 1 has viewed two pages and made two purchases.\n\n- In **row 2**, user 2 has viewed two pages and made one purchase.\n\n- In **row 3**, user 3 has viewed one page and made one purchase.\n\n\nEach user (row) can have a **variable number of columns**, and different users may have different activities stored in each row.\n\n**No predefined schema** is required, which means new columns (such as additional page views or purchases) can be added dynamically for each user\n\nThis model allows for high write throughput and distributed storage but doesn't enforce strict relationships like the SQL relational model.\n\n#### d) Graph Model (e.g., Neo4j)\n\nIn the graph model, data is stored as **nodes**, **edges**, and **properties**. This model is ideal for applications where data relationships are complex and highly interconnected (e.g., social networks).\n\nIn our **user management system**, users can be represented as nodes, and relationships between them (e.g., friendships or orders) can be represented as edges.\n\n**Graph Representation**:\n\n- Nodes: `Users`, `Orders`\n\n- Edges: `PLACED_ORDER`\n\n\n```\n(John) --PLACED_ORDER--> (Laptop)\n(Mike) --PLACED_ORDER--> (Smartphone)\n(Ron) --PLACED_ORDER--> (Headphones)\n```\n\nIn this model, querying relationships (e.g., finding all orders placed by a user) is highly efficient, especially for applications with complex interconnected data.\n\n[Share](https://blog.algomaster.io/p/sql-vs-nosql-7-key-differences?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n## 2\\. **Schema**\n\n### SQL\n\nIn SQL databases, the schema must be **defined upfront** before inserting any data.\n\nEach table has a specific set of columns with defined data types, constraints, and relationships. The database enforces this schema, ensuring that every row adheres to the predefined structure.\n\nThis **schema enforcement** ensures data integrity, making SQL databases ideal for applications where consistency and accuracy are critical.\n\nHowever, this rigidity can make it challenging to adapt to changing requirements.\n\n#### Example: User and Orders Tables in SQL\n\nLet’s take the example of a **user management system**. In SQL, we first define the structure (schema) of the `Users` and `Orders` tables before adding data.\n\n```\nCREATE TABLE Users (\n    UserID INT PRIMARY KEY,\n    Name VARCHAR(100),\n    Email VARCHAR(100),\n    Age INT\n);\n\nCREATE TABLE Orders (\n    OrderID INT PRIMARY KEY,\n    UserID INT,\n    Product VARCHAR(100),\n    Price DECIMAL(10, 2),\n    FOREIGN KEY (UserID) REFERENCES Users(UserID)\n);\n```\n\nIn this schema:\n\n- The `Users` table has fixed columns: `UserID`, `Name`, `Email`, and `Age`.\n\n- The `Orders` table has fixed columns: `OrderID`, `UserID`, `Product`, and `Price`.\n\n- **Foreign keys** are used to establish relationships between tables.\n\n\nIn SQL databases, changing the schema can be a complex process.\n\nIf you need to add a new column, modify a data type, or change relationships, it often requires **schema migrations**.\n\nThis can lead to **downtime** or careful planning in production systems to avoid disruptions.\n\n#### Example: Adding a new column in SQL\n\n```\nALTER TABLE Users ADD COLUMN Address VARCHAR(255);\n```\n\nThis operation modifies the schema to include an `Address` field. Every record will need to be updated, and default values may be necessary for existing data.\n\n### **NoSQL**\n\nIn NoSQL databases, there is **no fixed schema** that must be defined upfront.\n\nThis allows for flexible and dynamic data structures, where different records can have different attributes.\n\nThis flexibility makes NoSQL databases suitable for applications where data formats may evolve over time.\n\nIn NoSQL databases, schema changes are much simpler because the schema is **dynamic**. You can add new fields to individual records without affecting other records or requiring a schema migration.\n\n#### Example: User and Orders in a Document Database (e.g., MongoDB)\n\nIn a document-based NoSQL database, such as MongoDB, you store user and order data in a single document.\n\n```\n{\n    \"_id\": 1,\n    \"name\": \"John\",\n    \"email\": \"john@email.com\",\n    \"age\": 28,\n    \"orders\": [\\\n        {\\\n            \"orderId\": 101,\\\n            \"product\": \"Laptop\",\\\n            \"price\": 1200\\\n        },\\\n        {\\\n            \"orderId\": 104,\\\n            \"product\": \"Smartphone\",\\\n            \"price\": 800\\\n        }\\\n    ]\n}\n```\n\nIn another document, the structure can differ:\n\n```\n{\n    \"_id\": 3,\n    \"name\": \"Ron\",\n    \"email\": \"ron@email.com\",\n    \"age\": 26,\n    \"orders\": [\\\n        {\\\n            \"orderId\": 103,\\\n            \"product\": \"Headphones\",\\\n            \"price\": 150\\\n        }\\\n    ],\n    \"loyaltyPoints\": 500\n}\n```\n\nIn this flexible schema:\n\n- The first document has user details along with two orders.\n\n- The second document has user details, one order, and an additional attribute (`loyaltyPoints`), which is not present in the first document.\n\n\n* * *\n\n## 3\\. **Scalability**\n\n### **SQL**\n\n**SQL databases** are typically designed to scale **vertically** (also known as **scale-up**).\n\n[![](https://substackcdn.com/image/fetch/$s_!WA8M!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8748d4e2-55b5-4d96-bf15-61cf1b2725d2_950x546.png)](https://substackcdn.com/image/fetch/$s_!WA8M!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8748d4e2-55b5-4d96-bf15-61cf1b2725d2_950x546.png)\n\nThis means improving performance and capacity by adding **more power** (e.g., CPU, RAM, or storage) to a single server.\n\nThis approach works well for moderate loads but becomes limiting when the application scales to high levels of traffic or data growth.\n\nSQL databases rely on maintaining **ACID** (Atomicity, Consistency, Isolation, Durability) properties, which makes horizontal scaling challenging due to the complexity of distributed transactions and joins.\n\n### **NoSQL**\n\n**NoSQL databases** are designed to scale **horizontally** (also known as **scale-out**).\n\n[![](https://substackcdn.com/image/fetch/$s_!FvIZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f8ed9eb-fb45-45de-b846-32fea5c87aaa_2130x854.png)](https://substackcdn.com/image/fetch/$s_!FvIZ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f8ed9eb-fb45-45de-b846-32fea5c87aaa_2130x854.png)\n\nThis means increasing capacity by adding **more servers** or nodes to a distributed system.\n\nThis distributed architecture allows NoSQL databases to handle massive volumes of data and high traffic loads more efficiently.\n\nEach node handles a portion of the data, allowing for better load distribution and fault tolerance.\n\n* * *\n\n## 4\\. **Query Language**\n\nOne of the most significant differences between SQL and NoSQL databases is the **query language** used to interact with the data.\n\n### **SQL**\n\n**SQL (Structured Query Language)** is the de facto standard language used to interact with relational databases to perform operations such as **data retrieval**, **insertion**, **update**, and **deletion**.\n\nIt is **declarative**, meaning you specify what data you want, and the database engine determines how to retrieve it.\n\nSQL allows for powerful data retrieval, aggregation, filtering, and manipulation, making it ideal for handling complex relationships between tables in a relational database.\n\n#### **Example:**\n\n**Fetch users above age 25 and their orders**\n\n```\nSELECT Users.Name, Users.Email, Orders.Product, Orders.Price\nFROM Users\nJOIN Orders ON Users.UserID = Orders.UserID\nWHERE Users.Age > 25;\n```\n\nIn this query:\n\n- The `JOIN` operation combines the `Users` and `Orders` tables based on the `UserID`.\n\n- The `WHERE` clause filters out users whose age is less than 25.\n\n- The result is a list of users and their corresponding orders.\n\n\n### **NoSQL**\n\nNoSQL databases do not have a standard query language. Each NoSQL database may have its query syntax or API, depending on its data model.\n\nWhile this can provide more flexibility, it also means a steeper learning curve and potential limitations in querying capabilities.\n\n#### Example:\n\nIn a document-based NoSQL database like **MongoDB**, data is stored in **JSON-like documents**. MongoDB provides its own query language, which uses JSON syntax to query the documents.\n\nQueries in MongoDB allow for powerful filtering, sorting, and aggregation, but they work on the individual document level rather than across multiple tables.\n\nIn MongoDB, users and their orders are stored together in a single document.\n\n#### **Example:**\n\n**Fetch users above age 25 and their orders**\n\n```\ndb.Users.find(\n    { \"age\": { $gt: 25 } },\n    { \"name\": 1, \"email\": 1, \"orders.product\": 1, \"orders.price\": 1 }\n);\n```\n\nIn this MongoDB query:\n\n- The `find` operation searches for documents where the user's age is greater than 25.\n\n- The second parameter is a projection specifying which fields to return: the user's name, email, and the `product` and `price` of their orders.\n\n\nSame query in a **graph database** may look like:\n\n```\nMATCH (u:User)-[:PLACED_ORDER]->(o:Order)\nWHERE u.age > 25\nRETURN u.name, o.product, o.price;\n```\n\n* * *\n\n## 5\\. **Transaction Support**\n\n**Transactions** in databases ensure that a series of operations are executed in a reliable, consistent manner.\n\nTransactions are particularly important in applications where multiple operations must be completed together, such as transferring money between bank accounts or ensuring that a group of database updates either all succeed or all fail.\n\n### **SQL**\n\n**SQL databases** are known for their robust support of **ACID transactions**.\n\n- **Atomicity**: A transaction is treated as a single, indivisible unit. Either all operations within the transaction succeed, or none of them are applied (all-or-nothing).\n\n- **Consistency**: Transactions take the database from one valid state to another, maintaining all predefined rules such as constraints, triggers, and data types.\n\n- **Isolation**: Multiple transactions can occur concurrently without interfering with each other, ensuring that one transaction’s intermediate state is not visible to other transactions.\n\n- **Durability**: Once a transaction is committed, its results are guaranteed to persist, even in the event of a system crash.\n\n\nThis makes SQL databases ideal for applications where **data integrity** and **consistency** are critical, such as financial systems.\n\n#### Example:\n\n**Bank Transfer in SQL**\n\nConsider a banking system where you need to transfer $500 from User A's account to User B's account.\n\nThis operation requires two steps: debit User A's account and credit User B's account.\n\nBoth steps must succeed or fail together to ensure the system remains consistent.\n\n```\nSTART TRANSACTION;\n\n-- Debit User A's account\nUPDATE Accounts SET balance = balance - 500 WHERE user_id = 'A';\n\n-- Credit User B's account\nUPDATE Accounts SET balance = balance + 500 WHERE user_id = 'B';\n\nCOMMIT;\n```\n\nIf either the debit or credit operation fails (e.g., insufficient funds), the entire transaction will be rolled back, leaving both accounts unchanged.\n\n### **NoSQL**\n\n**NoSQL databases** typically do not prioritize full ACID transactions due to the need for high **availability** and **scalability** in distributed environments.\n\nInstead, many NoSQL databases follow the **BASE** model:\n\n- **Basically Available**: The system guarantees availability, meaning that data can always be read or written, even if some nodes in the distributed system are unavailable.\n\n- **Soft state**: The system may be in a temporarily inconsistent state, but eventual consistency will be reached over time.\n\n- **Eventually consistent**: Over time, the system will become consistent, though it may not happen immediately. This trades immediate consistency for higher availability.\n\n\nThe BASE model is designed for scenarios where strict consistency is not required, and **performance** and **availability** are more important, such as real-time data analytics, social media platforms, or large-scale distributed applications.\n\nWhile some NoSQL databases offer ACID-like features, they are generally less robust than those in SQL databases.\n\n#### Example:\n\n**Cassandra Conditional Update (Lightweight Transaction):**\n\nCassandra does not support full ACID transactions across multiple rows or tables. Instead, it offers **lightweight transactions** for operations requiring limited consistency.\n\n```\nBEGIN TRANSACTION;\nUPDATE Users SET balance = balance - 500 WHERE user_id = 'A' IF balance >= 500;\nUPDATE Users SET balance = balance + 500 WHERE user_id = 'B';\nAPPLY BATCH;\n```\n\nCassandra ensures atomicity for a batch of updates but does not support complex multi-table transactions like SQL databases.\n\n* * *\n\n## 6\\. Performance\n\n### **SQL**\n\nSQL databases are optimized to handle **complex queries** involving **multiple joins**, **aggregations**, and **transactions**.\n\nFor **small datasets**, SQL databases perform well, as the query optimizer can efficiently execute joins and filter data.\n\nAs the dataset grows, **performance may degrade** due to the complexity of joining large tables, especially if **indexing** is not optimized.\n\nTheir performance can be excellent for **read-heavy applications** with well-defined schemas and where data integrity is paramount.\n\nHowever, they may struggle with **write-intensive** operations at scale without appropriate **indexing** and **optimization**.\n\n**Transaction overhead** can also reduce performance when multiple queries are executed in a single transaction.\n\n### **NoSQL**\n\nNoSQL databases are optimized to offer high performance at scale, especially for **large volumes of unstructured or semi-structured data**.\n\nThey prioritize **horizontal scalability** and are optimized for **high-throughput read/write operations**, making them ideal for real-time applications, big data, and large-scale distributed systems.\n\nFor **large datasets**, performance remains high as additional nodes are added to the cluster, distributing the workload.\n\nNoSQL databases generally have **faster write performance** compared to SQL because:\n\n- **Eventual consistency**: In distributed NoSQL systems, data does not have to be immediately consistent across all nodes, reducing the need for locks and increasing write speed.\n\n- **Denormalized data model**: NoSQL databases often store related data together in a single document, which means fewer write operations compared to the normalized SQL model.\n\n\n* * *\n\n## 7\\. **Use Cases**\n\nThe choice between SQL and NoSQL databases often depends on the specific use case, as each type of database excels in different scenarios.\n\n### **SQL**\n\nSQL databases are ideal for applications that require:\n\n- **Structured data** with predefined schemas.\n\n- **Complex queries** involving joins, aggregations, and transactions.\n\n- **Strong consistency** and **ACID** (Atomicity, Consistency, Isolation, Durability) properties.\n\n- **Relational data** where relationships between tables are important.\n\n\nThey are commonly used in industries like finance, healthcare, and government, where data integrity and relational structures are paramount.\n\n### **NoSQL**\n\nNoSQL databases are ideal for use cases requiring:\n\n- **Horizontal scalability** to handle large amounts of distributed data.\n\n- **High-performance reads and writes** for real-time applications.\n\n- **Flexible schema** to store unstructured or semi-structured data.\n\n- **Eventual consistency** and high availability in distributed systems.\n\n\nThey are popular in industries like social media, IoT, and big data analytics, where flexibility and scalability are more important than strict consistency.\n\n## Conclusion\n\nHere’s a final table comparing **SQL** and **NoSQL** databases across different key aspects:\n\n[![](https://substackcdn.com/image/fetch/$s_!Q762!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25e22daa-b6d5-4382-81ba-be90a1a21bb2_3008x2924.png)](https://substackcdn.com/image/fetch/$s_!Q762!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25e22daa-b6d5-4382-81ba-be90a1a21bb2_3008x2924.png)\n\nTo summarize, both SQL and NoSQL databases have their strengths and weaknesses, and the choice between them depends on your application's specific needs.\n\nIf your application requires structured data, complex queries, and transaction management, an SQL database is likely the best choice.\n\nHowever, if your application demands scalability, flexibility, and the ability to handle unstructured data, a NoSQL database may be more suitable.\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/sql-vs-nosql-7-key-differences?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![KAILASH RAJPUT's avatar](https://substackcdn.com/image/fetch/$s_!n6ro!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F287da104-08e2-4ae1-847d-4b8006fede64_96x96.jpeg)](https://substack.com/profile/236116280-kailash-rajput)[![Mohammed Izhar Ahmed's avatar](https://substackcdn.com/image/fetch/$s_!IUHK!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F795a9f7c-1541-478e-b69b-2f3a1ab62efe_96x96.png)](https://substack.com/profile/21885789-mohammed-izhar-ahmed)[![Abhishek Ambatipudi's avatar](https://substackcdn.com/image/fetch/$s_!AxDI!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb122302-280e-462b-8e1e-ef68d616a8fa_96x96.png)](https://substack.com/profile/209044361-abhishek-ambatipudi)[![Deepak Katariya's avatar](https://substackcdn.com/image/fetch/$s_!dys7!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fea680570-fe98-4c93-b5e8-798d0d8f952d_1124x1124.jpeg)](https://substack.com/profile/254534325-deepak-katariya)[![Daphne's avatar](https://substackcdn.com/image/fetch/$s_!EdBG!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e59182f-b741-403a-b002-fe99e7ce6ea2_144x144.png)](https://substack.com/profile/83259808-daphne)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/sql-vs-nosql-7-key-differences"
    },
    {
      "article_title": "What are ACID Transactions in Databases?",
      "article_title_citation": "https://blog.algomaster.io/p/what-are-acid-transactions-in-databases",
      "article_content_markdown": "Imagine you’re running an e-commerce application.\n\nA customer places an order, and your system needs to deduct the item from inventory, charge the customer’s credit card, and record the sale in your accounting system—all at once.\n\nWhat happens if the payment fails but your inventory count has already been reduced? Or if your application crashes halfway through the process?\n\nThis is where **ACID transactions** come into play. They ensure that all the steps in such critical operations happen reliably and consistently.\n\nACID is an acronym that refers to the set of 4 key properties that define a transaction: **Atomicity, Consistency, Isolation,** and **Durability.**\n\n[![](https://substackcdn.com/image/fetch/$s_!zpL2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9ceb65c-70e6-4f3e-9511-f6bc5da93d13_1308x1086.png)](https://substackcdn.com/image/fetch/$s_!zpL2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9ceb65c-70e6-4f3e-9511-f6bc5da93d13_1308x1086.png)\n\nIn this article, we’ll dive into what each of the ACID properties mean, why they are important, and how they are implemented in databases.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n# What is a Database Transaction?\n\nA **transaction** in the context of databases is a sequence of one or more operations (such as inserting, updating, or deleting records) that the database treats as **one single action**. It either fully succeeds or fully fails, with no in-between states.\n\n**Example: Bank Transfer**\n\nWhen you send money to a friend, two things happen:\n\n1. Money is deducted from your account.\n\n2. Money is added to their account.\n\n\nThese two steps form **one transaction**. If either step fails, both are canceled.\n\nWithout transactions, databases could end up in inconsistent states.\n\nFor example:\n\n- **Partial updates**: Your money is deducted, but your friend never receives it.\n\n- **Conflicts**: Two people booking the last movie ticket at the same time.\n\n\nTransactions solve these problems by enforcing rules like **ACID properties** (Atomicity, Consistency, Isolation, Durability).\n\nNow, lets looks at each of the ACID properties.\n\n* * *\n\n# 1\\. Atomicity\n\nAtomicity ensures that a transaction—comprising multiple operations—executes as a **single and indivisible** unit of work: it either **fully** succeeds (commits) or **fully** fails (rolls back).\n\nIf any part of the transaction fails, the entire transaction is rolled back, and the database is restored to a state exactly as it was before the transaction began.\n\n> **Example:** In a money transfer transaction, if the credit step fails, the debit step cannot be allowed to stand on its own. This prevents inconsistent states like “money disappearing” from one account without showing up in another.\n\nAtomicity abstracts away the complexity of manually undoing changes if something goes wrong.\n\n## How Databases Implement Atomicity\n\nDatabases use two key mechanisms to guarantee atomicity.\n\n#### **1\\. Transaction Logs (Write-Ahead Logs)**\n\n- Every operation is recorded in a **write-ahead log** before it’s applied to the actual database table.\n\n- If a failure occurs, the database uses this log to **undo** incomplete changes.\n\n\n**Example:**\n\n[![](https://substackcdn.com/image/fetch/$s_!q5CP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7182af1e-62ac-4883-9434-6082cabe4328_478x312.png)](https://substackcdn.com/image/fetch/$s_!q5CP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7182af1e-62ac-4883-9434-6082cabe4328_478x312.png)\n\nOnce the WAL entry is safely on disk, the database proceeds with modifying the in-memory pages that contain rows for **Account A** and **Account B**.\n\nWhen the operations succeed:\n\n1. The database marks **Transaction ID 12345** as **committed** in the transaction log.\n\n2. The newly updated balances for A and B will eventually get flushed from memory to their respective data files on disk.\n\n\nIf the database crashes **after** the log entry is written but **before** the data files are fully updated, the WAL provides a way to recover:\n\n- On restart, the database checks the WAL.\n\n- It sees **Transaction 12345** was committed.\n\n- It reapplies the **UPDATE** operations to ensure the final balances are correct in the data files.\n\n\nIf the transaction had not committed (or was marked as “in progress”) at the time of the crash, the database would **roll back** those changes using information in the log, leaving the table as if the transaction never happened.\n\n#### **2\\. Commit/Rollback Protocols**\n\n- Databases provide commands like `BEGIN TRANSACTION`, `COMMIT`, and `ROLLBACK`\n\n- Any changes made between `BEGIN TRANSACTION` and `COMMIT` are considered “in-progress” and won’t be permanently applied unless the transaction commits successfully.\n\n- If any step fails, or if you explicitly issue a `ROLLBACK`, all changes since the start of the transaction are undone.\n\n\n**Example:**\n\n[![](https://substackcdn.com/image/fetch/$s_!5HO2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12443c03-6f81-4eb4-a913-0c5eaddebbbb_622x439.png)](https://substackcdn.com/image/fetch/$s_!5HO2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12443c03-6f81-4eb4-a913-0c5eaddebbbb_622x439.png)\n\n* * *\n\n# 2\\. Consistency\n\n**Consistency** in the context of ACID transactions ensures that any transaction will bring the database from one valid state to another valid state—never leaving it in a broken or “invalid” state.\n\nIt means that all the data integrity constraints, such as **primary key** **constraints** (no duplicate IDs), **foreign key** **constraints** (related records must exist in parent tables), and **check constraints**(age can’t be negative), are satisfied before and after the transaction.\n\nIf a transaction tries to violate these rules, it will not be committed, and the database will revert to its previous state.\n\n### Example:\n\nYou have two tables in an e-commerce database:\n\n1. `products` (with columns: `product_id`, `stock_quantity`, etc.)\n\n2. `orders` (with columns: `order_id`, `product_id`, `quantity`, etc.)\n\n\n- **Constraint**: You can’t place an order for a product if `quantity` is greater than the `stock_quantity` in the `products` table.\n\n\n#### Transaction Flow\n\n[![](https://substackcdn.com/image/fetch/$s_!rEA_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F43f22710-56e1-4bbb-af2d-d4808353edbc_642x378.png)](https://substackcdn.com/image/fetch/$s_!rEA_!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F43f22710-56e1-4bbb-af2d-d4808353edbc_642x378.png)\n\n- If the product’s `stock_quantity` was 8 (less than what we’re trying to order), the database sees that the new value would be `-2` which breaks the consistency rule (it should not go negative).\n\n- The transaction fails or triggers a rollback, preventing the database from ending in an invalid state.\n\n\n## How to Implement Consistency\n\n1. **Database Schema Constraints**\n\n   - **NOT NULL**, **UNIQUE**, **PRIMARY KEY**, **FOREIGN KEY**, **CHECK** constraints, and other schema definitions ensure no invalid entries are allowed.\n2. **Triggers and Stored Procedures**\n\n   - Triggers can automatically check additional rules whenever rows are inserted, updated, or deleted.\n\n   - Stored procedures can contain logic to validate data before committing.\n3. **Application-Level Safeguards**\n\n   - While the database enforces constraints at a lower level, applications often add extra checks—like ensuring business rules are followed or data is validated before it even reaches the database layer.\n\n[Share](https://blog.algomaster.io/p/what-are-acid-transactions-in-databases?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n# 3\\. Isolation\n\n**Isolation** ensures that concurrently running transactions do not interfere with each other’s intermediate states.\n\nEssentially, while a transaction is in progress, its updates (or intermediate data) remain invisible to other ongoing transactions—giving the illusion that each transaction is running sequentially, one at a time.\n\nWithout isolation, two or more transactions could read and write partial or uncommitted data from each other, causing incorrect or inconsistent results.\n\nWith isolation, developers can reason more reliably about how data changes will appear to other transactions.\n\n## Concurrency Anomalies\n\nTo understand how isolation works, it helps to see what can go wrong without proper isolation. Common concurrency anomalies include:\n\n1. **Dirty Read**\n\n   - Transaction A reads data that Transaction B has modified but not yet committed.\n\n   - If Transaction B then rolls back, Transaction A ends up holding an invalid or “dirty” value that never truly existed in the committed state.\n2. **Non-Repeatable Read**\n\n   - Transaction A reads the same row(s) multiple times during its execution but sees different data because another transaction updated or deleted those rows in between A’s reads.\n3. **Phantom Read**\n\n   - Transaction A performs a query that returns a set of rows. Another transaction inserts, updates, or deletes rows that match A’s query conditions.\n\n   - If A re-runs the same query, it sees a different set of rows (“phantoms”).\n\n## **Isolation Levels**\n\nDatabases typically allow you to choose an **isolation level**, which balances data correctness with performance.\n\nHigher isolation levels provide stronger data consistency but can reduce system performance by increasing the wait times for transactions.\n\nLet's explore the four common isolation levels:\n\n1. **Read Uncommitted**\n\n   - Allows dirty reads; transactions can see uncommitted changes.\n\n   - Rarely used, as it can lead to severe anomalies.\n\n     [![](https://substackcdn.com/image/fetch/$s_!grD2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45a40f9b-380a-472c-bd2d-49d0e1ebe771_593x150.png)](https://substackcdn.com/image/fetch/$s_!grD2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45a40f9b-380a-472c-bd2d-49d0e1ebe771_593x150.png)\n2. **Read Committed**\n\n   - A transaction sees only data that has been committed at the moment of reading.\n\n   - Prevents dirty reads, but non-repeatable reads and phantom reads can still occur.\n\n     [![](https://substackcdn.com/image/fetch/$s_!Si5W!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f4f73b9-df9a-4880-8d74-ad1581665342_420x135.png)](https://substackcdn.com/image/fetch/$s_!Si5W!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f4f73b9-df9a-4880-8d74-ad1581665342_420x135.png)\n3. **Repeatable Read**\n\n   - Ensures if you read the same rows multiple times within a transaction, you’ll get the same values (unless you explicitly modify them).\n\n   - Prevents dirty reads and non-repeatable reads, but phantom reads may still happen (depending on the database engine).\n\n     [![](https://substackcdn.com/image/fetch/$s_!X-U8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe6068dd-a64f-4005-8343-4df514804e52_481x136.png)](https://substackcdn.com/image/fetch/$s_!X-U8!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe6068dd-a64f-4005-8343-4df514804e52_481x136.png)\n4. **Serializable**\n\n   - The highest level of isolation, acting as if all transactions happen sequentially one at a time.\n\n   - Prevents dirty reads, non-repeatable reads, and phantom reads.\n\n   - Most expensive in terms of performance and concurrency because it can require more locking or more conflict checks.\n\n     [![](https://substackcdn.com/image/fetch/$s_!Forv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6eefdcc0-ecd6-4375-bb45-73df83f451fb_513x193.png)](https://substackcdn.com/image/fetch/$s_!Forv!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6eefdcc0-ecd6-4375-bb45-73df83f451fb_513x193.png)\n\n## How Databases Enforce Isolation\n\n#### 1\\. Locking\n\n- **Pessimistic Concurrency Control**\n\n  - Rows or tables are locked so that no other transaction can read or write them until the lock is released.\n\n  - Can lead to blocking or deadlocks if multiple transactions compete for the same locks.\n\n#### 2\\. MVCC (Multi-Version Concurrency Control)\n\n- **Optimistic Concurrency Control**\n\n  - Instead of blocking reads, the database keeps multiple versions of a row.\n\n  - Readers see a consistent snapshot of data (like a point-in-time view), while writers create a new version of the row when updating.\n\n  - This approach reduces lock contention but requires carefully managing row versions and cleanup (vacuuming in PostgreSQL, for example).\n\n#### 3\\. Snapshot Isolation\n\n- A form of MVCC where each transaction sees data as it was at the start (or a consistent point) of the transaction.\n\n- Prevents non-repeatable reads and dirty reads. Phantom reads may still occur unless the isolation level is fully serializable.\n\n\n* * *\n\n# 4\\. Durability\n\n**Durability** ensures that once a transaction has been committed, the changes it made will survive, even in the face of power failures, crashes, or other catastrophic events.\n\nIn other words, once a transaction says “done,” the data is permanently recorded and cannot simply disappear.\n\n## How Databases Ensure Durability\n\n#### 1\\. Transaction Logs (Write-Ahead Logging)\n\nMost relational databases rely on a **Write-Ahead Log (WAL)** to preserve changes before they’re written to the main data files:\n\n1. **Write Changes to WAL**: The intended operations (updates, inserts, deletes) are recorded in the WAL on durable storage (disk).\n\n2. **Commit the Transaction**: Once the WAL entry is safely persisted, the database can mark the transaction as committed.\n\n3. **Apply Changes to Main Data Files**: The updated data eventually gets written to the main files—possibly first in memory, then flushed to disk.\n\n\nIf the database crashes, it uses the WAL during **recovery**:\n\n- **Redo**: Any committed transactions not yet reflected in the main files are reapplied.\n\n- **Undo**: Any incomplete (uncommitted) transactions are rolled back to keep the database consistent.\n\n\n#### 2\\. Replication / Redundancy\n\nIn addition to WAL, many systems use replication to ensure data remains durable even if hardware or an entire data center fails.\n\n- **Synchronous Replication**: Writes are immediately copied to multiple nodes or data centers. A transaction is marked committed only if the primary and at least one replica confirm it’s safely stored.\n\n- **Asynchronous Replication**: Changes eventually sync to other nodes, but there is a (small) window where data loss can occur if the primary fails before the replica is updated.\n\n\n#### 3\\. Backups\n\nRegular **backups** provide a safety net beyond logs and replication. In case of severe corruption, human error, or catastrophic failure:\n\n- **Full Backups**: Capture the entire database at a point in time.\n\n- **Incremental/Differential Backups**: Store changes since the last backup for faster, more frequent backups.\n\n- **Off-Site Storage**: Ensures backups remain safe from localized disasters, allowing you to restore data even if hardware is damaged.\n\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/what-are-acid-transactions-in-databases?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![koushik naidu mullaguru's avatar](https://substackcdn.com/image/fetch/$s_!2-e2!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F432b8872-7c75-4f30-a8ae-760719f0ad4d_144x144.png)](https://substack.com/profile/268118691-koushik-naidu-mullaguru)[![Kumar Rounak's avatar](https://substackcdn.com/image/fetch/$s_!x_z0!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc80976d4-f745-446e-abb5-abe0dfd11260_144x144.png)](https://substack.com/profile/4387132-kumar-rounak)[![Avinesh's avatar](https://substackcdn.com/image/fetch/$s_!wj74!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F13e6f805-3bc0-41b5-86c8-bffeeff7c87e_144x144.png)](https://substack.com/profile/97914913-avinesh)[![Aaditya Shukla's avatar](https://substackcdn.com/image/fetch/$s_!uG0p!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff12d1fb-ea12-4748-ad90-31ef13296f58_144x144.png)](https://substack.com/profile/257665717-aaditya-shukla)[![Rahul Mishra's avatar](https://substackcdn.com/image/fetch/$s_!NnUO!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69f10fba-33e4-4513-be58-07eddd24c6c0_1336x1250.jpeg)](https://substack.com/profile/8564106-rahul-mishra)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/what-are-acid-transactions-in-databases"
    },
    {
      "article_title": "Database Indexes: A detailed guide",
      "article_title_citation": "https://blog.algomaster.io/p/a-detailed-guide-on-database-indexes",
      "article_content_markdown": "Consider a large **Book** of 1000 pages.\n\nSuppose you’re trying to find the page which contains information related to a certain **word**.\n\nWithout an index page, you would have to go through every page, which could take hours or even days.\n\nBut with an index page, you know where to look!\n\nOne you find the right index, you can efficiently jump to that page.\n\nThe index, since it's **sorted** alphabetically and gives page numbers for specific information, saves us from spending too much time flipping through every page.\n\n[![How indexes help organize our world | Connecticut Public](https://substackcdn.com/image/fetch/$s_!N0t4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb175bf87-f83e-4b0a-b930-27e6d7cb11aa_880x660.jpeg)](https://substackcdn.com/image/fetch/$s_!N0t4!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb175bf87-f83e-4b0a-b930-27e6d7cb11aa_880x660.jpeg) Credit: https://www.ctpublic.org/show/the-colin-mcenroe-show/2022-08-17/how-indexes-help-organize-our-world\n\n**Database indexes** work in a similar manner. They guide the database to the exact location of the data, enabling faster and more efficient data retrieval.\n\nIn this article, we'll explore:\n\n- What are database indexes?\n\n- How do they work?\n\n- Benefits of using them.\n\n- Different types of indexes.\n\n- Which data structure they use?\n\n- How to use them smartly?\n\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n# **1\\. What are Database Indexes?**\n\n[![](https://substackcdn.com/image/fetch/$s_!yl9Q!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4b31f2da-a2be-4ceb-aff8-7ce9d0477a2d_1120x738.png)](https://substackcdn.com/image/fetch/$s_!yl9Q!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4b31f2da-a2be-4ceb-aff8-7ce9d0477a2d_1120x738.png)\n\nA database index is a super-efficient lookup table that allows a database to find data much faster.\n\nIt holds the indexed column values along with pointers to the corresponding rows in the table.\n\nWithout an index, the database might have to scan every single row in a massive table to find what you want – a painfully slow process.\n\nBut, with an index, the database can zero in on the exact location of the desired data using the index’s pointers.\n\n### How to create Indexes?\n\nHere's an example of creating an index in a MySQL database.\n\nLet's say we have a table named `employees` with the following structure:\n\n[![](https://substackcdn.com/image/fetch/$s_!KdCH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd1f2fcd-22d6-4b99-abd6-c56bbf56585f_1216x396.png)](https://substackcdn.com/image/fetch/$s_!KdCH!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd1f2fcd-22d6-4b99-abd6-c56bbf56585f_1216x396.png)\n\nNow, let's create an index on the `last_name` column to improve the performance of queries that frequently search or sort based on the last name.\n\n[![](https://substackcdn.com/image/fetch/$s_!ygnK!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6e9c448-4de4-4bbe-9304-e1b8d9a84bfd_1332x120.png)](https://substackcdn.com/image/fetch/$s_!ygnK!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6e9c448-4de4-4bbe-9304-e1b8d9a84bfd_1332x120.png)\n\nIn this example, we use the `CREATE INDEX` statement to create an index named `idx_last_name` on the `employees` table. The index is created on the `last_name` column.\n\nAfter creating the index, queries that involve conditions or sorting on the `last_name` column will be optimized. For example:\n\n[![](https://substackcdn.com/image/fetch/$s_!afja!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbeb07c6f-61c9-4e5d-9555-aa5451ac56a8_1370x134.png)](https://substackcdn.com/image/fetch/$s_!afja!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbeb07c6f-61c9-4e5d-9555-aa5451ac56a8_1370x134.png)\n\nThis query will use the `idx_last_name` index to quickly locate the rows where the `last_name` is 'Smith', avoiding a full table scan.\n\nYou can also create indexes on multiple columns (composite indexes) if your queries frequently involve conditions on multiple columns together. For example:\n\n[![](https://substackcdn.com/image/fetch/$s_!lmOl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd042d7a7-e77c-4d48-b91c-b396474c8f6d_1528x136.png)](https://substackcdn.com/image/fetch/$s_!lmOl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd042d7a7-e77c-4d48-b91c-b396474c8f6d_1528x136.png)\n\nThis creates a composite index on the `first_name` and `last_name` columns, which can be useful for queries that search or sort based on both columns.\n\n[Share](https://blog.algomaster.io/p/a-detailed-guide-on-database-indexes?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n# 2\\. How do Database Indexes Work?\n\nHere's a step-by-step explanation of how database indexes work:\n\n1. **Index Creation**: The database administrator creates an index on a specific column or set of columns.\n\n2. **Index Building**: The database management system builds the index by scanning the table and storing the values of the indexed column(s) along with a pointer to the corresponding data.\n\n3. **Query Execution**: When a query is executed, the database engine checks if an index exists for the requested column(s).\n\n4. **Index Search**: If an index exists, the database searches the index for the requested data, using the pointers to quickly locate the data.\n\n5. **Data Retrieval**: The database retrieves the requested data, using the pointers from the index.\n\n\n* * *\n\n# **3\\. Benefits of Database Indexes**\n\nDatabase indexes offer several benefits, including:\n\n- **Faster Query Performance**: Indexes can significantly improve query performance especially for large datasets by reducing the amount of data that needs to be scanned.\n\n- **Reduced CPU Usage**: By reducing the number of rows that need to be scanned, indexes can decrease CPU usage and optimize resource utilization.\n\n- **Rapid Data Retrieval**: Indexes enable quick data retrieval for queries that involve equality or range conditions on the indexed columns.\n\n- **Efficient Sorting**: Indexes can also be used to efficiently sort data based on the indexed columns, eliminating the need for expensive sorting operations.\n\n- **Better Data Organization**: Indexes can help maintain data organization and structure, making it easier to manage and maintain the database.\n\n\n* * *\n\n# 4\\. Types of **Database** Indexes\n\n### Indexes based on Structure and Key Attributes:\n\n- **Primary Index:** Automatically created when a primary key constraint is defined on a table. Ensures uniqueness and helps with super-fast lookups using the primary key.\n\n- **Clustered Index:** Determines the order in which data is physically stored in the table. A clustered index is most useful when we’re searching in a range. Only one clustered index can exist per table.\n\n- **Non-clustered or Secondary Index:** This index does not store data in the order of the index. Instead, it provides a list of virtual pointers or references to the location where the data is actually stored.\n\n\n### Indexes based on Data Coverage:\n\n- **Dense index:** Has an entry for every search key value in the table. Suitable for situations where the data has a small number of distinct search key values or when fast access to individual records is required.\n\n\n- **Sparse index:** Has entries only for some of the search key values. Suitable for situations where the data has a large number of distinct search key values.\n\n\n### Specialized Index Types:\n\n- **Bitmap Index:** Excellent for columns with low cardinality (few distinct values). Common in data warehousing.\n\n\n- **Hash Index:** A index that uses a hash function to map values to specific locations. Great for exact match queries.\n\n- **Filtered Index:** Indexes a subset of rows based on a specific filter condition. Useful to improve query speed on commonly filtered columns.\n\n- **Covering Index:** Includes all the columns required by a query in the index itself, eliminating the need to access the underlying table data.\n\n- **Function-based index:** Indexes that are created based on the result of a function or expression applied to one or more columns of a table.\n\n- **Full-Text Index**: A index designed for full-text search, allowing for efficient searching of text data.\n\n- **Spatial Index:** Used for indexing geographical data types.\n\n\n* * *\n\n# 5\\. What Data Structure do Indexes use?\n\nMost commonly used data structures that power indexes are B-Trees, Hash Tables and Bitmaps.\n\n### B-Tree (Balanced Tree)\n\n[![](https://substackcdn.com/image/fetch/$s_!JuEy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd557e1a-d752-4653-9ae7-1ae2483fa252_2284x632.png)](https://substackcdn.com/image/fetch/$s_!JuEy!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd557e1a-d752-4653-9ae7-1ae2483fa252_2284x632.png)\n\nMost database engines use either a B-Tree or a variation of B-Trees like B+ Trees.\n\nB-Trees have a hierarchical structure with a root node, internal nodes (index nodes), and leaf nodes.\n\nEach node in a B-Tree contains a sorted array of keys and pointers to child nodes.\n\nHere's why they are so well-suited:\n\n- **Self-Balancing:** B-trees ensure that the 'height' of the tree stays balanced even when inserting or deleting data. This ensures `logarithmic time complexity` for insertion, deletion, and searching.\n\n- **Ordered:** B-trees keep the data sorted, making range queries (\"find all orders between date X and Y\") and inequality comparisons very fast.\n\n- **Disk-Friendly:** B-trees are designed to work well with disk-based storage. A single node of a B-tree often corresponds to a disk block, minimizing disk access operations.\n\n\nMany databases use a slightly modified B-tree variant called the B+ tree.\n\nIn a B+ tree, all data values are stored only in the leaf nodes, which can further improve performance for certain use cases like range queries.\n\n### Hash Tables\n\n[![](https://substackcdn.com/image/fetch/$s_!kh9E!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e98b8f5-8d7b-4c4a-b692-c4d547260ee8_2120x760.png)](https://substackcdn.com/image/fetch/$s_!kh9E!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e98b8f5-8d7b-4c4a-b692-c4d547260ee8_2120x760.png)\n\nHash tables are used for hash indexes, which are based on a hash function.\n\nA hash table consists of an array of buckets, with each bucket containing the addresses for rows in the data.\n\nHash indexes employ a hash function to map keys to their corresponding bucket in the hash table, enabling constant-time lookup operations.\n\nHash indexes provide fast equality lookups, as the hash function determines the exact location of the data based on the key.\n\nHowever, hash indexes do not support range queries or sorting efficiently.\n\n### Bitmaps\n\n[![](https://substackcdn.com/image/fetch/$s_!-Yoj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2bcdd47-be2e-48aa-90cb-671b28209d48_270x297.png)](https://substackcdn.com/image/fetch/$s_!-Yoj!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2bcdd47-be2e-48aa-90cb-671b28209d48_270x297.png)\n\nEach bit in the bitmap corresponds to a row, and the value of the bit indicates whether the key value exists in that row.\n\nBitmap indexes use a bitmap (a binary array) to represent the presence or absence of a specific key value in each row of a table.\n\nBitmap indexes are well-suited for columns with low cardinality (a small number of distinct values) and for performing complex queries involving multiple conditions.\n\nBitmap operations like AND, OR, and NOT are performed efficiently using bitwise operations, making bitmap indexes suitable for analytical queries involving multiple columns.\n\n* * *\n\n# **6\\. How to use Database Indexes Smartly?**\n\nTo get the most out of database indexes, consider these best practices:\n\n- **Identify Query Patterns**: Analyze the most frequent and critical queries executed against your database to determine which columns to index and which type of index to use.\n\n- **Index Frequently Used Columns**: Consider indexing columns that are frequently used in WHERE, JOIN, and ORDER BY clauses.\n\n- **Index Selective Columns:** Indexes are most effective on columns with a good spread of data values (high cardinality). Indexing a `gender` column might be less beneficial than one with a unique `customer_id`.\n\n- **Use Appropriate Index Types**: Choose the right index type for your data and queries.\n\n- **Consider Composite Indexes**: For queries involving multiple columns, consider creating composite indexes that encompass all relevant columns. This reduces the need for multiple single-column indexes and improves query performance.\n\n- **Monitor Index Performance**: Regularly monitor index performance, remove unused indexes and adjust your indexing strategy as the database workload evolves.\n\n- **Avoid Over-Indexing**: Avoid creating too many indexes, as this can lead to increased storage requirements and slower write performance.\n\n  - Indexes take up extra disk space since they're additional data structures that need to be stored alongside your tables.\n\n  - Every time you insert, update, or delete data in a table with an index, the index needs to update too. This can slightly slow down write operations.\n\nTo summarize, indexes are a powerful tool to optimize database query performance.\n\nBut remember to choose the right column and index type, monitor performance, and avoid over-indexing to get the most out of them.\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/a-detailed-guide-on-database-indexes?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n* * *\n\n#### References:\n\n- [What Are the Types of Indexes in a Relational Database?](https://vertabelo.com/blog/database-index-types/)\n\n\n[![Artem Hash's avatar](https://substackcdn.com/image/fetch/$s_!v33Z!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1bb4c99-f4b9-48a5-be30-2f695e48a7d1_144x144.png)](https://substack.com/profile/205975660-artem-hash)[![Raul Junco's avatar](https://substackcdn.com/image/fetch/$s_!ue6D!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45a92f5e-1e2e-4dfa-9ff3-45fc5ad0c57e_612x612.png)](https://substack.com/profile/98661477-raul-junco)[![Alexandre Zajac's avatar](https://substackcdn.com/image/fetch/$s_!h7lf!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c72a9e2-603f-49f0-9703-4f798e5efe81_500x500.jpeg)](https://substack.com/profile/23673358-alexandre-zajac)[![Artem Kudria's avatar](https://substackcdn.com/image/fetch/$s_!35a8!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff061dc77-f551-4816-8d1f-cce48ba75685_144x144.png)](https://substack.com/profile/41860387-artem-kudria)[![Srinu Nampalli's avatar](https://substackcdn.com/image/fetch/$s_!zgjP!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20ada02a-ce8d-43b4-a9c3-68f8d4b13328_784x788.jpeg)](https://substack.com/profile/97879594-srinu-nampalli)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/a-detailed-guide-on-database-indexes"
    },
    {
      "article_title": "Sharding vs. Partitioning",
      "article_title_citation": "https://blog.algomaster.io/p/sharding-vs-partitioning",
      "article_content_markdown": "**Sharding** and **partitioning** are two of the most commonly confused concepts in system design.\n\nAt first glance, they may seem similar, and people often use them interchangeably. But they are not the same.\n\nBoth are techniques to **divide and scale large databases**; however, they differ in how the data is divided.\n\n[![](https://substackcdn.com/image/fetch/$s_!TkHD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff725fe65-d580-4029-bd22-4b7ea239a228_1546x1090.png)](https://substackcdn.com/image/fetch/$s_!TkHD!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff725fe65-d580-4029-bd22-4b7ea239a228_1546x1090.png)\n\nSimply put **, partitioning** typically means breaking down database tables **within a single server** while **sharding** is about distributing data across **multiple servers**.\n\nIn this article, we’ll clear up the confusion between the two. You’ll learn:\n\n- What each term really means\n\n- How they work under the hood\n\n- Real-world examples with SQL and code\n\n\n* * *\n\n# 1\\. What is Partitioning?\n\n##\n\n*(Note: This is a preview of a paid post)*",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/sharding-vs-partitioning"
    },
    {
      "article_title": "Consistent Hashing Explained",
      "article_title_citation": "https://blog.algomaster.io/p/consistent-hashing-explained",
      "article_content_markdown": "In a **distributed system** where nodes (servers) are frequently **added or removed**, efficiently routing requests becomes challenging.\n\nA common approach is to use **hash the request** and assign it to a server using `Hash(key) mod N`, where N is the number of servers.\n\nHowever, this method is highly dependent on the number of servers, and any change in N can lead to **significant** **rehashing**, causing a major redistribution of keys (requests).\n\n**Consistent hashing** addresses this issue by ensuring that only a small subset of keys need to be reassigned when nodes are added or removed.\n\nPopularized by **[Amazon’s Dynamo paper](https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf)**, it has now become a fundamental technique in distributed databases like DynamoDB, Cassandra and ScyllaDB.\n\nIn this article, we’ll explore what consistent hashing is, why it’s needed, how it works, and how to implement it in code.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n# 1\\. The Problem with Traditional Hashing\n\nImagine you're building a **high-traffic web application** that serves millions of users daily. To handle the load efficiently, you distribute incoming requests across multiple backend servers using a **hash-based** **load balancer**.\n\nYour system consists of **5 backend servers** (`S0, S1, S2, S3, S4`), and requests are assigned using a hash function that maps each user's **IP address to a specific server**.\n\n[![](https://substackcdn.com/image/fetch/$s_!mjt2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44fe7140-c84e-4be0-b3c8-7c93fd373843_1498x1422.png)](https://substackcdn.com/image/fetch/$s_!mjt2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44fe7140-c84e-4be0-b3c8-7c93fd373843_1498x1422.png)\n\nThe process works like this:\n\n1. The load balancer takes a user’s IP address (or session ID).\n\n2. A **hash function** maps the IP to one of the backend servers by taking the **sum of bytes in the IP address** and computing `mod 5` (since we have 5 servers).\n\n3. The request is **routed to the assigned server**, ensuring that the same user is always directed to the same server for session consistency.\n\n\n**Example:**\n\n[![](https://substackcdn.com/image/fetch/$s_!HsWk!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa414e8ee-1a04-491d-9728-ba20d2b6a000_2114x1148.png)](https://substackcdn.com/image/fetch/$s_!HsWk!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa414e8ee-1a04-491d-9728-ba20d2b6a000_2114x1148.png)\n\n### **Everything Works Fine… Until You Scale**\n\nThis approach works **as long as the number of servers remains constant**. But what happens when you **add or remove a server**?\n\n#### **Scenario 1: Adding a New Server (S5)**\n\nAs traffic increases, you decide to **scale up** by adding a new backend server (`S5`). Now, the hash function must be modified to use `mod 6` instead of `mod 5`since we have 6 servers now.\n\n[![](https://substackcdn.com/image/fetch/$s_!eGg7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9416ad7c-2854-4102-bc70-87ac3ddf7089_2118x1290.png)](https://substackcdn.com/image/fetch/$s_!eGg7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9416ad7c-2854-4102-bc70-87ac3ddf7089_2118x1290.png)\n\nThis seemingly simple change **completely disrupts the existing mapping**, causing **most users to be reassigned to different servers**.\n\nThis results into **massive rehashing**, leading to **high overhead, and potential downtime**.\n\n#### **Scenario 2: Removing a Server (S4)**\n\nNow, let’s say one of the servers (`S4`) fails or is removed. The number of servers drops to 4, forcing the hash function to switch from `mod 5` to `mod 4`.\n\n[![](https://substackcdn.com/image/fetch/$s_!tKfa!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50affff1-61f2-4d78-87e3-983b731fff08_2116x1124.png)](https://substackcdn.com/image/fetch/$s_!tKfa!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50affff1-61f2-4d78-87e3-983b731fff08_2116x1124.png)\n\nEven though only **one** server was removed, **most users are reassigned to different servers**. This can cause:\n\n- **Session Loss:** Active users may be logged out or disconnected.\n\n- **Cache invalidation:** Cached data becomes irrelevant, increasing database load.\n\n- **Severe performance degradation:** The system may struggle to run efficiently.\n\n\n### **The Solution: Consistent Hashing**\n\n**Consistent hashing** offers a more scalable and efficient solution by ensuring that only a **small fraction of users** are reassigned when scaling up or down.\n\nIt performs really well when operated in dynamic environments, where the system scales up and down frequently.\n\n[Share](https://blog.algomaster.io/p/consistent-hashing-explained?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n# 2\\. How Consistent Hashing Works\n\nConsistent hashing is a **distributed hashing technique** used to efficiently distribute data across multiple nodes (servers, caches, etc.).\n\nIt uses a **circular hash space** (hash ring) with a large and constant hash space.\n\nBoth nodes (servers, caches, or databases) and keys (data items) are mapped to positions on this hash ring using a **hash function**.\n\nUnlike modulo-based hashing, where changes in the number of nodes cause large-scale remapping, consistent hashing ensures that only a small fraction of keys are reassigned when a node is added or removed, making it highly scalable and efficient.\n\n> In consistent hashing, when the number of nodes changes, only `k/n`keys need to be reassigned, where `k` is the total number of keys and `n` is the total number of nodes.\n\n## **2.1 Constructing the Hash Ring**\n\nInstead of distributing keys based on `Hash(key) mod N`, consistent hashing places both servers and keys on a circular hash ring.\n\n#### Defining the Hash Space\n\n- We use a large, fixed hash space ranging from `0` to `2^32 - 1` (assuming a 32-bit hash function).\n\n- This creates a circular structure, where values wrap around after reaching the maximum limit.\n\n\n#### **Placing Servers on the Ring**\n\n- Each **server (node)** is assigned a position on the hash ring by computing `Hash(server_id)`.\n\n- Using the above example with **5 servers (**`S0, S1, S2, S3, S4` **)**, the hash function distributes them at different positions around the ring.\n\n\n[![](https://substackcdn.com/image/fetch/$s_!0zaf!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F584274f3-e135-492f-a20e-ea415d4927d3_1536x1362.png)](https://substackcdn.com/image/fetch/$s_!0zaf!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F584274f3-e135-492f-a20e-ea415d4927d3_1536x1362.png)\n\n#### **Mapping Keys to Servers**\n\n- When a key is added, its position is determined by computing `Hash(key)`.\n\n  - Example: a user’s request is assigned a position on the ring based on the hash of their IP address: `Hash(IP Address)`\n- We then move clockwise around the ring until we find the next available server.\n\n- The key (or request) is assigned to this server for storage or retrieval.\n\n\n[![](https://substackcdn.com/image/fetch/$s_!2Bh4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6a01929-75d6-4885-a400-602f588b0f69_1636x1362.png)](https://substackcdn.com/image/fetch/$s_!2Bh4!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6a01929-75d6-4885-a400-602f588b0f69_1636x1362.png)\n\n> **Note:** In case a key’s hash falls directly on a node’s position, it belongs to that node.\n\n## **2.2 Adding a New Server**\n\nSuppose we add a **new server (**`S5` **)** to the system.\n\n- The position of `S5` falls between `S1` and `S2` in the hash ring.\n\n- `S5` takes over all keys (requests) that fall between `S1` and `S5`, which were previously handled by `S2`.\n\n  - **Example:**`User D’s`requests which were originally assigned to `S2,` will now be redirected to `S5.`\n\n[![](https://substackcdn.com/image/fetch/$s_!7Frc!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1dd6f660-5f49-4f85-9337-b653b06d5bdb_1700x1364.png)](https://substackcdn.com/image/fetch/$s_!7Frc!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1dd6f660-5f49-4f85-9337-b653b06d5bdb_1700x1364.png)\n\nThis demonstrates how consistent hashing efficiently redistributes keys with minimal disruption, ensuring that only a small subset of keys are reassigned when new servers are added.\n\n## **2.3 Removing a Node**\n\nWhen a server, such as `S4`, fails or is removed from the system:\n\n- All keys previously assigned to `S4` are reassigned to the next available server in the ring (`S3`).\n\n- Only the keys (requests) that were mapped to `S4` need to move, while all other keys remain unaffected.\n\n\n[![](https://substackcdn.com/image/fetch/$s_!X8so!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c2383a5-cd36-4bda-9a8c-ddef6693974b_1756x1362.png)](https://substackcdn.com/image/fetch/$s_!X8so!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c2383a5-cd36-4bda-9a8c-ddef6693974b_1756x1362.png)\n\nThis results in **minimal data movement**, unlike traditional hashing where removing a node would require reassigning most keys.\n\nSubscribe\n\n* * *\n\n# 3\\. Virtual Nodes\n\nIn **basic consistent hashing**, each server is assigned **a single position** on the hash ring. However, this can lead to **uneven data distribution**, especially when:\n\n- The number of servers is small.\n\n- Some servers accidentally get clustered together, creating **hot spots**.\n\n- A server is **removed**, causing a sudden load shift to its immediate neighbor.\n\n\n**Virtual nodes (VNodes)** are a technique used in consistent hashing to improve **load balancing** and **fault tolerance** by distributing data more evenly across servers.\n\n#### **How Virtual Nodes Work**\n\nInstead of assigning one position per server, each physical server is assigned **multiple positions** (virtual nodes) on the hash ring.\n\n- Each server is hashed multiple times to different locations on the ring.\n\n- When a request (key) is hashed, it is assigned to the next virtual node in a clockwise direction.\n\n- The request is then routed to the actual server associated with the virtual node.\n\n\n#### Example\n\nAssume we have **three physical servers (S1, S2, S3)**. Without virtual nodes, their positions might be:\n\n```\nS1 → Position 10\nS2 → Position 50\nS3 → Position 90\n```\n\n[![](https://substackcdn.com/image/fetch/$s_!Bbr2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91f7ac93-93fb-4da2-a634-18d2942e6020_1660x1338.png)](https://substackcdn.com/image/fetch/$s_!Bbr2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91f7ac93-93fb-4da2-a634-18d2942e6020_1660x1338.png)\n\nIf **S1 fails**, all its keys must be reassigned to **S2**, which can create an overload.\n\nWith **virtual nodes**, each server is hashed multiple times:\n\n```\nS1-1 → Position 10\nS1-2 → Position 70\nS1-3 → Position 120\nS2-1 → Position 50\nS2-2 → Position 80\nS2-3 → Position 160\nS3-1 → Position 30\nS3-2 → Position 90\nS3-3 → Position 140\n```\n\n[![](https://substackcdn.com/image/fetch/$s_!5fde!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2ba83bb-b944-4b89-97c5-ebf06314c63e_1838x1390.png)](https://substackcdn.com/image/fetch/$s_!5fde!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2ba83bb-b944-4b89-97c5-ebf06314c63e_1838x1390.png)\n\nNow, instead of just one point, `S1` is represented at **multiple positions**, making the distribution **more even**.\n\nIf **S1 fails**, its keys are more evenly redistributed among **S2 and S3**, rather than all going to **S2**.\n\n* * *\n\n# 4\\. Code Implementation (Python)\n\n[![](https://substackcdn.com/image/fetch/$s_!3wyU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e80b7c3-3e3e-4ec6-af39-5883f771be1c_761x1076.png)](https://substackcdn.com/image/fetch/$s_!3wyU!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e80b7c3-3e3e-4ec6-af39-5883f771be1c_761x1076.png)\n\n**Code Links: [Python](https://github.com/ashishps1/awesome-system-design-resources/blob/main/implementations/python/consistent_hashing/consistent-hashing.py), [Java](https://github.com/ashishps1/awesome-system-design-resources/blob/main/implementations/java/consistent_hashing/ConsistentHashing.java)**\n\n#### **Explanation:**\n\n1. **Key Components**\n\n   - **Hash Ring (**`self.ring` **):** Stores hash values → server mappings. Uses **virtual nodes** (replicas) for better load balancing.\n\n   - **Sorted Keys (**`self.sorted_keys` **):** Maintains a **sorted list** of hash values for efficient lookups.\n\n   - **Server Set (**`self.servers` **):** Tracks active physical servers.\n2. **Initialization (**`__init__` **)**\n\n   - Calls `add_server()` for each server, hashing it multiple times (based on `num_replicas`) to ensure even distribution.\n3. **Hashing Function (**`_hash` **)**\n\n   - Uses **MD5 hashing** to convert strings into large integers for consistent placement on the hash ring.\n4. **Adding a Server (**`add_server` **)**\n\n   - Generates multiple hash values for each server (`server-0`, `server-1`, etc.).\n\n   - Stores these in `self.ring` and maintains a sorted order in `self.sorted_keys` for fast lookup.\n5. **Removing a Server (**`remove_server` **)**\n\n   - Deletes the server’s hash values and its virtual nodes from `self.ring` and `self.sorted_keys`.\n6. **Getting a Server (**`get_server` **)**\n\n   - Hashes the input key and finds the closest **clockwise** server using `bisect.bisect()`. Wraps around to the first node if necessary.\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/consistent-hashing-explained?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)** and **[X](https://twitter.com/ashishps_1)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![Sai Lin Naung's avatar](https://substackcdn.com/image/fetch/$s_!EQwT!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde9a9f14-2ff8-4a8a-b271-a86fdc5ae3b9_144x144.png)](https://substack.com/profile/163955992-sai-lin-naung)[![YoyoB's avatar](https://substackcdn.com/image/fetch/$s_!dwT0!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd359b352-b195-4114-80da-66086fd470f4_96x96.jpeg)](https://substack.com/profile/90379963-yoyob)[![Venkat's avatar](https://substackcdn.com/image/fetch/$s_!vuRu!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5449b0e8-55c1-4877-ba79-0a99be7fb2e0_1552x1551.jpeg)](https://substack.com/profile/98795467-venkat)[![Niranjan Shetty's avatar](https://substackcdn.com/image/fetch/$s_!FLqm!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4cef904-df19-4961-9f88-ed0ea2cd92dd_96x96.png)](https://substack.com/profile/311472880-niranjan-shetty)[![Dharmaraj Rathinavel's avatar](https://substackcdn.com/image/fetch/$s_!FXwp!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c83532-d24e-4144-b4b8-f09b53156713_2120x2120.jpeg)](https://substack.com/profile/225555193-dharmaraj-rathinavel)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/consistent-hashing-explained"
    },
    {
      "article_title": "What is Change Data Capture (CDC)?",
      "article_title_citation": "https://blog.algomaster.io/p/change-data-capture-cdc",
      "article_content_markdown": "Modern applications often rely on multiple systems (e.g., search engines, caches, data lakes, microservices), all of which need **up-to-date data**.\n\nTraditional **batch ETL jobs** are slow, introduce latency, and often lead to stale data and inconsistencies.\n\n**Change Data Capture (CDC)** is a design pattern used to **track and capture changes** in a database (inserts, updates, deletes) and **stream those changes in real time** to downstream systems.\n\n[![](https://substackcdn.com/image/fetch/$s_!IzPK!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73deb423-fada-4452-9f19-946154c1efd6_1882x738.png)](https://substackcdn.com/image/fetch/$s_!IzPK!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73deb423-fada-4452-9f19-946154c1efd6_1882x738.png)\n\nThis ensures downstream systems remain in sync without needing expensive batch jobs.\n\nIn this article, we’ll dive into how CDC works, explore different implementation strategies, it’s real-world use cases, challenges and considerations.\n\n* * *\n\n# **1\\. How CDC Works**\n\nAt a high level, CDC works by continuously monitoring a database for data changes (insertions, updates, and deletions).\n\nWhen a change occurs, CDC captures the change event and makes the information available for processing.\n\n[![](https://substackcdn.com/image/fetch/$s_!5P5C!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79ad4890-0a66-415c-b9f3-be8caf2c8c2b_2512x594.png)](https://substackcdn.com/image/fetch/$s_!5P5C!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79ad4890-0a66-415c-b9f3-be8caf2c8c2b_2512x594.png)\n\nThe process typically involves:\n\n- **Monitoring:** Detecting changes from source systems. This can be achieved through database triggers, reading transaction logs, or using specialized CDC tools.\n\n- **Capturing:** Extracting details about the change event (such as before and after values) along with metadata (e.g., timestamp, changed table).\n\n- **Delivering:** Transmitting the change event to consumers, which might include message queues, data pipelines, or real-time analytics systems.\n\n\nThis helps in achieving **event-driven architectures** where applications respond to data changes as they happen.\n\n* * *\n\n# 2\\. CDC Implementation Approaches\n\nThere are three main approaches to implementing CDC:\n\n## **2.1 Timestamp-Based CDC**\n\nThis approach relies on adding a `last_updated`or` last_modified` column to your database tables.\n\nEvery time a row is inserted or modified, this column is updated with the current timestamp. Applications then query the table for rows where the `last_updated` time is later than the last sync time.\n\n#### **Example Query:**\n\n```\nSELECT * FROM orders WHERE last_updated > '2024-02-15 12:00:00';\n```\n\n#### **Pros:**\n\n- **Simplicity:** Easy to implement without major changes to the database architecture.\n\n- **No External Dependencies:** Can be executed with basic SQL operations, making it accessible for smaller projects or legacy systems.\n\n\n#### **Cons:**\n\n- **Incomplete Capture:** This method may not capture deleted records since the timestamp is typically updated on existing rows.\n\n- **Performance Overhead:** As your data grows, frequent querying based on timestamps can impact performance, especially if indexing is not optimally configured.\n\n- **Potential Data Gaps:** Misconfigured timestamp updates or clock skew issues can result in missed changes.\n\n\n## **2.2 Trigger-Based CDC**\n\nTrigger-Based CDC involves setting up database triggers that automatically log changes to a separate audit table whenever an insert, update, or delete operation occurs.\n\nThis audit table then serves as a reliable source of change records, which can be pushed to other systems as needed.\n\n#### **Example Trigger:**\n\n```\nCREATE TRIGGER order_changes\nAFTER UPDATE ON orders\nFOR EACH ROW\nINSERT INTO order_audit (order_id, old_status, new_status, changed_at)\nVALUES (OLD.id, OLD.status, NEW.status, NOW());\n```\n\n#### **Pros:**\n\n- **Real-Time Capture:** Triggers capture changes immediately when they occur.\n\n- **Detailed Auditing:** Offers a granular record of changes, including before-and-after values, which is useful for audit trails and debugging.\n\n- **Flexibility:** Can be tailored to capture specific columns or changes.\n\n\n#### **Cons:**\n\n- **Performance Impact:** Triggers execute during the transaction, potentially slowing down database write operations.\n\n- **Complexity in Maintenance:** Changes in database schema often require corresponding updates to trigger definitions.\n\n- **Resource Intensive:** In high-transaction environments, the additional load of maintaining an audit table can become significant.\n\n\n## **2.3 Log-Based CDC**\n\nLog-Based CDC reads changes directly from the database’s **write-ahead log (WAL)** or **binary log (binlog)**. This method intercepts the low-level database operations, enabling it to capture every change made to the database without interfering with the application’s normal workflow.\n\n#### **Examples Tools:**\n\n- **Debezium:** An open-source platform that streams database changes.\n\n- **Kafka Connect:** Often used in conjunction with Debezium to integrate with Apache Kafka.\n\n- **AWS DMS:** A managed service for data migration and CDC in the cloud.\n\n\n#### **Pros:**\n\n- **High Efficiency:** Minimizes the impact on the primary database since it leverages existing logs.\n\n- **Scalability:** Well-suited for large, high-transaction environments.\n\n- **Comprehensive Change Capture:** Accurately captures every change, including inserts, updates, and deletes.\n\n- **Minimal Latency:** Provides near real-time data movement, essential for dynamic data-driven systems.\n\n\n#### **Cons:**\n\n- **Complex Setup:** May require additional configuration and understanding of the underlying database logs.\n\n- **Dependency on Database Features:** Not all databases expose their logs in a manner that is easy to consume.\n\n- **Tooling Overhead:** Often necessitates integration with additional tools or services, which can add to the overall system complexity.\n\n\n> In modern applications, Log-based CDC is generally preferred because it efficiently captures all types of changes (inserts, updates, and deletes) directly from transaction logs, minimizes impact on the primary database, and scales well with high data volumes.\n\n* * *\n\n# **3\\. Real-World Use Cases of CDC**\n\n## 3.1. Microservices Communication\n\nIn a microservices architecture, individual services often need to communicate and share state changes without being tightly coupled.\n\n[![](https://substackcdn.com/image/fetch/$s_!YapJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb5b112d-46df-4e5f-ab74-4ff9ffea0051_2166x1282.png)](https://substackcdn.com/image/fetch/$s_!YapJ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb5b112d-46df-4e5f-ab74-4ff9ffea0051_2166x1282.png)\n\nWith CDC in place, the change is captured and propagated via a messaging system (such as Kafka) so that each microservice can stay updated on the relevant changes in other services' databases without needing direct service-to-service calls.\n\n## 3.2 Event Sourcing\n\nEvent sourcing involves recording every change to an application state as a sequence of events. CDC can be leveraged to capture these changes in real time, building a complete log of all modifications.\n\n[![](https://substackcdn.com/image/fetch/$s_!Ac8n!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcba3de12-a47c-473b-9d5e-1ec58f39f564_1588x1128.png)](https://substackcdn.com/image/fetch/$s_!Ac8n!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcba3de12-a47c-473b-9d5e-1ec58f39f564_1588x1128.png)\n\n#### **Example:**\n\nConsider a financial application that logs every transaction. Instead of simply updating an account’s balance, every deposit, withdrawal, or transfer is recorded as an event. CDC captures these events and builds a detailed log of all state changes. This audit trail can later be used to reconstruct any account’s history or to debug issues.\n\n## 3.3 Data Warehousing\n\nData warehousing involves consolidating large volumes of transactional data for analysis and reporting. CDC can capture database changes as they happen and push them into a data warehouse in near real-time.\n\n[![](https://substackcdn.com/image/fetch/$s_!2lTB!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbd4d88c-fb63-4a21-bce8-8f622fbf58b1_2616x1374.png)](https://substackcdn.com/image/fetch/$s_!2lTB!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbd4d88c-fb63-4a21-bce8-8f622fbf58b1_2616x1374.png)\n\nAnalysts and decision-makers then use up-to-date data for reporting, analytics and dashboards.\n\n## 3.4 Cache Invalidation\n\nCaches are used to improve application performance by storing frequently accessed data. However, stale cache data can cause issues, leading to outdated or incorrect information being displayed.\n\nCDC can trigger cache updates automatically whenever the underlying data changes.\n\n[![](https://substackcdn.com/image/fetch/$s_!IPFs!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff728d711-09f5-40da-9d77-6969a8b45ace_2262x1552.png)](https://substackcdn.com/image/fetch/$s_!IPFs!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff728d711-09f5-40da-9d77-6969a8b45ace_2262x1552.png)\n\n#### **Example:**\n\nAn online news platform uses caching to speed up page loads for popular articles. However, when an article is updated (e.g., a correction is issued or new content is added), the cache must be invalidated to prevent serving stale content.\n\nWith CDC, changes in the content database are captured and automatically trigger cache updates, ensuring readers always see the most current information.\n\n* * *\n\n# **4\\. Implementing CDC with Debezium and Kafka**\n\n**[Debezium](https://debezium.io/)** is a popular open-source tool that provides log-based CDC for various databases like MySQL, PostgreSQL, and MongoDB.\n\nWhen integrated with Apache Kafka, Debezium can capture and stream database changes in near real time.\n\n### **Step 1: Set Up Kafka and Debezium**\n\nBefore configuring Debezium, you need to have a running Kafka cluster.\n\n```\n# Start Zookeeper\nbin/zookeeper-server-start.sh config/zookeeper.properties &\n\n# Start Kafka Broker\nbin/kafka-server-start.sh config/server.properties &\n```\n\n### **Step 2: Configure Debezium Connector for MySQL**\n\nNext, create a Debezium connector configuration to capture changes from your MySQL database. This configuration tells Debezium which database and tables to monitor, along with necessary connection details.\n\n```\n{\n  \"name\": \"inventory-connector\",\n  \"config\": {\n    \"connector.class\": \"io.debezium.connector.mysql.MySqlConnector\",\n    \"database.hostname\": \"localhost\",\n    \"database.port\": \"3306\",\n    \"database.user\": \"cdc_user\",\n    \"database.password\": \"password\",\n    \"database.server.id\": \"184054\",\n    \"database.include.list\": \"ecommerce\",\n    \"table.include.list\": \"ecommerce.orders\",\n    \"database.history.kafka.bootstrap.servers\": \"localhost:9092\",\n    \"database.history.kafka.topic\": \"dbhistory.inventory\"\n  }\n}\n```\n\n### **Step 3: Listen for Changes**\n\nOnce the Debezium connector is properly configured and running, it starts capturing change events from the MySQL database.\n\nThese events are then published to Kafka topics. You can consume these events using Kafka command-line tools or any Kafka consumer application.\n\n```\nbin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic dbhistory.inventory --from-beginning\n```\n\n* * *\n\n# **5\\. Challenges and Considerations**\n\nWhile CDC is a powerful tool for real-time data integration, its implementation comes with several challenges that must be carefully managed:\n\n1. **Schema Evolution**: Databases evolve over time, with changes such as adding or modifying columns. A robust CDC pipeline must gracefully adapt to schema alterations, ensuring that no data changes are lost or misinterpreted.\n\n2. **High Throughput Handling**: In high-transaction environments, large volumes of data changes can occur rapidly. It’s essential to design a CDC system that can process and relay these events efficiently to avoid overwhelming downstream systems.\n\n3. **Ordering Guarantees**: Maintaining the correct sequence of events is critical, especially in distributed architectures. The CDC solution should ensure that events are processed in the exact order they occurred, preserving data integrity across all consuming services.\n\n4. **Security and Compliance**: Because CDC involves capturing detailed data changes, it can expose sensitive information if not properly managed. Implementing robust security measures such as encryption, data masking, and strict access controls is vital to protect data and comply with regulatory requirements.\n\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/change-data-capture-cdc?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n[![Sachin's avatar](https://substackcdn.com/image/fetch/$s_!Qx84!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9e20d93a-768f-426d-8ba9-b84530990da6_144x144.png)](https://substack.com/profile/109519556-sachin)[![Vaibhav Jindal's avatar](https://substackcdn.com/image/fetch/$s_!wZox!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75c739c1-63a0-4696-a24f-b61956aafc6d_4032x3024.jpeg)](https://substack.com/profile/34420025-vaibhav-jindal)[![Chanakya Rudhra B's avatar](https://substackcdn.com/image/fetch/$s_!Cteh!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1dce9653-1571-4c49-b2c5-113629fbc5a4_144x144.png)](https://substack.com/profile/119142510-chanakya-rudhra-b)[![Saket's avatar](https://substackcdn.com/image/fetch/$s_!YldW!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b9b8e53-a627-4e48-8e65-f5acb7610b89_144x144.png)](https://substack.com/profile/36067354-saket)[![Ishan Gupta's avatar](https://substackcdn.com/image/fetch/$s_!dDX3!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9648e1ab-a756-4d53-a549-56fb82afa972_1024x1028.jpeg)](https://substack.com/profile/18530345-ishan-gupta)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/change-data-capture-cdc"
    },
    {
      "article_title": "Caching 101",
      "article_title_citation": "https://blog.algomaster.io/p/4d7d6f8a-6803-4c7b-85ca-864c87c2cbf2",
      "article_content_markdown": "Caching is a technique used to temporarily store copies of data in **high-speed storage** layers (such as RAM) to reduce the time taken to access data.\n\n[![](https://substackcdn.com/image/fetch/$s_!LHKl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb4b7b7b-7793-4c49-a999-21464ec7545d_1406x896.png)](https://substackcdn.com/image/fetch/$s_!LHKl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb4b7b7b-7793-4c49-a999-21464ec7545d_1406x896.png)\n\nThe primary goal of caching is to improve system performance by **reducing latency**, offloading the main data store, and providing **faster data retrieval.**\n\n* * *\n\n# 1\\. Why Use Caching?\n\nCaching is essential for the following reasons:\n\n- **Improved Performance:** By storing frequently accessed data in a cache, the time required to retrieve that data is significantly reduced.\n\n- **Reduced Load on Backend Systems:** Caching reduces the number of requests that need to be processed by the backend, freeing up resources for other operations.\n\n- **Increased Scalability**: Caches help in handling a large number of read requests, making the system more scalable.\n\n- **Cost Efficiency**: By reducing the load on backend systems, caching can help lower infrastructure costs.\n\n- **Enhanced User Experience**: Faster response times lead to a better user experience, particularly for web and mobile applications.\n\n\n* * *\n\n# 2\\. Types of Caching\n\n### 2.1 In-Memory Cache\n\nIn-memory caches store data in the **main memory (RAM)** for extremely fast access.\n\nThese caches are typically used for session management, storing frequently accessed objects, and as a front for databases.\n\n> Examples: **Redis** and **Memcached**.\n\n### 2.2 Distributed Cache\n\nA distributed cache spans **multiple servers** and is designed to handle large-scale systems.\n\nIt ensures that cached data is available across different nodes in a distributed system.\n\n> Examples: **Redis Cluster** and **Amazon ElastiCache**.\n\n### 2.3 Client-Side Cache\n\nClient-side caching involves storing data on the client device, typically in the form of **cookies**, **local storage**, or application-specific caches.\n\nThis is commonly used in web browsers to cache static assets like images, scripts, and stylesheets.\n\n### 2.4 Database Cache\n\nDatabase caching involves storing frequently queried database results in a cache.\n\nThis reduces the number of queries made to the database, improving performance and scalability.\n\n### 2.5 Content Delivery Network (CDN)\n\nCDN is used to store copies of content on servers distributed across different geographical locations.\n\nThis reduces latency by serving content from a server closer to the user.\n\n* * *\n\n# 3\\. Caching Strategies\n\n- **Read-Through Cache**: The application first checks the cache for data. If it's not there (a cache miss), it retrieves the data from the database and updates the cache.\n\n- **Write-Through Cache**: Data is written to both the cache and the database simultaneously, ensuring consistency but potentially impacting write performance.\n\n- **Write-Back Cache**: Data is written to the cache first and later synchronized with the database, improving write performance but risking data loss.\n\n- **Cache-Aside (Lazy Loading)**: The application is responsible for reading and writing from both the cache and the database.\n\n\nTo learn more about caching strategies, checkout this article:\n\n[![Top 5 Caching Strategies Explained](https://substackcdn.com/image/fetch/$s_!qQlQ!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b38086e-3798-4d29-8231-33c8e84ffbc6_665x468.png)](https://blog.algomaster.io/p/top-5-caching-strategies-explained)\n\n[**Top 5 Caching Strategies Explained**](https://blog.algomaster.io/p/top-5-caching-strategies-explained)\n\n[Ashish Pratap Singh](https://substack.com/profile/83602743-ashish-pratap-singh)\n\n·\n\nOctober 23, 2024\n\n[Read full story](https://blog.algomaster.io/p/top-5-caching-strategies-explained)\n\n* * *\n\n# 4\\. Cache Eviction Policies\n\nTo manage the limited size of a cache, eviction policies are used to determine which data should be removed when the cache is full.\n\n### 4.1 Least Recently Used (LRU)\n\nLRU evicts the least recently accessed data when the cache is full. It assumes that recently used data will likely be used again soon.\n\n### 4.2 Least Frequently Used (LFU)\n\nLFU evicts data that has been accessed the least number of times, under the assumption that rarely accessed data is less likely to be needed.\n\n### 4.3 First In, First Out (FIFO)\n\nFIFO evicts the oldest data in the cache first, regardless of how often or recently it has been accessed.\n\n### 4.4 Time-to-Live (TTL)\n\nTTL is a time-based eviction policy where data is removed from the cache after a specified duration, regardless of usage.\n\nTo learn more about caching eviction policies, checkout this article:\n\n[![7 Cache Eviction Strategies You Should Know](https://substackcdn.com/image/fetch/$s_!_wbf!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe981dbbb-6d70-41ad-b6df-43c5bcb20f76_582x390.png)](https://blog.algomaster.io/p/7-cache-eviction-strategies)\n\n[**7 Cache Eviction Strategies You Should Know**](https://blog.algomaster.io/p/7-cache-eviction-strategies)\n\n[Ashish Pratap Singh](https://substack.com/profile/83602743-ashish-pratap-singh)\n\n·\n\nJanuary 2, 2025\n\n[Read full story](https://blog.algomaster.io/p/7-cache-eviction-strategies)\n\n* * *\n\n# 5\\. Challenges and Considerations\n\n1. **Cache Coherence**: Ensuring that data in the cache remains consistent with the source of truth (e.g., the database).\n\n2. **Cache Invalidation**: Determining when and how to update or remove stale data from the cache.\n\n3. **Cold Start**: Handling scenarios when the cache is empty, such as after a system restart.\n\n4. **Cache Eviction Policies**: Deciding which items to remove when the cache reaches capacity (e.g., Least Recently Used, Least Frequently Used).\n\n5. **Cache Penetration**: Preventing malicious attempts to repeatedly query for non-existent data, potentially overwhelming the backend.\n\n6. **Cache Stampede**: Managing situations where many concurrent requests attempt to rebuild the cache simultaneously.\n\n\n* * *\n\n# 6\\. Best Practices for Implementing Caching\n\n- **Cache the Right Data:** Focus on caching data that is expensive to compute or retrieve and that is frequently accessed.\n\n- **Set Appropriate TTLs:** Use TTLs to automatically invalidate cache entries and prevent stale data.\n\n- **Consider Cache Warming**: Preload essential data into the cache to avoid cold starts.\n\n- **Monitor Cache Performance:** Regularly monitor cache hit/miss ratios and adjust caching strategies based on usage patterns.\n\n- **Use Layered Caching:** Implement caching at multiple layers (e.g., client-side, server-side, CDN) to maximize performance benefits.\n\n- **Handle Cache Misses Gracefully:** Ensure that the system can handle cache misses efficiently without significant performance degradation.\n\n\n* * *\n\n# 7\\. Conclusion\n\nCaching is a powerful technique in system design that, when implemented correctly, can drastically improve the performance, scalability, and cost-efficiency of a system.\n\nHowever, it comes with its own set of challenges, particularly around consistency and invalidation.\n\nBy understanding the different types of caches, cache placement strategies, and best practices, you can design a robust caching strategy that meets the needs of your application.\n\n* * *\n\n#### Subscribe to AlgoMaster Newsletter\n\nBy Ashish Pratap Singh · Thousands of paid subscribers\n\nMaster Coding and System Design Interviews. Level up your Software Engineering career. Subscribe and get a FREE System Design Interview Handbook in your inbox.\n\nSubscribe\n\nBy subscribing, I agree to Substack's [Terms of Use](https://substack.com/tos), and acknowledge its [Information Collection Notice](https://substack.com/ccpa#personal-data-collected) and [Privacy Policy](https://substack.com/privacy).\n\n[![Vansh Thukral's avatar](https://substackcdn.com/image/fetch/$s_!DxQj!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7201ea9c-bd7a-4349-902a-2a7a91f29086_144x144.png)](https://substack.com/profile/158726009-vansh-thukral)[![koushik naidu mullaguru's avatar](https://substackcdn.com/image/fetch/$s_!2-e2!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F432b8872-7c75-4f30-a8ae-760719f0ad4d_144x144.png)](https://substack.com/profile/268118691-koushik-naidu-mullaguru)[![Gunjan Bali's avatar](https://substackcdn.com/image/fetch/$s_!c9V2!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f71acfa-8a53-4428-accc-b0acf5556a27_144x144.png)](https://substack.com/profile/9551313-gunjan-bali)[![Adarsh Kumar's avatar](https://substackcdn.com/image/fetch/$s_!RaEb!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F628fc2b9-1eee-4028-b4aa-571f09ef43b8_144x144.png)](https://substack.com/profile/269490078-adarsh-kumar)[![Annu Sharma's avatar](https://substackcdn.com/image/fetch/$s_!pwVo!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e63e538-da85-4547-8acb-ffd3aa1aefe1_144x144.png)](https://substack.com/profile/175698890-annu-sharma)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/4d7d6f8a-6803-4c7b-85ca-864c87c2cbf2"
    },
    {
      "article_title": "Top 5 Caching Strategies Explained",
      "article_title_citation": "https://blog.algomaster.io/p/top-5-caching-strategies-explained",
      "article_content_markdown": "**Caching** is a powerful technique to **reduce latency** and **improve system performance**.\n\nThere are several **caching strategies**, depending on what a system needs - whether the focus is on optimizing for **read-heavy** workloads, **write-heavy** operations, or ensuring **data consistency**.\n\nIn this article, we'll cover the **5 most common caching strategies** that frequently come up in **system design discussions** and widely used in **real-world applications**.\n\n* * *\n\nIf you’re finding this newsletter valuable and want to deepen your learning, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll receive an **exclusive deep-dive article** every week, access to a structured **[System Design Resource](https://algomaster.io/learn/system-design) (** 100+topics and interview questions **)**, and other **[premium perks](https://blog.algomaster.io/about#%C2%A7paid-subscribers-benefits)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n# 1\\. Read Through\n\nIn the **Read Through** strategy, the cache acts as an intermediary between the application and the database.\n\nWhen the application requests data, it first looks in the cache.\n\nIf data is available ( **cache hit**), it’s returned to the application.\n\nIf the data is not available ( **cache miss**), the cache itself is responsible for fetching the data from the database, storing it, and returning it to the application.\n\n[![](https://substackcdn.com/image/fetch/$s_!wBJO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4b1e05b5-a02f-411d-a1ea-628789582366_777x246.png)](https://substackcdn.com/image/fetch/$s_!wBJO!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4b1e05b5-a02f-411d-a1ea-628789582366_777x246.png) **Visualized using [Multiplayer](https://dub.sh/7c4EZAY)**\n\nThis approach **simplifies application logic** because the application does not need to handle the logic for fetching and updating the cache.\n\nThe cache itself handles both reading from the database and storing the requested data automatically. This minimizes unnecessary data in the cache and ensures that frequently accessed data is readily available.\n\nFor **cache hits**, Read Through provides **low-latency** data access.\n\nBut for **cache misses**, there is a potential **delay** while the cache queries the database and stores the data. This can result in higher latency during initial reads.\n\nTo prevent the cache from serving stale data, a **time-to-live (TTL)** can be added to cached entries. TTL automatically expires the data after a specified duration, allowing it to be reloaded from the database when needed.\n\n> **Read Through caching** is best suited for **read-heavy applications** where data is accessed frequently but updated less often, such as content delivery systems (CDNs), social media feeds, or user profiles.\n\n* * *\n\n# 2\\. Cache Aside\n\n**Cache Aside**, also known as **\"Lazy Loading\"**, is a strategy where the **application code** handles the interaction between the cache and the database. The data is loaded into the cache only when needed.\n\nThe application first checks the cache for data. If the data exists in cache ( **cache hit**), it’s returned to the application.\n\nIf the data isn't found in cache ( **cache miss**), the application retrieves it from the database (or the primary data store), then loads it into the cache for subsequent requests.\n\n[![](https://substackcdn.com/image/fetch/$s_!Y9wC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faea54ca9-0151-4ccb-8743-e5f7e8e7d8eb_692x439.png)](https://substackcdn.com/image/fetch/$s_!Y9wC!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faea54ca9-0151-4ccb-8743-e5f7e8e7d8eb_692x439.png) **Visualized using [Multiplayer](https://dub.sh/7c4EZAY)**\n\nThe cache acts as a **\"sidecar\"** to the database, and it's the responsibility of the application to manage when and how data is written to the cache.\n\nTo avoid stale data, we can set a **time-to-live (TTL)** for cached data. Once the TTL expires, the data is automatically removed from the cache.\n\n> **Cache Aside** is perfect for systems where the **read-to-write** ratio is **high**, and data updates are infrequent. For example, in an e-commerce website, product data (like prices, descriptions, or stock status) is often read much more frequently than it's updated.\n\n[Share](https://blog.algomaster.io/p/top-5-caching-strategies-explained?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n# 3\\. Write Through\n\nIn the **Write Through** strategy, every write operation is executed on both the cache and the database at the same time.\n\nThis is a **synchronous process**, meaning both the cache and the database are updated as part of the same operation, ensuring that there is no delay in data propagation.\n\n[![](https://substackcdn.com/image/fetch/$s_!XGEw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b749d07-1e86-4d0c-b7d1-66426cda1d29_777x256.png)](https://substackcdn.com/image/fetch/$s_!XGEw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b749d07-1e86-4d0c-b7d1-66426cda1d29_777x256.png) **Visualized using [Multiplayer](https://dub.sh/7c4EZAY)**\n\nThis approach ensures that the cache and the database remain **synchronized** and the read requests from the cache will always return the **latest data**, avoiding the risk of serving stale data.\n\nIn a Write Through caching strategy, cache expiration policies (such as TTL) are generally not necessary. However, if you are concerned about cache memory usage, you can implement a TTL policy to remove infrequently accessed data after a certain time period.\n\nThe biggest advantage of Write Through is that it ensures strong **data consistency** between the cache and the database.\n\nSince the cache always contains the latest data, **read operations** benefit from **low latency** because data can be directly retrieved from the cache.\n\nHowever, **write latency** can be **higher** due to the overhead of writing to both the cache and the database.\n\n> **Write Through is** ideal for **consistency-critical systems**, such as financial applications or online transaction processing systems, where the cache and database must always have the latest data.\n\n* * *\n\n# 4\\. Write Around\n\n**Write Around** is a caching strategy where data is written directly to the database, bypassing the cache.\n\nThe cache is only updated when the data is requested later during a read operation, at which point the **Cache Aside** strategy is used to load the data into the cache.\n\n[![](https://substackcdn.com/image/fetch/$s_!qQlQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b38086e-3798-4d29-8231-33c8e84ffbc6_665x468.png)](https://substackcdn.com/image/fetch/$s_!qQlQ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b38086e-3798-4d29-8231-33c8e84ffbc6_665x468.png)\n\nThis approach ensures that only **frequently accessed data** resides in the cache, preventing it from being polluted by data that may not be accessed again soon.\n\nIt keeps the cache clean by avoiding unnecessary data that might not be requested after being written.\n\n**Writes** are relatively **faster** because they only target the database and don’t incur the overhead of writing to the cache.\n\n**TTL** can be used to ensure that data does not remain in the cache indefinitely. Once the TTL expires, the data is removed from the cache, forcing the system to retrieve it from the database again if needed.\n\n> **Write Around** caching is best used in **write-heavy systems** where data is frequently written or updated, but **not immediately or frequently read** such as logging systems.\n\n* * *\n\n# 5\\. Write Back\n\nIn the **Write Back** strategy, data is first written to the cache and then **asynchronously** written to the database at a later time.\n\nThis strategy focuses on **minimizing write latency** by deferring database writes.\n\nThis deferred writing means that the cache acts as the primary storage during write operations, while the database is updated periodically in the background.\n\n[![](https://substackcdn.com/image/fetch/$s_!XY1c!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a47d998-e3d1-4134-9c67-7e6981d9c0c2_777x256.png)](https://substackcdn.com/image/fetch/$s_!XY1c!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a47d998-e3d1-4134-9c67-7e6981d9c0c2_777x256.png) **Visualized using [Multiplayer](https://dub.sh/7c4EZAY)**\n\nThe key advantage of Write Back is that it significantly **reduces write latency**, as writes are completed quickly in the cache, and the database updates are delayed or batched.\n\nHowever, with this approach, there is a risk of **data loss** if the cache fails before the data has been written to the database.\n\nThis can be mitigated by using persistent caching solutions like **Redis with AOF (Append Only File)**, which logs every write operation to disk, ensuring data durability even if the cache crashes.\n\nWrite Back doesn't require invalidation of cache entries, as the cache itself is the source of truth during the write process.\n\n> **Write Back** caching is ideal for **write-heavy** scenarios where write operations need to be **fast** and **frequent**, but **immediate consistency** with the database is not critical, such as logging systems and social media feeds.\n\n* * *\n\n# Conclusion\n\nChoosing the right caching strategy depends on your system's specific requirements.\n\nHere's a tabular summary:\n\n[![](https://substackcdn.com/image/fetch/$s_!3uS9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d856223-f042-4773-b744-9359e50fdee1_3008x1776.png)](https://substackcdn.com/image/fetch/$s_!3uS9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d856223-f042-4773-b744-9359e50fdee1_3008x1776.png)\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/top-5-caching-strategies-explained?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re finding this newsletter helpful and want to get even more value, consider becoming a **paid subscriber**.\n\nAs a paid subscriber, you'll receive an **exclusive deep dive** every week, access to a **[comprehensive system design learning resource](https://algomaster.io/learn/system-design)** , and other **[premium perks](https://blog.algomaster.io/about#%C2%A7paid-subscribers-benefits)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![User's avatar](https://substackcdn.com/image/fetch/$s_!7cZK!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc660300b-74d3-47ce-865f-bcb36da141de_144x144.png)](https://substack.com/profile/210164535-user)[![muhamad haikal's avatar](https://substackcdn.com/image/fetch/$s_!Y6Jp!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e5cb758-d452-47a7-8542-988e84e65116_96x96.jpeg)](https://substack.com/profile/95654891-muhamad-haikal)[![Muhammad Efath's avatar](https://substackcdn.com/image/fetch/$s_!DpHZ!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5af1fc2e-a967-4dbb-b870-48d883b3877e_144x144.png)](https://substack.com/profile/63413413-muhammad-efath)[![Steven Chu's avatar](https://substackcdn.com/image/fetch/$s_!4IDX!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdae88cf-81b4-40d0-a5a7-f3379a2d2b1d_96x96.jpeg)](https://substack.com/profile/85848147-steven-chu)[![Andy Winarko's avatar](https://substackcdn.com/image/fetch/$s_!ph_l!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5df150cb-d96c-4d1e-a334-2e990729a7df_222x222.jpeg)](https://substack.com/profile/254526959-andy-winarko)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/top-5-caching-strategies-explained"
    },
    {
      "article_title": "7 Cache Eviction Strategies You Should Know",
      "article_title_citation": "https://blog.algomaster.io/p/7-cache-eviction-strategies",
      "article_content_markdown": "**Caching** is a technique to make applications lightning fast, reduce database load, and improve user experience.\n\nBut, cache memory is **limited** \\- you can’t store everything.\n\nSo, how do you decide which items to keep and which ones to evict when space runs out?\n\nThis is where **cache eviction strategies** come into play. They determine which items are removed to make room for new ones.\n\nIn this article, we’ll dive into **Top** **7 Cache Eviction Strategies** explaining what they are, how they work, their pros and cons.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n# **1\\. Least Recently Used** (LRU)\n\n**LRU** evicts the item that hasn’t been used for the longest time.\n\nThe idea is simple: if you haven’t accessed an item in a while, it’s less likely to be accessed again soon.\n\n[![](https://substackcdn.com/image/fetch/$s_!jd2T!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d9520eb-cc71-4a8e-a036-f27067ebbdb1_534x382.png)](https://substackcdn.com/image/fetch/$s_!jd2T!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d9520eb-cc71-4a8e-a036-f27067ebbdb1_534x382.png) **Visualized using [Multiplayer](https://dub.sh/imMcs2n)**\n\n#### How it Works\n\n- **Access Tracking**: LRU keeps track of when each item in the cache was last accessed. This can be done using various data structures, such as a **doubly linked list** or a combination of a **hash map** and a **queue**.\n\n- **Cache Hit (Item Found in Cache):** When an item is accessed, it is moved to the **most recently used** position in the tracking data structure (e.g., moving it to the front of a list).\n\n- **Cache Miss (Item Not Found in Cache):**\n\n  - If the item isn’t in the cache and the cache has free space, it is added directly.\n\n  - If the cache is full, the **least recently used item** is evicted to make space for the new item.\n- **Eviction:** The item that has been accessed least recently (tracked at the beginning of the list) is removed from the cache.\n\n\nConsider a cache with a capacity of 3:\n\n1. **Initial State**: Empty cache.\n\n2. Add **A** → Cache: \\[A\\]\n\n3. Add **B** → Cache: \\[A, B\\]\n\n4. Add **C** → Cache: \\[A, B, C\\]\n\n5. Access **A** → Cache: \\[B, C, A\\] (A becomes recently used)\n\n6. Add **D** → Cache: \\[C, A, D\\] (B is evicted as it's the “least recently used”)\n\n\n#### **Pros**:\n\n1. **Intuitive**: Easy to understand and widely adopted.\n\n2. **Efficient**: Keeps frequently accessed items in the cache.\n\n3. **Optimized for Real-World Usage**: Matches many access patterns, such as web browsing and API calls.\n\n\n#### **Cons**:\n\n1. **Metadata Overhead**: Tracking usage order can consume additional memory.\n\n2. **Performance Cost**: For large caches, maintaining the access order may introduce computational overhead.\n\n3. **Not Adaptive**: Assumes past access patterns will predict future usage, which may not always hold true.\n\n\n* * *\n\n# **2\\. Least Frequently Used** (LFU)\n\n**LFU** evicts the item with the lowest access frequency. It assumes that items accessed less frequently in the past are less likely to be accessed in the future.\n\nUnlike LRU, which focuses on **recency**, LFU emphasizes **frequency** of access.\n\n[![](https://substackcdn.com/image/fetch/$s_!wmCU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc66e78e2-85aa-43b0-9a77-8890d58c618d_544x381.png)](https://substackcdn.com/image/fetch/$s_!wmCU!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc66e78e2-85aa-43b0-9a77-8890d58c618d_544x381.png) **Visualized using [Multiplayer](https://dub.sh/imMcs2n)**\n\n#### How it Works\n\n- **Track Access Frequency**: LFU maintains a frequency count for each item in the cache, incrementing the count each time the item is accessed.\n\n- **Cache Hit (Item Found in Cache):** When an item is accessed, its frequency count is increased.\n\n- **Cache Miss (Item Not Found in Cache):**\n\n  - If the cache has available space, the new item is added with an initial frequency count of 1.\n\n  - If the cache is full, the **item with the lowest frequency** is evicted to make room for the new item. If multiple items share the same lowest frequency, a secondary strategy (like LRU or FIFO) resolves ties.\n- **Eviction**: Remove the item with the smallest frequency count.\n\n\nConsider a cache with a capacity of 3:\n\n1. **Initial State**: Empty cache.\n\n2. Add **A** → Cache: \\[A (freq=1)\\]\n\n3. Add **B** → Cache: \\[A (freq=1), B (freq=1)\\]\n\n4. Add **C** → Cache: \\[A (freq=1), B (freq=1), C (freq=1)\\]\n\n5. Access **A** → Cache: \\[A (freq=2), B (freq=1), C (freq=1)\\]\n\n6. Add **D** → Cache: \\[A (freq=2), C (freq=1), D (freq=1)\\] (B is evicted as it has the lowest frequency).\n\n7. Access **C** → Cache: \\[A (freq=2), C (freq=2), D (freq=1)\\]\n\n\n#### **Pros**:\n\n1. **Efficient for Predictable Patterns**: Retains frequently accessed data, which is often more relevant.\n\n2. **Highly Effective for Popular Data**: Works well in scenarios with clear \"hot\" items.\n\n\n#### **Cons**:\n\n1. **High Overhead**: Requires additional memory to track frequency counts.\n\n2. **Slower Updates**: Tracking and updating frequency can slow down operations.\n\n3. **Not Adaptive**: May keep items that were frequently accessed in the past but are no longer relevant.\n\n\n* * *\n\n# 3\\. First In, First Out (FIFO)\n\nFIFO evicts the item that was added first, regardless of how often it’s accessed.\n\nFIFO operates under the assumption that items added earliest are least likely to be needed as the cache fills up.\n\n[![](https://substackcdn.com/image/fetch/$s_!tdo3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59a1f409-f309-4e07-a00b-0765ab133a46_653x292.png)](https://substackcdn.com/image/fetch/$s_!tdo3!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59a1f409-f309-4e07-a00b-0765ab133a46_653x292.png) **Visualized using [Multiplayer](https://dub.sh/imMcs2n)**\n\n#### **How It Works**\n\n- **Item Insertion**: When an item is added to the cache, it is placed at the end of the queue.\n\n- **Cache Hit (Item Found in Cache):** No changes are made to the order of items. FIFO does not prioritize recently accessed items.\n\n- **Cache Miss (Item Not Found in Cache):**\n\n  - If there is space in the cache, the new item is added to the end of the queue.\n\n  - If the cache is full, the item at the front of the queue (the oldest item) is evicted to make space for the new item.\n- **Eviction**: The oldest item, which has been in the cache the longest, is removed to make room for the new item.\n\n\nLet’s assume a cache with a capacity of 3:\n\n1. Add **A** → Cache: \\[A\\]\n\n2. Add **B** → Cache: \\[A, B\\]\n\n3. Add **C** → Cache: \\[A, B, C\\]\n\n4. Add **D** → Cache: \\[B, C, D\\] (A is evicted because it was added first).\n\n5. Access **B** → Cache: \\[B, C, D\\] (Order remains unchanged).\n\n6. Add **E** → Cache: \\[C, D, E\\] (B is evicted because it was the oldest remaining item).\n\n\n#### **Pros**:\n\n1. **Simple to Implement**: FIFO is straightforward and requires minimal logic.\n\n2. **Low Overhead**: No need to track additional metadata like access frequency or recency.\n\n3. **Deterministic Behavior**: Eviction follows a predictable order.\n\n\n#### **Cons**:\n\n1. **Ignores Access Patterns**: Items still in frequent use can be evicted, reducing cache efficiency.\n\n2. **Suboptimal for Many Use Cases**: FIFO is rarely ideal in modern systems where recency and frequency matter.\n\n3. **May Waste Cache Space**: If old but frequently used items are evicted, the cache loses its utility.\n\n\n[Share](https://blog.algomaster.io/p/7-cache-eviction-strategies?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n# 4\\. Random Replacement (RR)\n\nRR cache eviction strategy is the simplest of all: when the cache is full, it evicts a random item to make space for a new one.\n\nIt doesn't track recency, frequency, or insertion order, making it a lightweight approach with minimal computational overhead.\n\n[![](https://substackcdn.com/image/fetch/$s_!KHTZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bcfdb7c-ef4c-456b-a6cb-f038303968ce_560x294.png)](https://substackcdn.com/image/fetch/$s_!KHTZ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bcfdb7c-ef4c-456b-a6cb-f038303968ce_560x294.png) **Visualized using [Multiplayer](https://dub.sh/imMcs2n)**\n\nThis simplicity can sometimes be surprisingly effective, especially in systems with unpredictable or highly dynamic access patterns.\n\n#### **How It Works**\n\n- **Item Insertion**: When an item is added to the cache and there is space, it is stored directly.\n\n- **Cache Hit:** If the requested item exists in the cache, it is served, and no changes are made to the cache.\n\n- **Cache Miss:** If the item is not in the cache and the cache is full, a random item is removed.\n\n- **Eviction**: The randomly selected item is removed, and the new item is added to the cache.\n\n\nLet’s assume a cache with a capacity of 3:\n\n1. Add **A** → Cache: \\[A\\]\n\n2. Add **B** → Cache: \\[A, B\\]\n\n3. Add **C** → Cache: \\[A, B, C\\]\n\n4. Add **D** → Cache: \\[B, C, D\\] (A is randomly evicted).\n\n5. Add **E** → Cache: \\[C, E, D\\] (B is randomly evicted).\n\n\n#### **Pros**:\n\n1. **Simple to Implement**: No need for metadata like access frequency or recency.\n\n2. **Low Overhead**: Computational and memory requirements are minimal.\n\n3. **Fair for Unpredictable Access Patterns**: Avoids bias toward recency or frequency, which can be useful in some scenarios.\n\n\n#### **Cons**:\n\n1. **Unpredictable Eviction**: A frequently used item might be evicted, reducing cache efficiency.\n\n2. **Inefficient for Stable Access Patterns**: Doesn’t adapt well when certain items are consistently accessed.\n\n3. **High Risk of Poor Cache Hit Rates**: Random eviction often leads to suboptimal retention of important items.\n\n\n* * *\n\n# 5\\. Most Recently Used (MRU)\n\n**MRU** is the opposite of **Least Recently Used (LRU)**. In MRU, the item that was accessed most recently is the first to be evicted when the cache is full.\n\nThe idea behind MRU is that the most recently accessed item is likely to be a temporary need and won’t be accessed again soon, so evicting it frees up space for potentially more valuable data.\n\n[![](https://substackcdn.com/image/fetch/$s_!bpfH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddfeae1b-ef8d-4a6b-b58a-19abddce3224_534x380.png)](https://substackcdn.com/image/fetch/$s_!bpfH!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddfeae1b-ef8d-4a6b-b58a-19abddce3224_534x380.png) **Visualized using [Multiplayer](https://dub.sh/imMcs2n)**\n\n#### **How It Works**\n\n- **Item Insertion**: When a new item is added to the cache, it is marked as the most recently used.\n\n- **Cache Hit (Item Found in Cache):** When an item is accessed, it is marked as the most recently used.\n\n- **Cache Miss (Item Not Found in Cache):**\n\n  - If the cache has available space, the new item is added directly.\n\n  - If the cache is full, the most recently used item is evicted to make room for the new item.\n- **Eviction**: The item that was accessed or added most recently is removed.\n\n\nLet’s assume a cache with a capacity of 3:\n\n1. Add **A** → Cache: \\[A\\]\n\n2. Add **B** → Cache: \\[A, B\\]\n\n3. Add **C** → Cache: \\[A, B, C\\]\n\n4. Access **C** → Cache: \\[A, B, C\\] (C is marked as the most recently used).\n\n5. Add **D** → Cache: \\[A, B, D\\] (C is evicted as it was the most recently used).\n\n6. Access **B** → Cache: \\[A, B, D\\] (B becomes the most recently used).\n\n7. Add **E** → Cache: \\[A, D, E\\] (B is evicted as it was the most recently used).\n\n\n#### **Pros**:\n\n1. **Effective in Specific Scenarios**: Retains older data, which might be more valuable in certain workloads.\n\n2. **Simple Implementation**: Requires minimal metadata.\n\n\n#### **Cons**:\n\n1. **Suboptimal for Most Use Cases**: MRU assumes recent data is less valuable, which is often untrue for many applications.\n\n2. **Poor Hit Rate in Predictable Patterns**: Fails in scenarios where recently accessed data is more likely to be reused.\n\n3. **Rarely Used in Practice**: Limited applicability compared to other strategies like LRU or LFU.\n\n\n* * *\n\n# 6\\. Time to Live (TTL)\n\n**TTL** is a cache eviction strategy where each cached item is assigned a fixed lifespan. Once an item’s lifespan expires, it is automatically removed from the cache, regardless of access patterns or frequency.\n\nThis ensures that cached data remains fresh and prevents stale data from lingering in the cache indefinitely.\n\n[![](https://substackcdn.com/image/fetch/$s_!_wbf!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe981dbbb-6d70-41ad-b6df-43c5bcb20f76_582x390.png)](https://substackcdn.com/image/fetch/$s_!_wbf!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe981dbbb-6d70-41ad-b6df-43c5bcb20f76_582x390.png) **Visualized using [Multiplayer](https://dub.sh/imMcs2n)**\n\n#### **How It Works**\n\n- **Item Insertion**: When an item is added to the cache, a TTL value (e.g., 10 seconds) is assigned to it. The expiration time is usually calculated as `current time + TTL`.\n\n- **Cache Access (Hit or Miss)**: When an item is accessed, the cache checks its expiration time:\n\n  - If the item is expired, it is removed from the cache, and a cache miss is recorded.\n\n  - If the item is valid, it is served as a cache hit.\n- **Eviction**: Expired items are automatically removed either during periodic cleanup or on access.\n\n\nLet’s assume a cache with a TTL of 5 seconds:\n\n1. Add **A** with TTL = 5s → Cache: \\[A (expires in 5s)\\]\n\n2. Add **B** with TTL = 10s → Cache: \\[A (5s), B (10s)\\]\n\n3. After 6 seconds → Cache: \\[B (expires in 4s)\\] (A is evicted because its TTL expired).\n\n4. Add **C** with TTL = 5s → Cache: \\[B (4s), C (5s)\\]\n\n\nIf an item is accessed after its TTL expires, it results in a cache miss.\n\nTTL is often implemented in caching systems like **Redis** or **Memcached**, where you can specify expiration times for each key.\n\n#### **Pros**:\n\n1. **Ensures Freshness**: Automatically removes stale data, ensuring only fresh items remain in the cache.\n\n2. **Simple to Configure**: TTL values are easy to assign during cache insertion.\n\n3. **Low Overhead**: No need to track usage patterns or access frequency.\n\n4. **Prevents Memory Leaks**: Stale data is cleared out systematically, avoiding cache bloat.\n\n\n#### **Cons**:\n\n1. **Fixed Lifespan**: Items may be evicted prematurely even if they are frequently accessed.\n\n2. **Wasteful Eviction**: Items that haven’t expired but are still irrelevant occupy cache space.\n\n3. **Limited Flexibility**: TTL doesn’t adapt to dynamic workloads or usage patterns.\n\n\n* * *\n\n# 7\\. Two-Tiered Caching\n\nTwo-Tiered Caching combines two layers of cache—usually a **local cache** (in-memory) and a **remote cache** (distributed or shared).\n\n[![](https://substackcdn.com/image/fetch/$s_!EVB4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F784cbd22-6285-4d63-866c-6f9822f6a3cd_325x330.png)](https://substackcdn.com/image/fetch/$s_!EVB4!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F784cbd22-6285-4d63-866c-6f9822f6a3cd_325x330.png) **Visualized using [Multiplayer](https://dub.sh/imMcs2n)**\n\nThe local cache serves as the first layer (hot cache), providing ultra-fast access to frequently used data, while the remote cache acts as the second layer (cold cache) for items not found in the local cache but still needed relatively quickly.\n\n#### **How It Works**\n\n1. **Local Cache (First Tier)**:\n\n   - Resides on the same server as the application, often in memory (e.g., `HashMap`, `LRUCache` in the application)..\n\n   - Provides ultra-fast access to frequently accessed data, reducing latency and server load.\n\n   - Examples: In-memory data structures like `HashMap` or frameworks like **Guava Cache**.\n2. **Remote Cache (Second Tier)**:\n\n   - Shared across multiple servers in the system. Slightly slower due to network overhead but offers larger storage and shared consistency.\n\n   - Used to store data that is not in the local cache but is still frequently needed.\n\n   - Examples: Distributed cache systems like **Redis** or **Memcached**.\n\n**Workflow**:\n\n- A client request checks the **local cache** first.\n\n- If the data is not found (cache miss), it queries the **remote cache**.\n\n- If the data is still not found (another cache miss), it retrieves the data from the primary data source (e.g., a database), stores it in both the local and remote caches, and returns it to the client.\n\n\n#### **Pros**:\n\n1. **Ultra-Fast Access**: Local cache provides near-instantaneous response times for frequent requests.\n\n2. **Scalable Storage**: Remote cache adds scalability and allows data sharing across multiple servers.\n\n3. **Reduces Database Load**: Two-tiered caching significantly minimizes calls to the backend database.\n\n4. **Fault Tolerance**: If the local cache fails, the remote cache acts as a fallback.\n\n\n#### **Cons**:\n\n1. **Complexity**: Managing two caches introduces more overhead, including synchronization and consistency issues.\n\n2. **Stale Data**: Inconsistent updates between tiers may lead to serving stale data.\n\n3. **Increased Latency for Remote Cache Hits**: Accessing the second-tier remote cache is slower than the local cache.\n\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/7-cache-eviction-strategies?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![Giovanni F's avatar](https://substackcdn.com/image/fetch/$s_!1J0C!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9691fd3-2095-4c03-b761-63bb5269c06b_96x96.jpeg)](https://substack.com/profile/161912030-giovanni-f)[![Michael Kubler's avatar](https://substackcdn.com/image/fetch/$s_!9yYv!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F840573cc-707b-4db3-85f3-b710c2385aba_500x500.jpeg)](https://substack.com/profile/109333357-michael-kubler)[![SE Nguyen's avatar](https://substackcdn.com/image/fetch/$s_!cdgU!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f769c33-e4be-484a-91c3-dc2d4581f25d_96x96.png)](https://substack.com/profile/276978339-se-nguyen)[![Pavan D G's avatar](https://substackcdn.com/image/fetch/$s_!Qoo6!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4585246e-7a20-4c62-af02-360436883076_144x144.png)](https://substack.com/profile/278823353-pavan-d-g)[![Vidya Srinivasa Kesarla's avatar](https://substackcdn.com/image/fetch/$s_!mDe-!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7af62d00-c56f-4807-a72f-afe6f02d4483_96x96.jpeg)](https://substack.com/profile/232733382-vidya-srinivasa-kesarla)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/7-cache-eviction-strategies"
    },
    {
      "article_title": "What is a Content Delivery Network?",
      "article_title_citation": "https://blog.algomaster.io/p/content-delivery-networks",
      "article_content_markdown": "Imagine you've built an app that serves **video content** to millions of users worldwide.\n\nTo keep things simple, you host all your videos in **one geographical location**.\n\nAt first, everything seems to work fine—users located **near the server** enjoy smooth playback with minimal buffering.\n\nBut as your audience grows globally, you start noticing a problem.\n\nUsers in distant regions experience **significant latency, slow load times, and frustrating buffering issues.** The farther they are from your server, the longer it takes for data to travel across the network, degrading their experience.\n\n[![](https://substackcdn.com/image/fetch/$s_!fcJQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa67692ec-5972-426f-a1e4-f0db09c76768_2310x896.png)](https://substackcdn.com/image/fetch/$s_!fcJQ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa67692ec-5972-426f-a1e4-f0db09c76768_2310x896.png)\n\nTo fix this, you need a way to **bring your content physically closer to your users,** reducing the distance data must travel.\n\nThis is exactly what a **Content Delivery Network (CDN)** does.\n\nIn this article, we will explore what a CDN is, how it works, its benefits, different use-cases, and popular CDN providers.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n# 1\\. What is a CDN?\n\nA CDN is a geographically distributed network of servers that work together to deliver **web content** (like HTML pages, JavaScript files, stylesheets, images, and videos) to users based on their **geographic location**.\n\n[![Map of globally distributed servers serving content - What is a CDN](https://substackcdn.com/image/fetch/$s_!sN05!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa09696e9-f98e-47bd-9eb9-08a20c60464d_5667x2834.png)](https://substackcdn.com/image/fetch/$s_!sN05!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa09696e9-f98e-47bd-9eb9-08a20c60464d_5667x2834.png) source: https://www.cloudflare.com/learning/cdn/what-is-a-cdn/\n\nThe primary purpose of a CDN is to deliver content to end-users with **high availability** and **performance** by reducing the physical distance between the server and the user.\n\nWhen a user requests content from a website, the CDN redirects the request to the nearest server in its network, **reducing latency** and **improving load times.**\n\n[Share](https://blog.algomaster.io/p/content-delivery-networks?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n# 2\\. How Does a CDN Work?\n\nA **CDN** operates using three key components:\n\n- **Edge Servers** – Located at **[Points of Presence (PoP) locations](https://nilesecure.com/network-design/what-is-a-point-of-presence-pop-definition-how-it-works)**, these servers cache and deliver content closer to users.\n\n- **Origin Servers** – The primary servers where the original content is stored.\n\n- **DNS (Domain Name System)** – Directs user requests to the nearest edge server instead of the origin server.\n\n\nBy leveraging edge servers distributed across multiple geographical regions, CDNs minimize latency and accelerate content delivery.\n\nHere’s a step-by-step breakdown of how a CDN works:\n\n[![](https://substackcdn.com/image/fetch/$s_!fUV6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1ef9c83-5fd9-46e3-8469-c2a43f8b7dd2_1670x1046.png)](https://substackcdn.com/image/fetch/$s_!fUV6!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1ef9c83-5fd9-46e3-8469-c2a43f8b7dd2_1670x1046.png)\n\n1. **User Request** – A user visits a website and requests content, such as an image, a webpage, or a video. This request must be **resolved to a server** that can serve the content.\n\n2. **DNS Resolution** – The browser **sends a DNS query** to resolve the web content address (e.g., `https://cdn.example.com/images/logo.png`) into an IP address. The DNS return the **nearest CDN edge server’s IP address** rather than the origin server.\n\n3. **Cache Check**\n\n   - If the content is **already cached** at the edge server, it is served immediately to the user.\n\n   - If not, the edge server forwards the request to the origin server. The origin server processes the request and **sends the content back** to the edge server. The edge server caches the content it retrieved from the origin server.\n4. **Subsequent Requests** – Once cached, future requests for the same content are served **directly from the edge server**, reducing load on the origin and improving speed.\n\n\n> CDNs use a **Time-to-Live (TTL) mechanism** to determine how long content remains cached before expiring. To ensure users always receive the latest version, **CDNs periodically refresh and update cached content** from the origin server.\n\n* * *\n\n# 3\\. Benefits of Using a CDN\n\n- **Faster Load Times** – By serving content from the nearest edge server, CDNs reduce latency and improve page load speed.\n\n- **Reduced Server Load** – CDNs offload traffic from the origin server by caching static assets, reducing resource consumption.\n\n- **Improved Availability and Reliability** – With multiple servers in different locations, CDNs prevent single points of failure.\n\n- **Scalability**: CDNs can handle traffic spikes more efficiently than traditional hosting, making them ideal for websites with fluctuating traffic patterns.\n\n- **Global Reach**: CDNs make it easier to deliver content to users worldwide, regardless of their location.\n\n- **Enhanced Security** – Many CDNs offer DDoS protection, Web Application Firewalls (WAFs), and bot mitigation to secure applications.\n\n\nWhile CDNs offer many benefits, it’s important to note that they also introduce some challenges like:\n\n- **Increased Complexity:** Integrating a CDN requires proper DNS configuration, cache rules, and content invalidation policies.\n\n- **Increased Cost:** Many CDN providers charge based on bandwidth usage and request volume. For high-traffic websites, CDN costs **can be substantial**, especially for video streaming, gaming, and software distribution.\n\n\nSubscribe to receive new articles every week.\n\nSubscribe\n\n* * *\n\n# 4\\. Use Cases of CDNs\n\n- **Accelerating Website Performance**\n\n  - Websites with **global traffic** use CDNs to ensure **fast page loads** for users regardless of location.\n\n  - **CDNs cache static assets** (images, CSS, JavaScript) at **edge servers**, reducing the time required to fetch them from the origin.\n- **Video Streaming & OTT Platforms**\n\n  - **CDNs optimize video content delivery** by caching video files closer to users, minimizing buffering and latency.\n\n  - Supports **adaptive bitrate streaming** (ABR) to serve video based on the user’s internet speed.\n\n  - **Example:** Netflix, YouTube, and Spotify use CDNs to serve videos and music in real-time to user.\n- **Online Gaming**\n\n  - Multiplayer **online games** require **low-latency** content delivery to ensure a smooth gaming experience.\n\n  - CDNs help distribute game updates, patches, and downloadable content (DLCs) faster.\n- **Content & Media Distribution**\n\n  - News websites and content platforms **deliver images, articles, and videos** through a CDN to handle large traffic spikes.\n- **Software Distribution & Updates**\n\n  - Operating system and software vendors use CDNs to **distribute large files, updates, and patches** quickly.\n\n  - Accelerates the distribution of software updates and applications to users worldwide.\n\n  - **Example:** Microsoft, Apple, and Google use CDNs for distributing Windows updates, macOS updates, and Android app downloads.\n\n* * *\n\n# 5\\. Popular CDN Providers\n\nHere are some of the most widely used CDN providers:\n\n- **[Akamai](https://www.akamai.com/solutions/content-delivery-network)**: One of the oldest and largest CDN providers, known for its extensive global network and robust security features.\n\n- **[Cloudflare](https://www.cloudflare.com/en-in/application-services/products/cdn/)**: Offers a comprehensive suite of performance and security services, including a free tier for smaller websites.\n\n- **[Fastly](https://www.fastly.com/products/cdn)**: Known for its real-time content delivery and edge computing capabilities.\n\n- **[Amazon CloudFront](https://aws.amazon.com/cloudfront/)**: Integrated with AWS, provides seamless scalability and extensive integration with other AWS services.\n\n- **[Google Cloud CDN](https://cloud.google.com/cdn?hl=en)**: Leverages Google’s global network infrastructure to ensure high performance and low-latency content delivery.\n\n- **[Microsoft Azure CDN](https://azure.microsoft.com/en-us/products/cdn)** – Designed for applications hosted on Microsoft Azure, providing seamless integration with other Azure services.\n\n\n### **Choosing the Right CDN**\n\nSelecting the best CDN depends on your **use case**, **budget**, and **platform integration requirements**.\n\nCloudflare and Fastly are great for performance and security, while CloudFront, Google Cloud CDN, and Azure CDN offer seamless cloud integration.\n\nAkamai is a preferred choice for high-scale enterprise applications requiring a robust global network.\n\n* * *\n\n# Conclusion\n\nA Content Delivery Network is an essential tool for any online service aiming to deliver content quickly and reliably to a global audience.\n\nBy understanding how CDNs work, the benefits they offer, and how to choose and implement the right one, you can significantly enhance the performance, security, and scalability of your web applications.\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/content-delivery-networks?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)** and **[X](https://twitter.com/ashishps_1)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![Kumar Rounak's avatar](https://substackcdn.com/image/fetch/$s_!x_z0!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc80976d4-f745-446e-abb5-abe0dfd11260_144x144.png)](https://substack.com/profile/4387132-kumar-rounak)[![Ayush Jaiswal's avatar](https://substackcdn.com/image/fetch/$s_!8c9I!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb04a8635-583d-48c5-ad75-3b052af3384b_96x96.png)](https://substack.com/profile/227369822-ayush-jaiswal)[![Allan's avatar](https://substackcdn.com/image/fetch/$s_!dEuO!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56fda53b-3928-4ed7-b49b-418703607882_144x144.png)](https://substack.com/profile/40129440-allan)[![SASI TILAK RAVI's avatar](https://substackcdn.com/image/fetch/$s_!3mw9!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F937aafcf-5b08-4b81-b7b8-eccf6416170c_144x144.png)](https://substack.com/profile/129737919-sasi-tilak-ravi)[![Aparna Panwar's avatar](https://substackcdn.com/image/fetch/$s_!ph29!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9349464f-af73-4cc5-aaf2-ab9470fe4e8e_1176x1176.jpeg)](https://substack.com/profile/88673369-aparna-panwar)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/content-delivery-networks"
    },
    {
      "article_title": "Rate Limiting Algorithms Explained with Code",
      "article_title_citation": "https://blog.algomaster.io/p/rate-limiting-algorithms-explained-with-code",
      "article_content_markdown": "Rate limiting helps protects services from being overwhelmed by too many requests from a single user or client.\n\n[![](https://substackcdn.com/image/fetch/$s_!tIoU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f62ee63-ccfd-40b9-b1d2-5be4d20395bf_278x344.png)](https://substackcdn.com/image/fetch/$s_!tIoU!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f62ee63-ccfd-40b9-b1d2-5be4d20395bf_278x344.png)\n\nIn this article we will dive into 5 of the most common rate limiting algorithms, their pros and cons and learn how to implement them in code.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n# 1\\. Token Bucket\n\n[![](https://substackcdn.com/image/fetch/$s_!B6c-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2955cacb-e76f-4606-b257-84718268524d_1132x956.png)](https://substackcdn.com/image/fetch/$s_!B6c-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2955cacb-e76f-4606-b257-84718268524d_1132x956.png)\n\nThe Token Bucket algorithm is one of the most popular and widely used rate limiting approaches due to its simplicity and effectiveness.\n\n#### **How It Works**:\n\n- Imagine a bucket that holds tokens.\n\n- The bucket has a maximum capacity of tokens.\n\n- Tokens are added to the bucket at a fixed rate (e.g., 10 tokens per second).\n\n- When a request arrives, it must obtain a token from the bucket to proceed.\n\n- If there are enough tokens, the request is allowed and tokens are removed.\n\n- If there aren't enough tokens, the request is dropped.\n\n\n[![](https://substackcdn.com/image/fetch/$s_!UyUO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F99b5890f-d100-416a-9948-b704daba4d47_3568x3068.png)](https://substackcdn.com/image/fetch/$s_!UyUO!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F99b5890f-d100-416a-9948-b704daba4d47_3568x3068.png)\n\nCode Link: **[Python](https://github.com/ashishps1/awesome-system-design-resources/blob/main/implementations/python/rate_limiting/token_bucket.py), [Java](https://github.com/ashishps1/awesome-system-design-resources/blob/main/implementations/java/rate_limiting/TokenBucket.java)**\n\n#### Pros:\n\n- Relatively straightforward to implement and understand.\n\n- Allows bursts of requests up to the bucket's capacity, accommodating short-term spikes.\n\n\n#### Cons:\n\n- The memory usage scales with the number of users if implemented per-user.\n\n- It doesn’t guarantee a perfectly smooth rate of requests.\n\n\n* * *\n\n# 2\\. Leaky Bucket\n\n[![](https://substackcdn.com/image/fetch/$s_!vVHH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0815d30e-dc9c-4ff4-9eb8-ac76d21ba52d_1048x684.png)](https://substackcdn.com/image/fetch/$s_!vVHH!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0815d30e-dc9c-4ff4-9eb8-ac76d21ba52d_1048x684.png)\n\nThe Leaky Bucket algorithm is similar to Token Bucket but focuses on smoothing out bursty traffic.\n\n#### How it works:\n\n1. Imagine a bucket with a small hole in the bottom.\n\n2. Requests enter the bucket from the top.\n\n3. The bucket processes (\"leaks\") requests at a constant rate through the hole.\n\n4. If the bucket is full, new requests are discarded.\n\n\n[![](https://substackcdn.com/image/fetch/$s_!2d9c!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd07bb981-33a2-48f1-960b-8fb94f7220a4_3532x3516.png)](https://substackcdn.com/image/fetch/$s_!2d9c!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd07bb981-33a2-48f1-960b-8fb94f7220a4_3532x3516.png)\n\nCode Link: **[Python](https://github.com/ashishps1/awesome-system-design-resources/blob/main/implementations/python/rate_limiting/leaky_bucket.py), [Java](https://github.com/ashishps1/awesome-system-design-resources/blob/main/implementations/java/rate_limiting/LeakyBucket.java)**\n\n#### Pros:\n\n- Processes requests at a steady rate, preventing sudden bursts from overwhelming the system.\n\n- Provides a consistent and predictable rate of processing requests.\n\n\n#### Cons:\n\n- Does not handle sudden bursts of requests well; excess requests are immediately dropped.\n\n- Slightly more complex to implement compared to Token Bucket.\n\n\n[Share](https://blog.algomaster.io/p/rate-limiting-algorithms-explained-with-code?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n# 3\\. Fixed Window Counter\n\n[![](https://substackcdn.com/image/fetch/$s_!LeEy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6683da4-8b67-4bbf-bf95-8289d640e1b3_1236x832.png)](https://substackcdn.com/image/fetch/$s_!LeEy!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6683da4-8b67-4bbf-bf95-8289d640e1b3_1236x832.png)\n\nThe Fixed Window Counter algorithm divides time into fixed windows and counts requests in each window.\n\n#### How it works:\n\n1. Time is divided into fixed windows (e.g., 1-minute intervals).\n\n2. Each window has a counter that starts at zero.\n\n3. New requests increment the counter for the current window.\n\n4. If the counter exceeds the limit, requests are denied until the next window.\n\n\n[![](https://substackcdn.com/image/fetch/$s_!z3UI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F643a169a-b6c9-4130-b68e-3fe805df4865_3532x3248.png)](https://substackcdn.com/image/fetch/$s_!z3UI!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F643a169a-b6c9-4130-b68e-3fe805df4865_3532x3248.png)\n\nCode Link: **[Python](https://github.com/ashishps1/awesome-system-design-resources/blob/main/implementations/python/rate_limiting/fixed_window_counter.py), [Java](https://github.com/ashishps1/awesome-system-design-resources/blob/main/implementations/java/rate_limiting/FixedWindowCounter.java)**\n\n#### Pros:\n\n- Easy to implement and understand.\n\n- Provides clear and easy-to-understand rate limits for each time window.\n\n\n#### Cons:\n\n- Does not handle bursts of requests at the boundary of windows well. Can allow twice the rate of requests at the edges of windows.\n\n\n* * *\n\n# 4\\. Sliding Window Log\n\n[![](https://substackcdn.com/image/fetch/$s_!zeZh!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4db0d4a-77b4-44b1-b5c9-50c02d4764ec_950x622.png)](https://substackcdn.com/image/fetch/$s_!zeZh!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4db0d4a-77b4-44b1-b5c9-50c02d4764ec_950x622.png)\n\nThe Sliding Window Log algorithm keeps a log of timestamps for each request and uses this to determine if a new request should be allowed.\n\n#### How it works:\n\n1. Keep a log of request timestamps.\n\n2. When a new request comes in, remove all entries older than the window size.\n\n3. Count the remaining entries.\n\n4. If the count is less than the limit, allow the request and add its timestamp to the log.\n\n5. If the count exceeds the limit, request is denied.\n\n\n[![](https://substackcdn.com/image/fetch/$s_!Qy78!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d45128c-2c85-4158-8731-f7c3893ec994_3532x3068.png)](https://substackcdn.com/image/fetch/$s_!Qy78!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d45128c-2c85-4158-8731-f7c3893ec994_3532x3068.png)\n\nCode Link: **[Python](https://github.com/ashishps1/awesome-system-design-resources/blob/main/implementations/python/rate_limiting/sliding_window_log.py), [Java](https://github.com/ashishps1/awesome-system-design-resources/blob/main/implementations/java/rate_limiting/SlidingWindowLog.java)**\n\n#### Pros:\n\n- Very accurate, no rough edges between windows.\n\n- Works well for low-volume APIs.\n\n\n#### Cons:\n\n- Can be memory-intensive for high-volume APIs.\n\n- Requires storing and searching through timestamps.\n\n\n* * *\n\n# 5\\. Sliding Window Counter\n\n[![](https://substackcdn.com/image/fetch/$s_!KT3o!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80181659-e4fa-4398-bd12-bef659174e81_972x686.png)](https://substackcdn.com/image/fetch/$s_!KT3o!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80181659-e4fa-4398-bd12-bef659174e81_972x686.png)\n\nThis algorithm combines the Fixed Window Counter and Sliding Window Log approaches for a more accurate and efficient solution.\n\nInstead of keeping track of every single request’s timestamp as the sliding log does, it focus on the number of requests from the last window.\n\nSo, if you are in 75% of the current window, 25% of the weight would come from the previous window, and the rest from the current one:\n\n```\nweight = (100 - 75)% * lastWindowRequests + currentWindowRequests\n```\n\nNow, when a new request comes, you add one to that weight (weight + 1). If this new total crosses our set limit, we have to reject the request.\n\n#### How it works:\n\n1. Keep track of request count for the current and previous window.\n\n2. Calculate the weighted sum of requests based on the overlap with the sliding window.\n\n3. If the weighted sum is less than the limit, allow the request.\n\n\n[![](https://substackcdn.com/image/fetch/$s_!MNuT!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5bf707c-52e2-49ed-a9b6-c8deb4bfd409_3680x3876.png)](https://substackcdn.com/image/fetch/$s_!MNuT!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5bf707c-52e2-49ed-a9b6-c8deb4bfd409_3680x3876.png)\n\nCode Link: **[Python](https://github.com/ashishps1/awesome-system-design-resources/blob/main/implementations/python/rate_limiting/sliding_window_counter.py), [Java](https://github.com/ashishps1/awesome-system-design-resources/blob/main/implementations/java/rate_limiting/SlidingWindowCounter.java)**\n\n#### Pros:\n\n- More accurate than Fixed Window Counter.\n\n- More memory-efficient than Sliding Window Log.\n\n- Smooths out edges between windows.\n\n\n#### Cons:\n\n- Slightly more complex to implement.\n\n\nWhen implementing rate limiting, consider factors such as the scale of your system, the nature of your traffic patterns, and the granularity of control you need.\n\nLastly, always communicate your rate limits clearly to your API users, preferably through response headers, so they can implement appropriate retry and backoff strategies in their clients.\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/rate-limiting-algorithms-explained-with-code?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![Ajay's avatar](https://substackcdn.com/image/fetch/$s_!SVvm!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ba0ded7-d18c-41aa-b65a-3fd24a2cb7fd_1166x1168.jpeg)](https://substack.com/profile/57765957-ajay)[![alokam gnaneswarasai's avatar](https://substackcdn.com/image/fetch/$s_!Ax39!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb3e335c-8bb5-49bc-b8ea-289a751adae0_96x96.png)](https://substack.com/profile/244618226-alokam-gnaneswarasai)[![Paras saini's avatar](https://substackcdn.com/image/fetch/$s_!eLkI!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d7aa1f6-0e99-4771-ab43-c4a6302d2ef7_600x600.jpeg)](https://substack.com/profile/251382264-paras-saini)[![Suraj Panker's avatar](https://substackcdn.com/image/fetch/$s_!8V-s!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc22f55c1-a610-4b79-9363-0dbe4246fc5b_96x96.jpeg)](https://substack.com/profile/8100733-suraj-panker)[![Gandhar P's avatar](https://substackcdn.com/image/fetch/$s_!Ktiv!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94674c4d-fb8e-4eb4-9198-00838fa475bb_4032x3024.jpeg)](https://substack.com/profile/42955235-gandhar-p)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/rate-limiting-algorithms-explained-with-code"
    },
    {
      "article_title": "What are Message Queues and When to Use Them?",
      "article_title_citation": "https://blog.algomaster.io/p/message-queues",
      "article_content_markdown": "A message queue is a communication mechanism that enables different parts of a system to send and receive messages **asynchronously**.\n\nIt acts as an **intermediary** that temporarily holds messages sent from **producers (or publishers)** and delivers them to **consumers (or subscribers)**.\n\nThe key characteristic of a message queue is that it allows components to communicate without needing to be aware of each other's existence, leading to a **decoupled architecture**.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n## 1\\. Core Components of a Message Queue\n\n[![](https://substackcdn.com/image/fetch/$s_!Kg04!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6eab95c-f56f-45c7-9248-7e6070c1979b_1614x702.png)](https://substackcdn.com/image/fetch/$s_!Kg04!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6eab95c-f56f-45c7-9248-7e6070c1979b_1614x702.png)\n\n#### **1\\. Producer/Publisher**\n\nThe entity that sends messages to the queue. Producers push messages into the queue without worrying about the consumer's state.\n\n#### **2\\. Consumer/Subscriber**\n\nThe entity that reads messages from the queue. Consumers pull messages from the queue and process them.\n\n#### **3\\. Queue**\n\nThe data structure that stores messages until they are consumed.\n\n#### **4\\. Broker/Queue Manager**\n\nThe software or service that manages the message queue, handles the delivery of messages, and ensures that messages are routed correctly between producers and consumers.\n\n#### **5\\. Message**\n\nThe unit of data sent through the queue. A message typically contains the **payload** (the actual data being sent) and **metadata** (such as headers, timestamps, and priority).\n\n* * *\n\n## 2\\. How Do Message Queues Work?\n\n[![](https://substackcdn.com/image/fetch/$s_!3PO-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44eb88f9-3d87-46ea-9f4a-1c778307bda8_1590x728.png)](https://substackcdn.com/image/fetch/$s_!3PO-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44eb88f9-3d87-46ea-9f4a-1c778307bda8_1590x728.png)\n\nThe basic workflow of a message queue can be broken down into the following steps:\n\n1. **Message Creation**: A producer generates a message containing the necessary data and metadata.\n\n2. **Message Enqueue**: The producer sends the message to the queue, where it is stored until a consumer retrieves it.\n\n3. **Message Storage**: The queue stores the message in a persistent or transient manner based on its configuration.\n\n4. **Message Dequeue**: A consumer retrieves the message from the queue for processing. Depending on the queue's configuration, messages can be consumed in order, based on priority, or even in parallel.\n\n5. **Acknowledgment**: Once the consumer processes the message, it may send an acknowledgment back to the broker, confirming that the message has been successfully handled.\n\n6. **Message Deletion**: After acknowledgment, the broker removes the message from the queue to prevent it from being processed again.\n\n\n* * *\n\n## 3\\. Types of Message Queues\n\nThere are several types of message queues, each designed to solve specific problems:\n\n#### **1\\. Point-to-Point (P2P) Queue**\n\nIn this model, messages are sent from one producer to one consumer.\n\n> Used when a message needs to be processed by a **single consumer**, such as in task processing systems.\n\n#### **2\\. Publish/Subscribe (Pub/Sub) Queue**\n\n[![](https://substackcdn.com/image/fetch/$s_!K2Z6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ccbe5e6-1c1d-4316-b8c0-96abf58ed229_1446x680.png)](https://substackcdn.com/image/fetch/$s_!K2Z6!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ccbe5e6-1c1d-4316-b8c0-96abf58ed229_1446x680.png)\n\nIn this model, messages are published to a **topic**, and multiple consumers can subscribe to that topic to receive messages.\n\n> Used for broadcasting messages to **multiple consumers**, such as in notification systems.\n\n#### **3\\. Priority Queue**\n\nMessages in the queue are assigned **priorities**, and higher-priority messages are processed before lower-priority ones.\n\n> Used when certain tasks need to be handled more urgently than others.\n\n#### **4\\. Dead Letter Queue (DLQ)**\n\n[![](https://substackcdn.com/image/fetch/$s_!obv9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ec7dc65-448d-4880-947e-0f8a15bdce14_1592x712.png)](https://substackcdn.com/image/fetch/$s_!obv9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ec7dc65-448d-4880-947e-0f8a15bdce14_1592x712.png)\n\nA special type of queue where messages that cannot be processed (due to errors or retries) are sent.\n\n> Useful for troubleshooting and handling failed messages.\n\n[Share](https://blog.algomaster.io/p/message-queues?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n## **4\\.** Advantages of Using Message Queues\n\nMessage queues offer several benefits including:\n\n- **Decoupling**: Message queues decouple producers and consumers, allowing them to operate independently. This enables more flexible and scalable architectures.\n\n- **Asynchronous Processing**: Producers can send messages to the queue and move on to other tasks without waiting for consumers to process the messages. This improves overall system throughput.\n\n- **Load Balancing**: Multiple consumers can pull messages from the queue, allowing work to be distributed and balanced across different consumers.\n\n- **Fault Tolerance**: Persistent message queues ensure that messages are not lost even if a consumer or producer fails. They also allow for **retries** and **error handling**.\n\n- **Scalability**: Message queues can handle a high volume of messages, allowing systems to scale horizontally by adding more consumers.\n\n- **Throttling**: Message queues can help control the rate of message processing, preventing consumers from being overwhelmed.\n\n\n* * *\n\n## 5\\. When to Use Message Queues\n\nMessage queues aren't always the best solution, but they are very useful in certain situations:\n\n#### **1\\. Microservices Architecture**\n\n- **Problem**: Microservices need to communicate with each other, but direct communication can lead to tight coupling and cascading failures.\n\n- **Solution**: Use message queues to enable asynchronous communication between microservices, allowing each service to operate independently and resiliently.\n\n\n#### **2\\. Task Scheduling and Background Processing**\n\n- **Problem**: Certain tasks, such as image processing or sending emails, are time-consuming and should not block the main application flow.\n\n- **Solution**: Offload these tasks to a message queue and have background workers (consumers) process them asynchronously.\n\n\n#### **3\\. Event-Driven Architectures**\n\n- **Problem**: Events need to be propagated to multiple services or components, but direct communication would be inefficient.\n\n- **Solution**: Use a Pub/Sub message queue to broadcast events to all interested consumers, ensuring that all parts of the system receive the necessary updates.\n\n\n#### **4\\. Load Leveling**\n\n- **Problem**: Sudden spikes in requests can overwhelm a system, leading to degraded performance or failures.\n\n- **Solution**: Queue incoming requests using a message queue and process them at a steady rate, ensuring that the system remains stable under load.\n\n\n#### **5\\. Reliable Communication**\n\n- **Problem**: Communication between components needs to be reliable, even in the face of network or service failures.\n\n- **Solution**: Use persistent message queues to ensure that messages are not lost and can be retried if delivery fails.\n\n\n* * *\n\n## 6\\. Best Practices for Implementing Message Queues\n\n- **Idempotency**: Ensure that your consumers can handle duplicate messages gracefully, as message queues may deliver the same message more than once.\n\n- **Message Durability**: Choose between persistent and transient messages based on the criticality of the data. Persistent messages ensure reliability but may come with performance trade-offs.\n\n- **Error Handling**: Implement robust error handling, including retries, dead-letter queues, and alerting mechanisms to deal with failed message processing.\n\n- **Security**: Secure your message queues by implementing encryption, authentication, and access control to protect the data in transit and at rest.\n\n- **Monitoring and Metrics**: Set up monitoring and metrics to track the performance and health of your message queues, including message throughput, queue length, and consumer lag.\n\n- **Scalability**: Plan for scalability by choosing a message queue solution that can grow with your system, whether by adding more consumers, partitioning queues, or using a distributed messaging system.\n\n\n* * *\n\n## 7\\. Popular Message Queue Systems\n\nSeveral message queue systems are widely used in the industry, each with its own strengths and use cases:\n\n1. **RabbitMQ**: A widely-used open-source message broker that supports multiple messaging protocols, including [AMQP](https://en.wikipedia.org/wiki/Advanced_Message_Queuing_Protocol). It's known for its reliability and extensive features.\n\n2. **Apache Kafka**: A distributed streaming platform that excels at handling large volumes of data. Kafka is often used for real-time data processing and event streaming.\n\n3. **Amazon SQS**: A fully managed message queue service provided by AWS. SQS is highly scalable and integrates well with other AWS services.\n\n4. **Google Cloud Pub/Sub**: A fully managed message queue service offered by Google Cloud, designed for real-time analytics and event-driven applications.\n\n5. **Redis Streams**: A feature of Redis that provides a simple, in-memory message queue with high performance, suitable for lightweight tasks.\n\n6. **ActiveMQ**: An open-source message broker that supports various messaging protocols and is used in enterprise environments for reliable messaging.\n\n\n* * *\n\n## 8\\. Conclusion\n\nTo conclude, message queues are a powerful tool to enable asynchronous communication, decouple components, and improve the scalability and resilience of modern software systems.\n\nAs with any architectural decision, it's important to consider your specific use case and requirements when deciding to implement message queues in your system.\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/message-queues?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![Tushar Ahuja's avatar](https://substackcdn.com/image/fetch/$s_!N-Yp!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc81ed5b8-8b21-4393-ba47-eb98739104bf_96x96.jpeg)](https://substack.com/profile/58895908-tushar-ahuja)[![Bhagwan Sahane's avatar](https://substackcdn.com/image/fetch/$s_!A_Fh!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe0a5214e-911c-4398-9f34-c2a00556fb9a_96x96.png)](https://substack.com/profile/152206147-bhagwan-sahane)[![Chirag patel's avatar](https://substackcdn.com/image/fetch/$s_!nOHG!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0a13256-6bbe-449a-b417-37fddd3d9661_1080x1080.jpeg)](https://substack.com/profile/160233748-chirag-patel)[![Mahalasa kini's avatar](https://substackcdn.com/image/fetch/$s_!wU--!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70518b49-4ddd-4c7b-9337-a06321b5dfd8_1167x1166.jpeg)](https://substack.com/profile/88179902-mahalasa-kini)[![Hemant Pandey's avatar](https://substackcdn.com/image/fetch/$s_!G-vB!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5d8aef1-0399-40a0-9537-5615ca0fe8d4_1166x1167.jpeg)](https://substack.com/profile/58770480-hemant-pandey)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/message-queues"
    },
    {
      "article_title": "What are Bloom Filters and Where are they Used?",
      "article_title_citation": "https://blog.algomaster.io/p/bloom-filters",
      "article_content_markdown": "Have you ever wondered how **Netflix** knows which shows you've already watched? Or how **Amazon** avoids showing you products you've already purchased?\n\nUsing a traditional data structure like a **hash table** for these checks could consume significant amount of **memory**, especially with millions of users and items.\n\nInstead, many systems rely on a more efficient data structure—a **Bloom Filter**.\n\n[![](https://substackcdn.com/image/fetch/$s_!2-E7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39579c9e-bd42-40d3-a9e5-6031881768da_454x329.png)](https://substackcdn.com/image/fetch/$s_!2-E7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39579c9e-bd42-40d3-a9e5-6031881768da_454x329.png)\n\nIn this article, we will learn what a bloom filter is, how it works, how to implement it in code, it’s real-world applications and limitations.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n## 🤔 What is a Bloom Filter?\n\nA **Bloom Filter** is a **probabilistic data structure** that allows you to quickly check whether an element might be in a set.\n\nIt’s useful in scenarios where you need **fast lookups** and don’t want to use a large amount of memory, but you’re okay with occasional **false positives**.\n\n## 🧩 Key Components of a Bloom Filter:\n\n[![](https://substackcdn.com/image/fetch/$s_!ndRB!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1217bb68-9c1f-4d7d-a961-d1393df35c46_908x771.png)](https://substackcdn.com/image/fetch/$s_!ndRB!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1217bb68-9c1f-4d7d-a961-d1393df35c46_908x771.png)\n\n1. **Bit Array**: The Bloom Filter consists of a bit array of a fixed size, initialized to all zeros. This array represents whether certain elements are in the set.\n\n2. **Hash Functions**: To add or check an element, a Bloom Filter uses multiple hash functions. Each hash function maps an element to an index in the bit array.\n\n\n## ⚙️ How Does a Bloom Filter Work?\n\nA Bloom filter works by using multiple hash functions to map each element in the set to a bit array.\n\n#### **1\\. Initialization:**\n\n- A Bloom filter starts with an empty bit array of size `m` (all bits are initially set to 0).\n\n- It also requires `k` independent hash functions, each of which maps an element to one of the `m` positions in the bit array.\n\n\n#### **2\\. Inserting an Element:**\n\n- To insert an element into the Bloom filter, you pass it through each of the `k` hash functions to get `k` positions in the bit array.\n\n- The bits at these positions are set to 1.\n\n\n#### **3\\. Checking for Membership:**\n\n- To check if an element is in the set, you again pass it through the `k` hash functions to get `k` positions.\n\n- If all the bits at these positions are set to 1, the element is considered to be in the set (though there's a chance it might be a false positive).\n\n- If any bit at these positions is 0, the element is definitely not in the set.\n\n\n[Share](https://blog.algomaster.io/p/bloom-filters?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n## 🔎 Example: Using a Bloom Filter for URL Checking\n\nImagine you're building a web crawler that needs to keep track of which URLs it has already visited.\n\nInstead of storing every URL (which would require a lot of memory), you decide to use a Bloom Filter.\n\n#### Step 1: Set Up the Bloom Filter\n\n- **Initialize a Bit Array**: Let’s assume our Bloom Filter uses a bit array of size **10**, initially all set to 0.\n\n[![](https://substackcdn.com/image/fetch/$s_!jNzn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dc4444c-c968-4a67-9129-e95ce9e945b9_645x177.png)](https://substackcdn.com/image/fetch/$s_!jNzn!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dc4444c-c968-4a67-9129-e95ce9e945b9_645x177.png)\n\n- **Choose Hash Functions**: We’ll use two hash functions in this example. These hash functions take an input (like a URL) and output an index in the bit array.\n\n\n#### Step 2: Adding a URL to the Bloom Filter\n\nSuppose we want to add the URL `example.com` to our Bloom Filter.\n\n1. **Hash Function 1** generates an index of `3` for `example.com`.\n\n2. **Hash Function 2** generates an index of `7` for `example.com`.\n\n\nWe set the bits at indices 3 and 7 in the bit array to 1.\n\n[![](https://substackcdn.com/image/fetch/$s_!FRmB!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8765730b-731c-4237-926c-930d6fb067ae_645x199.png)](https://substackcdn.com/image/fetch/$s_!FRmB!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8765730b-731c-4237-926c-930d6fb067ae_645x199.png)\n\n#### Step 3: Adding Another URL\n\nNow, let's add another URL, `algomaster.io`.\n\n1. **Hash Function 1** generates an index of `1` for `algomaster.io.`\n\n2. **Hash Function 2** generates an index of `4` for `algomaster.io.`\n\n\nWe set the bits at indices 1 and 4 in the bit array to 1.\n\n[![](https://substackcdn.com/image/fetch/$s_!yLrK!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F655099bb-3a2d-471c-833c-46583b9d69bb_645x199.png)](https://substackcdn.com/image/fetch/$s_!yLrK!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F655099bb-3a2d-471c-833c-46583b9d69bb_645x199.png)\n\n#### Step 4: Checking for a URL in the Bloom Filter\n\nSuppose we want to check if `example.com` is already in the Bloom Filter.\n\n1. **Hash Function 1** generates index `3` for `example.com`.\n\n2. **Hash Function 2** generates index `7` for `example.com`.\n\n\nSince both bits at indices 3 and 7 are set to 1, we can say that `example.com` **is probably in the set** (there's a small chance of a false positive).\n\n[![](https://substackcdn.com/image/fetch/$s_!Fs64!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ad6f932-6443-4b31-8ac7-a3da82a96d14_645x199.png)](https://substackcdn.com/image/fetch/$s_!Fs64!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ad6f932-6443-4b31-8ac7-a3da82a96d14_645x199.png)\n\n#### Step 5: Checking for a Non-Existent URL\n\nNow, let's check if `nonexistent.com` is in the Bloom Filter.\n\n1. **Hash Function 1** generates index `2` for `nonexistent.com`.\n\n2. **Hash Function 2** generates index `5` for `nonexistent.com`.\n\n\nSince the bits at indices 2 and 5 are both 0, we can confidently say that `nonexistent.com` **is not in the set**.\n\n[![](https://substackcdn.com/image/fetch/$s_!PUh7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F809bb60f-c484-4fc1-998c-52c4be22b572_645x199.png)](https://substackcdn.com/image/fetch/$s_!PUh7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F809bb60f-c484-4fc1-998c-52c4be22b572_645x199.png)\n\n### 💻 Code Implementation (Java)\n\n[![](https://substackcdn.com/image/fetch/$s_!BDxG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04ccaf04-4289-426c-bb41-71bdf8f1132e_1556x1434.png)](https://substackcdn.com/image/fetch/$s_!BDxG!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04ccaf04-4289-426c-bb41-71bdf8f1132e_1556x1434.png)\n\n#### Explanation\n\n1. **BitSet**: Java’s `BitSet` is used for the bit array to efficiently store and manipulate bits.\n\n2. **Hash Functions**: The code uses two simple hash functions. You can add more complex ones for better distribution.\n\n3. **add(String item)**: This method takes an item, applies each hash function, and sets the corresponding bit in the bit array.\n\n4. **mightContain(String item)**: This method checks if an item might be in the set by testing if all corresponding bits are 1.\n\n   - If any bit is 0, the item is **definitely not in the set**.\n\n   - If all bits are 1, the item is **probably in the set** (with a small chance of a false positive).\n\n## 🌎 Real-World Applications of Bloom Filters\n\nBloom Filters are widely used in real-world applications where space efficiency and speed are essential, and occasional false positives are acceptable.\n\nHere are some common scenarios where Bloom Filters are employed:\n\n### 1\\. **Web Caching**\n\n**Problem**: Web servers often cache frequently accessed pages or resources to improve response times. However, checking the cache for every resource could become costly and slow as the cache grows.\n\n**Solution**: A Bloom Filter can be used to quickly check if a URL might be in the cache. When a request arrives, the Bloom Filter is checked first. If the Bloom Filter indicates the URL is “probably in the cache,” a cache lookup is performed.\n\nIf it indicates the URL is “definitely not in the cache,” the server skips the cache lookup and fetches the resource from the primary storage, saving time and resources.\n\n### 2\\. Spam Filtering in Email Systems\n\n**Problem**: Email systems need to filter out spam emails without constantly checking large spam databases.\n\n**Solution**: A Bloom Filter can store hashes of known spam email addresses. When a new email arrives, the Bloom Filter checks if the sender's address might be in the spam list.\n\nThis allows the email system to quickly determine whether an email is likely to be spam or legitimate.\n\n### 3\\. Databases\n\n**Problem**: Databases, especially distributed ones, often need to check if a key exists before accessing or modifying data. Performing these checks for every key directly in the database can be slow.\n\n**Solution**: Many databases, such as **Cassandra**, **HBase**, and **Redis**, use Bloom Filters to avoid unnecessary disk lookups for non-existent keys. The Bloom Filter quickly checks if a key might be present. If the Bloom Filter indicates “not present,” it can skip the database lookup.\n\n### 4\\. Content Recommendation Systems\n\n**Problem**: Recommendation systems, such as those used by streaming services, need to avoid recommending content that users have already consumed.\n\n**Solution**: A Bloom Filter can track the content each user has previously watched or interacted with. When generating new recommendations, the Bloom Filter quickly checks if an item might already have been consumed.\n\n### 5\\. Social Network Friend Recommendations\n\n**Problem**: Social networks like Facebook or LinkedIn recommend friends or connections to users, but they need to avoid recommending people who are already friends.\n\n**Solution**: A Bloom Filter is used to store the list of each user’s existing connections. Before suggesting new friends, the Bloom Filter can be checked to ensure the user isn’t already connected with them.\n\n## 🛑 Limitations of Bloom Filters\n\n### 1\\. **False Positives**\n\nBloom Filters can produce false positives, meaning they may incorrectly indicate that an element is present in the set when it is not.\n\n> **Example:** Consider a scenario where a non-existent key is checked against a Bloom Filter. If all the hash functions map to bits that are already set to `1`, the filter falsely signals the presence of the key.\n\nSuch false positives can lead to unnecessary processing or incorrect assumptions about data.\n\n**For instance,** in a database system, this might trigger unnecessary cache lookups or wasted attempts to fetch data that doesn’t actually exist.\n\nThe likelihood of false positives can be reduced by choosing an optimal size for the bit array and an appropriate number of hash functions, but they can never be completely eliminated.\n\n### 2\\. **No Support for Deletions**\n\nStandard Bloom Filters do not support element deletions. Once a bit is set to 1 by adding an element, it cannot be unset because other elements may also rely on that bit.\n\nThis limitation makes Bloom Filters unsuitable for dynamic sets where elements are frequently added and removed.\n\nVariants like the **Counting Bloom Filter** can allow deletions by using counters instead of bits, but this requires more memory.\n\n### 3\\. Limited to Set Membership Queries\n\nBloom Filters are specifically designed to answer set membership queries. They do not provide information about the actual elements in the set, nor do they support complex queries or operations beyond basic membership checks.\n\n**Example**: If you need to know the details of an element (e.g., full information about a user ID), you would need another data structure in addition to the Bloom Filter.\n\n### **4\\. Not Suitable for Exact Set Membership**\n\nBloom Filters are probabilistic, meaning they cannot provide a definite “yes” answer (only a “probably yes” or “definitely no”).\n\nFor applications requiring exact membership information, Bloom Filters are not suitable. Other data structures like hash tables or balanced trees should be used instead.\n\n### 5\\. Vulnerable to Hash Collisions\n\nHash collisions are more likely as the number of elements in the Bloom Filter grows. Multiple elements can end up setting or relying on the same bits, increasing false positives.\n\nAs hash collisions accumulate, the filter’s effectiveness decreases. With a high load factor, the filter may perform poorly and become unreliable.\n\nThe use of additional hash functions can help reduce collisions, but increasing the number of hash functions also increases the complexity and the memory requirements.\n\n## ✅ Conclusion\n\nTo summarize, bloom filters are a powerful tool for space-efficient set membership testing, with a wide range of applications. While they may not be suitable for all applications due to the possibility of false positives, they shine in scenarios where space is at a premium and a small error rate is acceptable.\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/bloom-filters?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![pratik thorve's avatar](https://substackcdn.com/image/fetch/$s_!8hvf!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a4d4546-58cc-4194-b13c-acd6dd8e2ffc_96x96.jpeg)](https://substack.com/profile/43234375-pratik-thorve)[![Srinivasa murthy's avatar](https://substackcdn.com/image/fetch/$s_!rvVZ!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1523722d-fa59-4ffc-b80a-98f95cc4b25d_96x96.jpeg)](https://substack.com/profile/14083814-srinivasa-murthy)[![Ilan Sarveswaran's avatar](https://substackcdn.com/image/fetch/$s_!Yjr8!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F00695f94-a98b-42c5-92a4-b9926e48e87a_834x937.jpeg)](https://substack.com/profile/205680843-ilan-sarveswaran)[![Goutam Mishra's avatar](https://substackcdn.com/image/fetch/$s_!u-oG!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68b0ae07-a775-4462-8772-17cd6398bcdc_144x144.png)](https://substack.com/profile/32794823-goutam-mishra)[![Md.Zameari Islam's avatar](https://substackcdn.com/image/fetch/$s_!iuIu!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d12663e-0f95-42ad-a81f-d4dda3e8c438_144x144.png)](https://substack.com/profile/288826601-mdzameari-islam)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/bloom-filters"
    },
    {
      "article_title": "What is Idempotency in Distributed Systems?",
      "article_title_citation": "https://blog.algomaster.io/p/idempotency-in-distributed-systems",
      "article_content_markdown": "Imagine you're making a **purchase** from an online store.\n\nYou hit **\"pay\"** but the screen freezes, and you're unsure if the payment went through.\n\nSo, you **refresh** the page and **try again**.\n\nBehind the scenes, how does the system ensure you aren’t accidentally **charged twice**?\n\n[![](https://substackcdn.com/image/fetch/$s_!yjks!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F538d3bda-046f-48f0-b62d-730327bf3bd7_954x696.png)](https://substackcdn.com/image/fetch/$s_!yjks!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F538d3bda-046f-48f0-b62d-730327bf3bd7_954x696.png)\n\nThis scenario highlights a common problem in distributed systems: **handling repeated operations gracefully.**\n\nThe solution to this problem lies in the concept of **idempotency.**\n\nIn this blog, we'll explore what idempotency is, why it matters, how to implement it, challenges, considerations and best practices to ensure robust and reliable systems.\n\n* * *\n\n## What is Idempotency?\n\n> In mathematics, an operation is idempotent if applying it multiple times produces the same result as applying it once.\n\nFor example, the absolute value function is idempotent: `||-5|| = |-5| = 5.`\n\n**Idempotency** is a property of certain operations whereby executing the same operation multiple times produces the same result as executing it once.\n\nFor example: If a request to delete an item is idempotent—all requests after the first will have no impact.\n\nIn programming, setting a value is idempotent, while incrementing a value is not.\n\n```\nIdempotent: user.status = 'active'  Not Idempotent: user.login_count += 1\n```\n\nSome operations are naturally idempotent.\n\n[![](https://substackcdn.com/image/fetch/$s_!S0ki!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6358570-6fec-4c8c-bc26-32071450a939_940x96.png)](https://substackcdn.com/image/fetch/$s_!S0ki!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6358570-6fec-4c8c-bc26-32071450a939_940x96.png)\n\nNo matter how many times you run this, the result remains the same.\n\n## Why Idempotency Matters\n\nDistributed systems often require **fault tolerance** to ensure high availability. When a network issue causes a **timeout** or an **error**, the client might **retry** the request.\n\n[![](https://substackcdn.com/image/fetch/$s_!czYH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F637607fe-3d2c-49db-be80-3d247bea6ab8_1212x394.png)](https://substackcdn.com/image/fetch/$s_!czYH!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F637607fe-3d2c-49db-be80-3d247bea6ab8_1212x394.png)\n\nIf the system handles retries without idempotency, every retry could change the system’s state unpredictably.\n\nBy designing operations to be idempotent, engineers create a buffer against unexpected behaviors caused by retries.\n\nThis “safety net” prevents repeated attempts from distorting the outcome, ensuring stability and reliability.\n\n[Share](https://blog.algomaster.io/p/idempotency-in-distributed-systems?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n## Strategies to Implement Idempotency\n\n### 1\\. Unique Request Identifiers\n\nOne of the simplest techniques to achieve idempotency is by attaching a **unique identifier**, often called an **idempotency key** to each request.\n\nWhen a client makes a request, it generates a **unique ID** that the server uses to track the request. If the server receives a request with the same ID later, it knows it’s a duplicate and discards it.\n\n> **Example**: A payment service could require every transaction request to include a unique ID. If the client retries with the same ID, the server will skip the charge, preventing duplicate transactions.\n\n**Code Example:**\n\n[![](https://substackcdn.com/image/fetch/$s_!wVHX!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2db9023-fa9a-4d77-9941-a9eaa0b19e92_1698x1500.png)](https://substackcdn.com/image/fetch/$s_!wVHX!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2db9023-fa9a-4d77-9941-a9eaa0b19e92_1698x1500.png)\n\nIn this example, each request includes a unique `request_id` stored in the database to track processed requests and prevent duplicates.\n\n### 2\\. **Database Design Adjustments (Upsert Operation)**\n\nSome database operations, such as inserting the same record multiple times, can lead to unintended duplicate entries.\n\nAchieving idempotency in these cases often requires redesigning the database operations to be inherently idempotent.\n\nThis can involve using `upsert` operations (which updates a record if it exists or inserts it otherwise) or applying **unique constraints** that prevent duplicates from being added in the first place.\n\nIn this example, we use SQL `INSERT ... ON CONFLICT` to achieve an upsert operation, ensuring that duplicate entries don’t affect the database state.\n\n[![](https://substackcdn.com/image/fetch/$s_!2O8p!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2283e98b-4bb9-4785-a247-60b571ffe43c_876x228.png)](https://substackcdn.com/image/fetch/$s_!2O8p!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2283e98b-4bb9-4785-a247-60b571ffe43c_876x228.png)\n\nThis SQL statement inserts a new item if it doesn't exist. If it does exist (conflict on `item_id`), it updates the stock by adding the new stock quantity, ensuring the operation remains idempotent.\n\n### 3\\. Idempotency in Messaging Systems\n\nIn a messaging system, we can enforce idempotency by storing a log of processed message IDs and checking against it for every incoming message.\n\n[![](https://substackcdn.com/image/fetch/$s_!tJRt!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a1e1402-6368-424e-b3e7-f8be7247a786_1372x878.png)](https://substackcdn.com/image/fetch/$s_!tJRt!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a1e1402-6368-424e-b3e7-f8be7247a786_1372x878.png)\n\nEach message has a unique `messageId`. Before processing, we check if the `messageId` is already in `processedMessages`. If it is, the message is ignored; otherwise, it’s processed and added to the set to avoid duplicates.\n\n### **4\\. Idempotency in HTTP Methods**\n\nHTTP defines several methods (verbs) for different types of requests.\n\nThese methods can be categorized by whether they are idempotent or non-idempotent, influencing how a system handles retries and preventing unintended side effects.\n\n#### **Idempotent Methods:**\n\n- **GET:** Retrieves data from a resource. GET requests are inherently idempotent because they only read data and do not alter the server’s state.\n\n  - **Example:** Accessing a blog post by making a GET request to `/posts/123` will simply retrieve that post, without modifying any server data. Whether you retrieve it once or a thousand times, the post remains unchanged.\n- **PUT:** Update or completely replace an existing resource. PUT requests are idempotent because the final state is the same whether the PUT request is executed once or multiple times.\n\n  - **Example:** Updating user information by making a PUT request to `/users/45` with updated user details will overwrite the user’s data with the new information provided. Executing the same PUT request repeatedly results in the same final user data on the server.\n- **DELETE:** Removes a resource from the server. DELETE requests are idempotent because deleting a resource that’s already been deleted has no further effect.\n\n  - **Example:** Deleting an item by making a DELETE request to `/items/678` will remove the item. If you attempt the DELETE request again, it will have no effect since the item no longer exists.\n\n#### **Non-Idempotent Methods:**\n\n- **POST:** Creates a new resource on the server. POST requests are non-idempotent because each request usually results in the creation of a new resource.\n\n  - **Example:** Creating a new order by making a POST request to `/orders` with order details will generate a new order each time the request is made.\n\n## Challenges and Considerations\n\nWhile idempotency is powerful, it comes with its own set of challenges:\n\n1. **Performance Overhead**: Storing idempotency keys or checking for duplicate operations can add overhead and increase the overall latency.\n\n2. **State Management**: Idempotency often requires maintaining state, which can be challenging in stateless architectures.\n\n3. **Distributed Systems**: Ensuring idempotency across distributed systems can be challenging and may require **distributed locking** or **consensus algorithms**.\n\n4. **Time Window**: How long should idempotency guarantees be maintained? Forever, or for a limited time?\n\n5. **Database Constraints**: Not all operations are idempotent by default; unique constraints or upsert logic may be necessary to avoid duplication.\n\n\n## Best Practices\n\nWhen implementing idempotency in your system, consider these best practices:\n\n1. **Use Unique Identifiers**: Attach a unique ID (idempotency key) to each request to track and prevent duplicate processing.\n\n2. **Design for Idempotency from the Start**: It's much easier to design for idempotency from the beginning than to add it later.\n\n3. **Implement Retry with Backoff**: When retrying idempotent operations, use an exponential backoff strategy to avoid overwhelming the system.\n\n4. **Employ Idempotent HTTP Methods**: Prefer idempotent methods (GET, PUT, DELETE) for operations that may be retried; design POST with unique identifiers if idempotency is required.\n\n5. **Document Idempotent Operations**: Clearly document which operations are idempotent in your API specifications.\n\n6. **Test Thoroughly**: Implement tests that verify the idempotency of your operations, including edge cases and failure scenarios.\n\n7. **Use Locks or Versioning**: Use locks, optimistic concurrency control, or version numbers to manage simultaneous requests safely.\n\n\nIdempotency is a powerful concept in distributed systems that can greatly enhance the reliability and fault-tolerance of your systems.\n\nWhether you're designing a distributed database, a payment processing system, or a simple web API, considering idempotency in your design can save you (and your users) from many headaches down the road.\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/idempotency-in-distributed-systems?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![pratik thorve's avatar](https://substackcdn.com/image/fetch/$s_!8hvf!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a4d4546-58cc-4194-b13c-acd6dd8e2ffc_96x96.jpeg)](https://substack.com/profile/43234375-pratik-thorve)[![Tejendra Oberoi's avatar](https://substackcdn.com/image/fetch/$s_!4UiV!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1c1944ab-6ad5-41f7-9b7d-c75754f19670_96x96.png)](https://substack.com/profile/278933138-tejendra-oberoi)[![naviinbharathy's avatar](https://substackcdn.com/image/fetch/$s_!7gK1!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb2a73812-c290-4f6e-a7ff-e7656e985329_96x96.jpeg)](https://substack.com/profile/161224250-naviinbharathy)[![Tulasi Reddy's avatar](https://substackcdn.com/image/fetch/$s_!dRAA!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93a467f4-d29d-4dbd-9a23-adda8e2f62f0_96x96.jpeg)](https://substack.com/profile/108358388-tulasi-reddy)[![Rohindra's avatar](https://substackcdn.com/image/fetch/$s_!VStd!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfcea633-c5f8-4b07-8626-271ed125ae29_144x144.png)](https://substack.com/profile/262772540-rohindra)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/idempotency-in-distributed-systems"
    },
    {
      "article_title": "Concurrency vs Parallelism",
      "article_title_citation": "https://blog.algomaster.io/p/concurrency-vs-parallelism",
      "article_content_markdown": "**Concurrency** and **parallelism** are two of the most misunderstood concepts in **system design**.\n\nWhile they might sound similar, they refer to fundamentally different approaches to handling tasks.\n\nSimply put, one is about **managing** multiple tasks simultaneously, while the other is about **executing** multiple tasks at the same time.\n\nIn this article, we’ll break down the differences between these two concepts, explore how they work, and illustrate their real-world applications with examples and code.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n## 1\\. What is Concurrency?\n\n> _Concurrency_ means an application is making progress on more than one task at the same time.\n\nIn a computer, the tasks are executed using **Central Processing Unit (CPU).**\n\nWhile a single **CPU** can work on only one task at a time, it achieves concurrency by rapidly switching between tasks.\n\nFor example, consider playing music while writing code. The CPU alternates between these tasks so quickly that, to the user, it feels like both are happening at the same time.\n\n[![](https://substackcdn.com/image/fetch/$s_!Qru4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62f1bd22-5554-4ff3-89eb-a06edb787d98_701x289.png)](https://substackcdn.com/image/fetch/$s_!Qru4!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62f1bd22-5554-4ff3-89eb-a06edb787d98_701x289.png) **Visualized using [Multiplayer](https://dub.sh/HCUjQvL)**\n\nThis seamless switching—enabled by modern CPU designs—creates the **illusion of multitasking** andgives the appearance of tasks running in parallel.\n\nHowever, it’s important to note **this is not parallel**. **This is concurrent**.\n\nConcurrency is primarily achieved using **threads**, which are the smallest units of execution within a process. The CPU switches between threads to handle multiple tasks concurrently, ensuring the system remains responsive.\n\nThe primary objective of concurrency is to **maximize CPU utilization** by minimizing idle time.\n\n**For example:**\n\n- When one thread or process is waiting for I/O operations, database transactions, or external program launches, the CPU can allocate resources to another thread.\n\n\nThis ensures the CPU remains productive, even when individual tasks are stalled.\n\n### **How Does Concurrency Works?**\n\nConcurrency in a CPU is achieved through **context switching**.\n\nHere’s how it works:\n\n1. **Context Saving**: When the CPU switches from one task to another, it saves the current task's state (e.g., program counter, registers) in memory.\n\n2. **Context Loading**: The CPU then loads the context of the next task and continues executing it.\n\n3. **Rapid Switching**: The CPU repeats this process, switching between tasks so quickly that it seems like they are running simultaneously.\n\n\n#### The Cost of Context Switching\n\nWhile context switching enables concurrency, it also introduces **overhead**:\n\n- Every switch requires saving and restoring task states, which consumes both time and resources.\n\n- Excessive context switching can degrade performance by increasing CPU overhead.\n\n\n### Real-World Examples of Concurrency\n\n#### 1\\. **Web Browsers**\n\nModern web browsers perform multiple tasks concurrently:\n\n- Rendering web pages (HTML/CSS).\n\n- Fetching external resources like images and scripts.\n\n- Responding to user actions such as clicks and scrolling.\n\n\nEach of these tasks is managed by separate threads, ensuring the browser remains responsive while loading and displaying content.\n\n#### **2\\. Web Servers**\n\nWeb servers like Apache or Nginx handle multiple client requests concurrently:\n\n- Each request is processed independently using threads or asynchronous I/O.\n\n- For example, a server can handle multiple users loading different pages simultaneously without blocking.\n\n\n#### **3\\. Chat Applications**\n\nChat applications perform several operations concurrently:\n\n- Processing incoming messages.\n\n- Updating the user interface with new messages.\n\n- Sending outgoing messages.\n\n\nThis ensures smooth real-time communication without delays or freezes.\n\n#### **4\\. Video Games**\n\nVideo games rely heavily on concurrency to deliver an immersive experience:\n\n- Rendering graphics.\n\n- Processing user input (e.g., character movement).\n\n- Simulating physics.\n\n- Playing background audio.\n\n\nFor example, while a player moves a character, the game simultaneously updates the environment and plays music, ensuring smooth gameplay.\n\n### Code Example\n\nMost popular programming languages come with inbuilt support for creating and managing threads.\n\nHere's an example of a concurrent program in Java:\n\n[![](https://substackcdn.com/image/fetch/$s_!hBll!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b9a362-c13a-49d0-b35b-32e51b4ab514_1234x1418.png)](https://substackcdn.com/image/fetch/$s_!hBll!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b9a362-c13a-49d0-b35b-32e51b4ab514_1234x1418.png)\n\n#### Output (Interleaved Execution):\n\n```\nTask A - Step 1 Task B - Step 1 Task C - Step 1 Task A - Step 2 Task B - Step 2 Task C - Step 2 ...\n```\n\n[Share](https://blog.algomaster.io/p/concurrency-vs-parallelism?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n## 2\\. What is Parallelism?\n\n> _Parallelism_ means multiple tasks are executed simultaneously.\n\nTo achieve parallelism, an application divides its tasks into smaller, independent subtasks. These subtasks are distributed across multiple CPUs, CPU cores, GPU cores, or similar processing units, allowing them to be processed in parallel.\n\n[![](https://substackcdn.com/image/fetch/$s_!UFJl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665560cd-8e55-441b-9b5b-8071ce9e29e2_595x276.png)](https://substackcdn.com/image/fetch/$s_!UFJl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665560cd-8e55-441b-9b5b-8071ce9e29e2_595x276.png) **Visualized using [Multiplayer](https://dub.sh/HCUjQvL)**\n\nTo achieve true parallelism, your application must:\n\n1. Utilize more than one thread.\n\n2. Ensure each thread is assigned to a separate CPU core or processing unit.\n\n\n### **How does Parallelism Works?**\n\nModern CPUs consist of multiple cores. Each core can independently execute a task. Parallelism divides a problem into smaller parts and assigns each part to a separate core for simultaneous processing.\n\n[![](https://substackcdn.com/image/fetch/$s_!6RRF!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69ea729c-73f8-41d4-8391-52f5d397fcfd_1794x666.png)](https://substackcdn.com/image/fetch/$s_!6RRF!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69ea729c-73f8-41d4-8391-52f5d397fcfd_1794x666.png) **Visualized using [Multiplayer](https://dub.sh/HCUjQvL)**\n\n- **Task Division**: The problem is broken into smaller independent sub-tasks.\n\n- **Task Assignment**: Sub-tasks are distributed across multiple CPU cores.\n\n- **Execution**: Each core processes its assigned task simultaneously.\n\n- **Result Aggregation**: Results from all cores are combined to form the final output.\n\n\n### Real-World Examples of Parallelism\n\n#### **1\\. Machine Learning Training**\n\n- Training deep learning models involves dividing datasets into smaller batches.\n\n- Each batch is processed simultaneously across multiple GPUs or CPU cores, significantly speeding up the training process.\n\n\n#### **2\\. Video Rendering**\n\n- Video frames are rendered independently, making it possible to process multiple frames simultaneously.\n\n- For example, rendering a 3D animation becomes much faster when using multiple cores to handle different frames in parallel.\n\n\n#### **3\\. Web Crawlers**\n\n- Web crawlers like Googlebot break a list of URLs into smaller chunks and process them in parallel.\n\n- This allows the crawler to fetch data from multiple websites simultaneously, reducing the time to gather information.\n\n\n#### **4\\. Data Processing**\n\n- Big data frameworks like Apache Spark leverage parallelism to handle massive datasets.\n\n- Tasks such as analyzing logs from millions of users are distributed across a cluster, enabling simultaneous processing and faster insights.\n\n\n#### **5\\. Scientific Simulations**\n\n- Simulations like weather modeling or molecular interactions require heavy computations.\n\n- These computations are divided among multiple cores, allowing simultaneous execution and faster results.\n\n\n### Code Example\n\nHere's a simple example of parallelism in Java using the `ForkJoinPool` framework to compute the sum of an array in parallel:\n\n[![](https://substackcdn.com/image/fetch/$s_!a364!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd5217bd-8503-47c9-b570-74a3feb93a34_1244x1396.png)](https://substackcdn.com/image/fetch/$s_!a364!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd5217bd-8503-47c9-b570-74a3feb93a34_1244x1396.png)\n\n1. **Task Splitting**: The array is divided into smaller segments until the segment size is below the `THRESHOLD`.\n\n2. **Parallel Execution**: Subtasks are executed in parallel using separate threads from the `ForkJoinPool`.\n\n3. **Result Combination**: Results from all subtasks are combined to compute the final sum.\n\n\n* * *\n\n## 3\\. Concurrency and Parallelism Combinations\n\n### **3.1 Concurrent, Not Parallel**\n\nAn application can be concurrent without being parallel. In this case:\n\n- The application makes progress on multiple tasks at the same time **seemingly** (concurrently).\n\n- However, it achieves this by **switching** between tasks rapidly, rather than running them simultaneously.\n\n- **Example**: A single-core CPU alternating between tasks, giving the illusion of multitasking.\n\n\n### **3.2 Parallel, Not Concurrent**\n\nAn application can be parallel without being concurrent. Here:\n\n- A single task is divided into subtasks, and these subtasks are executed simultaneously on separate cores.\n\n- There is no overlap between tasks; one task (and its subtasks) completes before the next task starts.\n\n- **Example**: Video rendering, where a single video is divided into frames, and each frame is processed in parallel.\n\n\n### **3.3 Neither Concurrent Nor Parallel**\n\nSome applications are neither concurrent nor parallel. This means:\n\n- Tasks are executed sequentially, one at a time, without any overlap or parallel execution.\n\n- **Example**: A single-core CPU where only one task is processed, and it completes fully before the next task begins.\n\n\n### **3.4 Concurrent and Parallel**\n\nAn application can be both **concurrent and parallel**, combining the strengths of both execution models.\n\nIn this approach:\n\n1. Multiple tasks make progress at the same time, and each task is also divided into subtasks that are executed in parallel.\n\n2. **Example**: A Multi-core CPU where some subtasks run concurrently on the same core, while others run in parallel on separate cores.\n\n\n[![](https://substackcdn.com/image/fetch/$s_!ljKA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa90047d9-3639-4de2-a8b1-6d8c90b85ad6_1015x683.png)](https://substackcdn.com/image/fetch/$s_!ljKA!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa90047d9-3639-4de2-a8b1-6d8c90b85ad6_1015x683.png) **Visualized using [Multiplayer](https://dub.sh/HCUjQvL)**\n\nIn the above example, a single task is broken into 4 **subtasks**, which are distributed across 2 CPU cores for **parallel execution**. These subtasks are executed by multiple threads. Some threads run on the same CPU core (concurrent execution), while others run on separate CPU cores (parallel execution).\n\nIf each subtask is executed by its own thread on a **dedicated CPU** (e.g., 4 threads on 4 CPUs), the task execution becomes fully **parallel**, with no concurrency involved.\n\nIt’s often challenging to break a task into exactly as many subtasks as there are CPUs. Instead, tasks are typically divided into a number of subtasks that align naturally with the problem's structure and number of CPU cores available.\n\n* * *\n\n## 4\\. Summary\n\n[![](https://substackcdn.com/image/fetch/$s_!IjUc!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59e9520a-fa89-40e7-8b0b-c2a63926e314_2720x2016.png)](https://substackcdn.com/image/fetch/$s_!IjUc!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59e9520a-fa89-40e7-8b0b-c2a63926e314_2720x2016.png)\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/concurrency-vs-parallelism?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![Pawan Kumar's avatar](https://substackcdn.com/image/fetch/$s_!bl6u!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16c2f5db-6e20-4efd-88a6-fc3b7bf30a53_144x144.png)](https://substack.com/profile/166125036-pawan-kumar)[![Chigozie Ugwuede's avatar](https://substackcdn.com/image/fetch/$s_!_HBZ!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84e69510-cf06-4498-9ec6-f1041f8beefb_96x96.png)](https://substack.com/profile/87422201-chigozie-ugwuede)[![Urmindra Shukla's avatar](https://substackcdn.com/image/fetch/$s_!6pUp!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a9a71c6-889b-426c-b44f-cb6e5fc31cc8_3088x2316.jpeg)](https://substack.com/profile/274592874-urmindra-shukla)[![Priyank Kumar Verma's avatar](https://substackcdn.com/image/fetch/$s_!TnFN!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40598ee4-98dc-4a14-b6eb-8eed251e7667_144x144.png)](https://substack.com/profile/58372271-priyank-kumar-verma)[![Pavan D G's avatar](https://substackcdn.com/image/fetch/$s_!Qoo6!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4585246e-7a20-4c62-af02-360436883076_144x144.png)](https://substack.com/profile/278823353-pavan-d-g)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/concurrency-vs-parallelism"
    },
    {
      "article_title": "Stateful vs. Stateless Architecture",
      "article_title_citation": "https://blog.algomaster.io/p/stateful-vs-stateless-architecture",
      "article_content_markdown": "When a client interacts with a server, there are two ways to handle it:\n\n- **Stateless:** The client includes all necessary data in each request, so the server doesn’t store any prior information.\n\n- **Stateful:** The server retains some data from previous requests, making future interactions dependent on past state.\n\n\n> In software systems, **state** refers to any data that persists across requests, such as user sessions, shopping carts, or authentication details.\n\nThe choice between stateless and stateful architecture can affect scalability, performance, complexity, and cost.\n\nIn this article, we’ll break down both the approaches, their advantages and trade-offs, and when to use each—with real-world examples.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n# 1\\. Stateful Architecture\n\nIn a **stateful architecture**, the system remembers client or process data ( **state**) across multiple requests.\n\nOnce a client connects, the server holds on to certain details—like user preferences, shopping cart contents, or authentication sessions—so the client doesn’t need to resend everything with each request.\n\nStateful systems typically store the state data in a database or in-memory storage.\n\n[![](https://substackcdn.com/image/fetch/$s_!Qpx8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f3c594a-5876-4f39-bb3d-619aa6735e59_978x978.png)](https://substackcdn.com/image/fetch/$s_!Qpx8!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f3c594a-5876-4f39-bb3d-619aa6735e59_978x978.png)\n\n> **Example:** During online shopping, when you add items to your cart, the website remembers your selections. If you navigate away to browse more items and then return to your cart, your items are still there, waiting for you to check out.\n\n## Common Patterns in Stateful Architecture\n\n### 1\\. Sticky Sessions\n\nIf you use **in-memory** session storage (i.e., each app server keeps its own sessions locally), you can configure your load balancer for “sticky sessions.”\n\n[![](https://substackcdn.com/image/fetch/$s_!q644!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F531179e7-2f92-49fb-96e7-721ff504c6d8_1424x1840.png)](https://substackcdn.com/image/fetch/$s_!q644!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F531179e7-2f92-49fb-96e7-721ff504c6d8_1424x1840.png)\n\nThis means: Once a client is assigned to **Server A**, all subsequent requests from that client are routed to **Server A**.\n\n> **Trade-Off**: If Server A fails, the user’s session data is lost or the user is forced to re-log in. Sticky sessions are also less flexible when scaling because you can’t seamlessly redistribute user traffic to other servers.\n\n### 2\\. Centralized Session Store\n\nA more robust approach is to store session data in a **centralized** or **distributed** store (e.g., Redis).\n\n[![](https://substackcdn.com/image/fetch/$s_!4m1w!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33631f1e-e350-4098-a044-17353f37ea37_1334x2038.png)](https://substackcdn.com/image/fetch/$s_!4m1w!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33631f1e-e350-4098-a044-17353f37ea37_1334x2038.png)\n\nThis allows:\n\n- **Shared access**: All servers can access and update session data for any user. Any server can handle any request, because the session data is not tied to a specific server’s memory.\n\n\n> **Trade-Off**: You introduce network overhead and rely on an external storage. If the centralized storage fails, you lose session data unless you have a fallback strategy.\n\n## **Advantages:**\n\n- **Personalized Experiences:** Stateful systems can deliver highly tailored interactions, as they remember user preferences and past actions.\n\n- **Contextual Continuity:** Users can seamlessly resume activities where they left off, even if they disconnect and reconnect.\n\n- **Reduced Round Trips:** Certain operations can be faster because the server already possesses necessary data.\n\n\n## **Challenges:**\n\n- **Scalability:** Maintaining state for a large number of users can become resource-intensive and complex, as each server needs to keep track of specific sessions.\n\n- **Complexity:** Managing and synchronizing state across multiple servers (if needed) introduces additional challenges.\n\n- **Failure Points:** If a server holding a user's state fails, their session data might be lost.\n\n\n## Example Use Cases\n\n- **E-commerce Shopping Carts** – Stores cart contents and user preferences across multiple interactions, even if the user navigates away and returns.\n\n- **Video Streaming Services (Netflix, YouTube)** – Remembers user watch progress, recommendations, and session data for a seamless experience.\n\n- **Messaging Apps (WhatsApp, Slack)** – Maintains active user sessions and message history for real-time communication.\n\n\n[Share](https://blog.algomaster.io/p/stateful-vs-stateless-architecture?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n# 2\\. Stateless Architecture\n\nIn a **stateless** architecture, the server does **not** preserve client-specific data between individual requests.\n\n- Each request is treated as **independent**, with no memory of previous interactions.\n\n- Every request must include **all necessary information** for processing.\n\n- Once the server responds, it **discards any temporary data** used for that request.\n\n\n[![](https://substackcdn.com/image/fetch/$s_!stKS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb13cdbee-6c1a-4cb5-af9e-97ba182a3d51_1170x464.png)](https://substackcdn.com/image/fetch/$s_!stKS!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb13cdbee-6c1a-4cb5-af9e-97ba182a3d51_1170x464.png)\n\n> **Example**: Most **RESTful APIs** follow a stateless design. For instance, when you request weather data from a public API, you must provide all required details (e.g., location) in each request. The server processes it, sends a response, and forgets the interaction.\n\n## Common Patterns in Stateless Architecture\n\n### 1\\. Token-Based Authentication (JWT)\n\nA very popular way to implement statelessness is through tokens, particularly **JWTs** (JSON Web Tokens):\n\n1. **Client Authenticates Once**: The user logs in using credentials (username/password) for the first time, and the server issues a signed **JWT**.\n\n2. **Subsequent Requests**: The client includes JWT token in each request (e.g., `Authorization: Bearer <token>` header).\n\n3. **Validation**: The server validates the token’s signature and any embedded claims (e.g., user ID, expiry time).\n\n4. **No Server-Side Storage**: The server does **not** need to store session data; it just verifies the token on each request.\n\n\n> Many APIs, including OAuth-based authentication systems, use JWTs to enable stateless, scalable authentication.\n\n### 2\\. Idempotent APIs\n\nStateless architectures benefit from **idempotent operations**, ensuring that repeated requests produce the same result. This prevents inconsistencies due to network retries or client errors.\n\n**Example:** A `PUT /users/123` request with the same payload **always** updates the user’s data but doesn’t create duplicates.\n\n> Idempotent APIsensures consistency and reliability, especially in distributed systems where requests might be retried automatically.\n\n## **Advantages:**\n\n- **Scalability:** Stateless systems are inherently easier to scale horizontally. New servers can be added effortlessly, as they don't need to maintain any specific user sessions.\n\n- **Simplicity:** Since servers don't track state, the architecture is generally simpler and easier to manage.\n\n- **Resilience:** The failure of a single server won't disrupt user sessions, as data isn't tied to specific servers.\n\n- **Lower Memory Footprint:** With no session data stored on the server, you free up memory that would otherwise be reserved for session management.\n\n- **Easier to Cache Responses:** Since requests are self-contained, caching layers (like CDNs) can more easily store and serve responses.\n\n\n## **Challenges:**\n\n- **Less Context:** Stateless systems can't provide the same level of personalization or context awareness as stateful systems without additional effort (like using cookies or tokens).\n\n- **Client-Side Complexity:** The client must keep track of the authentication token or relevant data. If it loses the token, it must re-authenticate.\n\n- **Large Payloads:** Every request needs to carry all the required information, potentially leading to larger payloads.\n\n\n## Example Use Cases\n\n1. **Microservices Architecture:** Each service handles requests independently, relying on external databases or caches instead of maintaining session data.\n\n2. **Public APIs (REST, GraphQL):** Clients send tokens with each request, eliminating the need for server-side sessions.\n\n3. **Mobile Apps:** Tokens are securely stored on the device and sent with every request to authenticate users.\n\n4. **CDN & Caching Layers:** Stateless endpoints make caching easier since responses depend only on request parameters, not stored session data. A CDNcan cache and serve repeated requests, improving performance and reducing backend load.\n\n\n* * *\n\n# Choosing the Right Approach\n\nThere's no one-size-fits-all answer when choosing between stateful and stateless architectures.\n\nThe best choice depends on your application’s needs, scalability goals, and user experience expectations.\n\n### **When to Choose Stateful Architecture**\n\nStateful systems are ideal when **user context and continuity** are critical.\n\nConsider a stateful approach if your application:\n\n- Requires personalization (e.g., user preferences, session history)\n\n- Needs real-time interactions (e.g., chat applications, multiplayer gaming)\n\n- Manages multi-step workflows (e.g., online banking transactions, checkout processes)\n\n- Must retain authentication sessions for security and convenience\n\n\n> **Example:** A shopping cart in an e-commerce app should persist, so users don’t have to re-add items after refreshing the page.\n\n### **When to Choose Stateless Architecture**\n\nStateless systems work best when **scalability, simplicity, and resilience** are top priorities.\n\nUse a stateless approach if your application:\n\n- Handles a high volume of requests and needs to scale efficiently\n\n- Doesn’t require storing client-specific data between requests\n\n- Needs fast, distributed processing without server dependencies\n\n- Must ensure reliability and failover readiness\n\n\n> **Example:** A weather API doesn’t need to remember previous requests. Each query includes the location, and the response is processed independently.\n\n### **Hybrid Approaches: The Best of Both Worlds**\n\nMany modern applications **blend** stateful and stateless components for flexibility.\n\nThis hybrid approach allows:\n\n- Stateless APIs for core functionality, ensuring high scalability\n\n- Stateful sessions for personalization, improving user experience\n\n- External session stores (e.g., Redis) to manage state while keeping app servers stateless\n\n\n> **Example:** A video streaming platform (e.g., Netflix) uses a stateless backend for streaming but retains stateful user sessions to track watch history and recommendations.\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/stateful-vs-stateless-architecture?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)** and **[X](https://twitter.com/ashishps_1)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![User's avatar](https://substackcdn.com/image/fetch/$s_!7cZK!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc660300b-74d3-47ce-865f-bcb36da141de_144x144.png)](https://substack.com/profile/210164535-user)[![Koushik's avatar](https://substackcdn.com/image/fetch/$s_!REtd!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F996b9117-969c-4f02-b525-28db53755b17_144x144.png)](https://substack.com/profile/111377069-koushik)[![Ibrahim Elsawaf's avatar](https://substackcdn.com/image/fetch/$s_!Wq_L!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7373590-b109-4fe8-9257-c188a1ac4e01_1170x1170.jpeg)](https://substack.com/profile/14689925-ibrahim-elsawaf)[![Nimil Shah's avatar](https://substackcdn.com/image/fetch/$s_!BfI0!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5c6fd61-162c-4a1c-90dd-77d675c3d605_144x144.png)](https://substack.com/profile/139446871-nimil-shah)[![Aparna Panwar's avatar](https://substackcdn.com/image/fetch/$s_!ph29!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9349464f-af73-4cc5-aaf2-ab9470fe4e8e_1176x1176.jpeg)](https://substack.com/profile/88673369-aparna-panwar)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/stateful-vs-stateless-architecture"
    },
    {
      "article_title": "Long Polling vs WebSockets",
      "article_title_citation": "https://blog.algomaster.io/p/long-polling-vs-websockets",
      "article_content_markdown": "Whether you are playing an online game or chatting with a friend—updates appear in real-time without hitting **“refresh”**.\n\nBehind these seamless experiences lies a critical engineering decision: **how to push real-time updates from servers to clients**.\n\nThe traditional HTTP model was designed for request-response: _\"Client asks, server answers.\"._ But in many real-time systems, the server needs to talk first and more often.\n\nThis is where **Long Polling** and **WebSockets** come into play—two popular methods for achieving real-time updates.\n\nIn this article, we’ll explore these two techniques, how they work, their pros and cons, and use cases.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n# 1\\. Why Traditional HTTP Isn’t Enough\n\nHTTP, the backbone of the web, follows a **client-driven** **request-response model**:\n\n1. The client (e.g., a browser or mobile app) sends a request to the server.\n\n2. The server processes the request and sends back a response.\n\n3. The connection closes.\n\n\n[![](https://substackcdn.com/image/fetch/$s_!2MXM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F094ef5bb-a62f-44b4-8ef0-a317c3504e61_410x558.png)](https://substackcdn.com/image/fetch/$s_!2MXM!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F094ef5bb-a62f-44b4-8ef0-a317c3504e61_410x558.png)\n\nThis model is simple and works for many use-cases, but it has limitations:\n\n- **No automatic updates:** With plain HTTP, the server cannot proactively push data to the client. The client has to request the data periodically.\n\n- **Stateless nature:** HTTP is stateless, meaning each request stands alone with no persistent connection to the server. This can be problematic if you need continuous exchange of data.\n\n\nTo build truly real-time features—live chat, financial tickers, or gaming updates—you need a mechanism where the server can instantly notify the client when something changes.\n\n* * *\n\n# 2\\. Long Polling\n\n**Long polling** is a technique that mimics real-time behavior by keeping HTTP requests open until the server has data.\n\nLong Polling is an enhancement over traditional polling. In regular polling, the client repeatedly sends requests at fixed intervals (e.g., every second) to check for updates. This can be wasteful if no new data exists.\n\nLong Polling tweaks this approach: the client asks the server for data and then “waits” until the server has something new to return or until a timeout occurs.\n\n### How Does Long Polling Work?\n\n1. **Client sends a request** to the server, expecting new data.\n\n2. **Server holds the request open** until it has an update or a timeout is reached.\n\n   - If there's new data, the server immediately responds.\n\n   - If there’s no new data and the timeout is reached, the server responds with an empty or minimal message.\n3. Once the client receives a response—new data or a timeout—it **immediately sends a new request** to the server to keep the connection loop going.\n\n\n[![](https://substackcdn.com/image/fetch/$s_!OZ48!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1a03057-991b-4334-80a2-5d413f7d4a61_449x620.png)](https://substackcdn.com/image/fetch/$s_!OZ48!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1a03057-991b-4334-80a2-5d413f7d4a61_449x620.png)\n\n### Pros ✅\n\n- Simple to implement (uses standard HTTP).\n\n- Supported universally since it uses standard HTTP, and it works reliably through firewalls and proxies.\n\n\n### Cons ❌\n\n- Higher latency after each update (client must re-establish connection).\n\n- Resource-heavy on servers (many open hanging requests).\n\n\n### Use Cases\n\n- Simple chat or comment systems where real-time but slightly delayed updates (near real-time) are acceptable.\n\n- Notification systems for less frequent updates (e.g., Gmail’s \"new email\" alert).\n\n- Legacy systems where WebSockets aren’t feasible.\n\n\n### Code Example (JavaScript)\n\n[![](https://substackcdn.com/image/fetch/$s_!ps4_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e16c3c7-3e02-4c48-9db1-2de7c35c1689_595x339.png)](https://substackcdn.com/image/fetch/$s_!ps4_!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e16c3c7-3e02-4c48-9db1-2de7c35c1689_595x339.png)\n\n[Share](https://blog.algomaster.io/p/long-polling-vs-websockets?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n# 3\\. WebSockets\n\n**WebSockets** provide a **full-duplex, persistent connection** between the client and the server.\n\nOnce established, both parties can send data to each other at any time, without the overhead of repeated HTTP requests.\n\n### How Do WebSockets Work?\n\n1. **Handshake:** Client sends an HTTP request with `Upgrade: websocket`.\n\n2. **Connection**: If supported, the server upgrades the connection to WebSocket (switching from `http://` to `ws://`). After the handshake, client and server keep a TCP socket open for communication.\n\n3. **Full-Duplex Communication:** Once upgraded, data can be exchanged bidirectionally in real time until either side closes the connection.\n\n\n[![](https://substackcdn.com/image/fetch/$s_!MzeY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89167db8-498e-4c23-bd68-c61935128b27_410x572.png)](https://substackcdn.com/image/fetch/$s_!MzeY!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89167db8-498e-4c23-bd68-c61935128b27_410x572.png)\n\n### Pros ✅\n\n1. Ultra-low latency (no repeated handshakes).\n\n2. Lower overhead since there’s only one persistent connection rather than repeated HTTP requests.\n\n3. Scalable for real-time applications that need to support large number of concurrent users.\n\n\n### Cons ❌\n\n1. More complex setup (requires the client and server to support WebSocket).\n\n2. Some proxies and firewalls may not allow WebSocket traffic.\n\n3. Complexity in implementation and handling reconnections/errors.\n\n4. Server resource usage might grow if you have a large number of concurrent connections.\n\n\n### Use Cases\n\n1. Live chat and collaboration tools (Slack, Google Docs, etc.).\n\n2. Multiplayer online games with real-time state synchronization.\n\n3. Live sports/financial dashboards that need to push frequent updates.\n\n\n### Code Example (JavaScript)\n\n[![](https://substackcdn.com/image/fetch/$s_!Tw27!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2692cd8b-09c4-4c76-8852-fddbe0549399_557x521.png)](https://substackcdn.com/image/fetch/$s_!Tw27!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2692cd8b-09c4-4c76-8852-fddbe0549399_557x521.png)\n\n* * *\n\n# **4\\. Choosing the Right Solution**\n\nBoth methods achieve real-time updates, but your choice depends on your project’s requirements:\n\n1. **Complexity and Support**\n\n   - **Long Polling** is easier to implement using standard libraries. Any environment that supports HTTP can handle it, often without extra packages.\n\n   - **WebSockets** require a bit more setup and a capable proxy environment (e.g., support in Nginx or HAProxy). However, many frameworks (e.g., Socket.io) simplify the process significantly.\n2. **Scalability and Performance**\n\n   - **Long Polling** can become resource-intensive with a large number of simultaneous clients, due to multiple open connections waiting on the server side.\n\n   - **WebSockets** offer a more efficient, persistent connection and scale better for heavy, frequent data streams.\n3. **Type of Interaction**\n\n   - **Long Polling** fits scenarios where data updates aren’t super frequent. If new data arrives every few seconds or minutes, long polling might be enough.\n\n   - **WebSockets** are better for high-frequency updates or two-way communication (e.g., multiple participants editing a document or interacting in a game).\n4. **Network Constraints**\n\n   - **Long Polling** typically works even in older networks or those with strict firewalls.\n\n   - **WebSockets** might face issues in certain corporate or older mobile environments, though this is less of a problem as the standard becomes more widespread.\n\n> While both achieve real-time communication, WebSockets are generally more efficient for truly real-time applications, while Long Polling can be simpler to implement for less demanding scenarios.\n\n* * *\n\n# 5\\. Alternative Solutions Worth Considering\n\n#### **1\\. Server-Sent Events (SSE)**\n\n- Allows the server to push messages to the client over HTTP.\n\n- It's simpler than WebSockets for one-way communication, but not full-duplex.\n\n- Best suited for use cases like news feeds, real-time notifications, and status updates.\n\n\n#### **2\\. MQTT**\n\n- Commonly used in IoT for lightweight publish-subscribe messaging.\n\n- Specialized for device-to-device or device-to-server communication with minimal overhead.\n\n\n#### **3\\. Libraries like Socket.io**\n\n- Provides an abstraction over WebSockets for easier real-time communication.\n\n- Automatically falls back to long polling if WebSockets are unsupported.\n\n- Ensures cross-browser compatibility with robust and reliable performance.\n\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/long-polling-vs-websockets?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![Narendra Reddy's avatar](https://substackcdn.com/image/fetch/$s_!J1p5!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab4b7586-b57a-4b43-bfe9-bde2eeda4b86_144x144.png)](https://substack.com/profile/38321720-narendra-reddy)[![Koushik's avatar](https://substackcdn.com/image/fetch/$s_!REtd!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F996b9117-969c-4f02-b525-28db53755b17_144x144.png)](https://substack.com/profile/111377069-koushik)[![Aishwarya Venkatesh's avatar](https://substackcdn.com/image/fetch/$s_!1CtA!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faedd194b-e488-4513-9a5e-c40b717ddca8_144x144.png)](https://substack.com/profile/252816061-aishwarya-venkatesh)[![Aaditya Shukla's avatar](https://substackcdn.com/image/fetch/$s_!uG0p!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff12d1fb-ea12-4748-ad90-31ef13296f58_144x144.png)](https://substack.com/profile/257665717-aaditya-shukla)[![Aparna Panwar's avatar](https://substackcdn.com/image/fetch/$s_!ph29!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9349464f-af73-4cc5-aaf2-ab9470fe4e8e_1176x1176.jpeg)](https://substack.com/profile/88673369-aparna-panwar)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/long-polling-vs-websockets"
    },
    {
      "article_title": "Batch vs Stream Processing - What's the Difference?",
      "article_title_citation": "https://blog.algomaster.io/p/batch-processing-vs-stream-processing",
      "article_content_markdown": "In the world of big data, **batch processing** and **stream processing** are the two common approaches to **process large amounts of data**.\n\nWhile both the approaches aim to process data, they differ in **execution** and are suited for different use cases.\n\nIn this article, we'll dive into the details of batch processing and stream processing, explore their characteristics, differences, and provide examples to clarify their use cases.\n\n* * *\n\nIf you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Unlock Full Access](https://blog.algomaster.io/subscribe)\n\n* * *\n\n# **1\\. Batch Processing**\n\n[![](https://substackcdn.com/image/fetch/$s_!o-Mu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8baf741-05a4-4f3f-83ea-22f0f25f1105_994x712.png)](https://substackcdn.com/image/fetch/$s_!o-Mu!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8baf741-05a4-4f3f-83ea-22f0f25f1105_994x712.png)\n\n**Batch processing** is a traditional approach to data processing that has been around for decades.\n\nIt involves:\n\n1. **Collecting** and **storing** data over a period of time (hours, days, or even weeks).\n\n2. Processing this data in **bulk** at **scheduled intervals.**\n\n3. Producing some output data.\n\n\n### Key Characteristics:\n\n- **Scheduled**: It processes data at scheduled intervals, such as daily, weekly, or monthly.\n\n- **High throughput**: Since large volumes of data are processed together, it achieves high throughput.\n\n- **Latency**: There is inherent latency because data is processed after being accumulated over a period.\n\n- **Consistency**: It ensures that the entire dataset is processed consistently.\n\n\n> **Example Use Cases:**\n>\n> - Generating end-of-day reports.\n>\n> - Processing payroll at the end of the month.\n>\n> - Performing large-scale ETL (Extract, Transform, Load) tasks.\n\n## Batch Processing Workflow\n\n#### 1\\. Data Collection:\n\nData is collected over time and stored in a buffer, file system, database, or data warehouse. This phase can last for hours, days, or even months, depending on the business requirement.\n\n#### 2\\. Pre-processing:\n\nBefore the batch is processed, the system may perform a series of preparatory steps such as data validation, cleaning, filtering, or aggregating.\n\n#### 3\\. Batch Execution:\n\nOnce the data is ready, it is processed as a single unit.\n\nThis can involve:\n\n- Running computations over the data.\n\n- Performing ETL (Extract, Transform, Load) operations.\n\n- Aggregating, summarizing, or transforming the data. Batch jobs are usually executed by a batch processing system or job scheduler that triggers the execution at scheduled intervals.\n\n\n#### 4\\. Post-processing:\n\nAfter the execution, the processed data is typically written back to the database, storage, or sent to another system for further use. Reporting or analytics tasks can also be triggered in this step.\n\n#### 5\\. Job Completion:\n\nFinally, the system marks the batch as complete and prepares for the next scheduled run.\n\n## Code Example:\n\n[![](https://substackcdn.com/image/fetch/$s_!6WI0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7a27078-b870-4a32-b640-d9710c3f9d22_1330x766.png)](https://substackcdn.com/image/fetch/$s_!6WI0!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7a27078-b870-4a32-b640-d9710c3f9d22_1330x766.png)\n\nIn this simple example, all the data is collected and processed in one go, typical of batch processing.\n\n## Challenges in Batch Processing:\n\n- **Latency**: The time it takes to collect data can be a bottleneck in situations where timely insights are required.\n\n- **Storage**: Batch systems require large amounts of storage to collect and hold data before processing. Storing massive datasets over time can be costly.\n\n- **Resource Spikes**: Batch processing jobs often consume significant system resources when they run, causing spikes in CPU, memory, and disk usage. This can slow down other system operations, especially during peak hours.\n\n- **Failure and Error Handling**: If an error occurs during a batch process, the entire batch may need to be reprocessed, leading to inefficiency and delays.\n\n\n## Frameworks and Tools\n\n#### 1\\. **Apache Hadoop**\n\nHadoop is one of the most popular batch processing frameworks. It uses the **MapReduce** paradigm to split large datasets across a distributed cluster, process the data in parallel, and then aggregate the results.\n\n#### 2\\. Apache Spark\n\nSpark is a distributed computing system that supports batch processing through its **RDD (Resilient Distributed Dataset)** architecture. Spark is more efficient than Hadoop for certain workloads due to its in-memory processing capabilities.\n\n#### 3\\. AWS Batch\n\nAWS Batch allows developers to easily and efficiently run batch jobs on the cloud. It automatically provisions resources based on job requirements and scales resources up or down as needed.\n\n[Share](https://blog.algomaster.io/p/batch-processing-vs-stream-processing?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n# **2\\. Stream Processing**\n\n[![](https://substackcdn.com/image/fetch/$s_!i6rP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20989426-433b-4e9e-9bc1-46ddcacd5e15_928x556.png)](https://substackcdn.com/image/fetch/$s_!i6rP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20989426-433b-4e9e-9bc1-46ddcacd5e15_928x556.png)\n\n**Stream processing** is a more recent approach that has gained popularity with the rise of **real-time data** and the need for immediate insights.\n\nIt involves processing data in **real time** or **near real time** as it arrives.\n\n### Key Characteristics:\n\n- **Real-time processing**: Data is processed as soon as it is received.\n\n- **Low latency**: Stream processing systems are designed to provide low-latency responses, often within milliseconds or seconds.\n\n- **Event-driven**: Processing is triggered by events, making it suitable for real-time applications.\n\n- **Infinite data streams**: Stream processing systems work on continuous flows of data, as opposed to finite datasets in batch processing.\n\n\n> **Example Use Cases:**\n>\n> - Monitoring sensor data in IoT systems.\n>\n> - Detecting fraud in financial transactions in real-time.\n>\n> - Real-time analytics for online user activity.\n\n## Stream Processing Workflow\n\n#### 1\\. Data Ingestion:\n\nThe first step is the ingestion of a continuous flow of data from one or more sources. This data could come from:\n\n- Message brokers like **Apache Kafka** or **AWS Kinesis**.\n\n- IoT devices that generate sensor data.\n\n- Log streams from web servers.\n\n- Financial systems generating transaction records.\n\n\n#### 2\\. Processing/Transformation:\n\nOnce data is ingested, it is processed as it arrives. Stream processing involves operations such as:\n\n- **Filtering**: Removing unnecessary or irrelevant data.\n\n- **Aggregation**: Summarizing data in real time (e.g., calculating running totals).\n\n- **Windowing**: Grouping events within a specific time window (e.g., calculating metrics over the last 10 minutes).\n\n- **Enrichment**: Joining the stream with external data sources to add more context to the event.\n\n\n#### 3\\. State Management:\n\nMany stream processing tasks require the system to maintain state (e.g., aggregating transactions per user).\n\nManaging state in a distributed, real-time environment is complex, but modern frameworks provide fault-tolerant state management to ensure consistency.\n\n#### 4\\. Output:\n\nThe processed data can be used to trigger immediate actions or be sent to other systems like databases, dashboards, or external APIs.\n\nCommon destinations include:\n\n- Databases for real-time analytics.\n\n- Alerts or notifications for abnormal events (e.g., fraud detection).\n\n- Updates to a real-time dashboard for visualization.\n\n\n## Code Example:\n\n[![](https://substackcdn.com/image/fetch/$s_!2Xhn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8aec7a3c-b5e3-4347-86b7-e5941e8f7f96_1242x730.png)](https://substackcdn.com/image/fetch/$s_!2Xhn!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8aec7a3c-b5e3-4347-86b7-e5941e8f7f96_1242x730.png)\n\nIn this example, transactions are processed one by one as they come in, typical of stream processing where the data is constantly flowing.\n\n## Challenges in Stream Processing:\n\n- **Complexity**: The system must handle data continuously, requiring real-time monitoring, scaling, and fault tolerance mechanisms.\n\n- **Data consistency**: Since data is processed in real time, maintaining consistency, especially in distributed systems, can be difficult.\n\n- **Error Handling**: In stream processing, errors need to be managed in real time. Recovering from failures while maintaining accurate results can be challenging, especially in distributed systems where state is maintained across multiple nodes.\n\n\n* * *\n\n# 3\\. Frameworks and Tools\n\n#### 1\\. Apache Kafka\n\nKafka is one of the most popular distributed messaging systems used for ingesting data streams. It provides high-throughput, fault-tolerant, and scalable message processing. Kafka acts as a buffer between data producers and consumers in stream processing.\n\n#### 2\\. Apache Flink\n\nFlink is a stream processing framework known for low-latency, high-throughput data processing. It supports stateful computations and allows users to build robust real-time data pipelines.\n\n#### 3\\. AWS Kinesis\n\nKinesis is Amazon’s managed stream processing service. It enables real-time data ingestion and processing at scale, providing seamless integration with other AWS services like Lambda, S3, and Redshift.\n\n* * *\n\n# 4\\. Batch vs Stream processing: A tabular comparison\n\n[![](https://substackcdn.com/image/fetch/$s_!t2zl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa179a77c-6eab-4ea9-b835-af6c0c0d1d92_2304x2168.png)](https://substackcdn.com/image/fetch/$s_!t2zl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa179a77c-6eab-4ea9-b835-af6c0c0d1d92_2304x2168.png)\n\n* * *\n\n# **5\\. Choosing the Right Approach**\n\nWhen deciding between batch processing and stream processing, consider the following factors:\n\n- **Data volume**: If you're dealing with large volumes of data, batch processing might be the better choice.\n\n- **Real-time requirements**: If your application requires immediate insights or actions based on incoming data, stream processing is the way to go.\n\n- **Complexity**: If your processing tasks require complex algorithms and data transformations, batch processing might be more suitable.\n\n- **Data nature:** Is your data finite and predictable in size, or an unbounded, ongoing flow? Batch processing is better suited for the former, stream processing for the latter.\n\n\n### Hybrid Approach: Micro-Batch Processing\n\nSome systems like **Apache Spark Streaming** employ a hybrid approach known as **micro-batch processing**.\n\nThis method bridges the gap between traditional batch and stream processing by processing small chunks of data over short intervals.\n\nThis allows for near real-time processing with the simplicity of batch processing.\n\n* * *\n\nThank you for reading!\n\nIf you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.\n\nIf you have any questions or suggestions, leave a comment.\n\nThis post is public so feel free to share it.\n\n[Share](https://blog.algomaster.io/p/batch-processing-vs-stream-processing?utm_source=substack&utm_medium=email&utm_content=share&action=share)\n\n* * *\n\n**P.S.** If you’re enjoying this newsletter and want to get even more value, consider becoming a **[paid subscriber](https://blog.algomaster.io/subscribe)**.\n\nAs a paid subscriber, you'll unlock all **premium articles** and gain full access to all **[premium courses](https://algomaster.io/newsletter/paid/resources)** on **[algomaster.io](https://algomaster.io/)**.\n\n[Get full access to AlgoMaster](https://blog.algomaster.io/subscribe)\n\n**There are [group discounts](https://blog.algomaster.io/subscribe?group=true), [gift options](https://blog.algomaster.io/subscribe?gift=true), and [referral bonuses](https://blog.algomaster.io/leaderboard) available.**\n\n* * *\n\nCheckout my **[Youtube channel](https://www.youtube.com/@ashishps_1/videos)** for more in-depth content.\n\nFollow me on **[LinkedIn](https://www.linkedin.com/in/ashishps1/)**, **[X](https://twitter.com/ashishps_1)** and **[Medium](https://medium.com/@ashishps)** to stay updated.\n\nCheckout my **[GitHub repositories](https://github.com/ashishps1)** for free interview preparation resources.\n\nI hope you have a lovely day!\n\nSee you soon,\n\nAshish\n\n[![PremKumar G's avatar](https://substackcdn.com/image/fetch/$s_!1Lo1!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F709427a0-0b2c-411c-bc51-94a9e3c316b0_96x96.jpeg)](https://substack.com/profile/39259997-premkumar-g)[![Aaditya Shukla's avatar](https://substackcdn.com/image/fetch/$s_!uG0p!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff12d1fb-ea12-4748-ad90-31ef13296f58_144x144.png)](https://substack.com/profile/257665717-aaditya-shukla)[![Suprita Chakravorty's avatar](https://substackcdn.com/image/fetch/$s_!M1eK!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1f3ae3c-65f3-4dc1-9415-4415c143aa0c_96x96.png)](https://substack.com/profile/219201398-suprita-chakravorty)[![Gourav Trivedi's avatar](https://substackcdn.com/image/fetch/$s_!kh7W!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59a66db1-e49f-471f-8867-2298e17961a7_144x144.png)](https://substack.com/profile/209853279-gourav-trivedi)[![Aparna Panwar's avatar](https://substackcdn.com/image/fetch/$s_!ph29!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9349464f-af73-4cc5-aaf2-ab9470fe4e8e_1176x1176.jpeg)](https://substack.com/profile/88673369-aparna-panwar)\n",
      "article_content_markdown_citation": "https://blog.algomaster.io/p/batch-processing-vs-stream-processing"
    }
  ]
}
